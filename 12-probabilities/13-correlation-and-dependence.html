
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Correlation and Dependence &#8212; Data Science Handbook</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bayesian’s Theorem" href="31-bayesian-theorem.html" />
    <link rel="prev" title="Expectation and Variance" href="11-expectation-and-variance.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Data Science Handbook</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Data Science Handbook
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11-math/00-math.html">
   Math
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/11-combinatorics.html">
     Combinatorics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/12-derangement.html">
     Derangement
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/21-linear-algebra.html">
     Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/51-optimization.html">
     Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/90-puzzles.html">
     Puzzles
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="00-probabilities.html">
   Probabilities
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="11-expectation-and-variance.html">
     Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Correlation and Dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="31-bayesian-theorem.html">
     Bayesian’s Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="51-markov-chain.html">
     Markov Chain
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="71-sampling.html">
     Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="90-multivariate-notations.html">
     Multivariate Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="91-large-sample-theory.html">
     Large Sample Theory
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13-statistics/00-statistics.html">
   Statistics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/11-sample-survey.html">
     Sample Survey
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/13-randomized-trial.html">
     Causality and Randomized Trial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/21-hypothesis-testing.html">
     Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/25-two-sample-tests.html">
     Two Sample Mean Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/33-confusion-matrix.html">
     Confusion Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/41-maximum-likelihood-estimation.html">
     Maximum Likelihood Estimator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/43-estimators-evaluation.html">
     Estimators Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../14-python/00-python.html">
   Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/11-programming-tools.html">
     Programmer tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/12-syntax.html">
     Syntax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/13-data-structure.html">
     Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/15-functional-programming.html">
     Functional Programming
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../17-sql/00-sql.html">
   SQL
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/11-database.html">
     Database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/12-relational-structure.html">
     Relational Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/31-data-query.html">
     Data Query
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/33-data-manipulation.html">
     Data Manipulation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../19-miscellaneous/00-miscellaneous.html">
   Miscellaneous
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../19-miscellaneous/11-latex.html">
     LaTeX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19-miscellaneous/13-myst.html">
     MyST Markdown
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../20-algorithms-basics/00-algorithms-basics.html">
   Algorithms Basics
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../21-greedy-algorithms/00-greedy-algorithms.html">
   Greedy Algorithms
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/11-interval-scheduling.html">
     Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/31-huffman-coding.html">
     Huffman Coding
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../23-dynamic-programming/00-dynamic-programming.html">
   Dynamic Programming
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/11-weighted-interval-scheduling.html">
     Weighted Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/13-longest-common-subsequence.html">
     Longest Common Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/15-longest-increasing-subsequence.html">
     Longest Increasing Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/17-largest-sum-subsequence.html">
     Largest Sum Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/31-knapsack.html">
     Minimum Knapsack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/51-chain-matrix-multiplication.html">
     Chain Matrix Multiplication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../25-graph-related/00-graph-related.html">
   Graph Related
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/13-shortest-path.html">
     Shortest Path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/21-minimum-spanning-tree.html">
     Minimum Spanning Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/31-maximum-flow.html">
     Maximum Flow
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../30-ml-basics/00-ml-basics.html">
   Machine Learning Basics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/02-taxonomy.html">
     Taxonomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/03-information-theory.html">
     Information Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/05-kernels.html">
     Kernels
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../31-regression/00-regression.html">
   Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/11-lm-estimation.html">
     Linear Models - Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/12-lm-inference.html">
     Linear Regression - Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/13-lm-extension.html">
     Linear Regression - Extension
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../32-classification/00-classification.html">
   Classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/11-support-vector-machine.html">
     Support Vector Machine
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../33-dimensionality-reduction/00-dimensionality-reduction.html">
   Dimensionality Reduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/11-principal-component-analysis.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/13-canonical-correlation-analysis.html">
     Canonical Corerlation Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/21-multidimensional-scaling.html">
     Multidimensional Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/23-graph-based-spectral-methods.html">
     Graph-based Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/25-kernel-pca.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/31-t-SNE.html">
     SNE and $t$-SNE
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../34-clustering/00-clustering.html">
   Clustering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/11-k-means.html">
     K-means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/13-agglomerative-methods.html">
     Agglomerative Methods
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../37-neural-networks/00-neural-networks.html">
   Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/01-stochastic-gradient-descent.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/03-trainability.html">
     Trainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/05-regularization.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/11-autoencoders.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/13-variational-autoencoders.html">
     Variational Autoencoders
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/12-probabilities/13-correlation-and-dependence.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/dennissxz/data-science-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/dennissxz/data-science-handbook/issues/new?title=Issue%20on%20page%20%2F12-probabilities/13-correlation-and-dependence.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#definitions">
   Definitions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation">
     Correlation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pearson-correlation-coefficient">
       Pearson Correlation Coefficient
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#spearman-correlation-coefficient">
       Spearman Correlation Coefficient
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlated">
     Correlated
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dependence">
     Dependence
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#comparison">
   Comparison
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#independent-rightarrow-uncorrelated">
     Independent $\Rightarrow$ Uncorrelated
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#uncorrelated-not-rightarrow-independent">
     Uncorrelated $\not \Rightarrow$ Independent
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simpson-s-paradox">
   Simpson’s Paradox
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   Exercise
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="correlation-and-dependence">
<h1>Correlation and Dependence<a class="headerlink" href="#correlation-and-dependence" title="Permalink to this headline">¶</a></h1>
<div class="section" id="definitions">
<h2>Definitions<a class="headerlink" href="#definitions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="correlation">
<h3>Correlation<a class="headerlink" href="#correlation" title="Permalink to this headline">¶</a></h3>
<p>The correlation of two random variables measures how two or more variables are related or associated to one another. There are several correlation coefficients, and the most familiar one is Pearson correlation coefficient.</p>
<div class="section" id="pearson-correlation-coefficient">
<h4>Pearson Correlation Coefficient<a class="headerlink" href="#pearson-correlation-coefficient" title="Permalink to this headline">¶</a></h4>
<p>It is defined for two continuous variables $X,Y$ and only measure the <strong>linear relationship</strong> between them.</p>
<p>$$
\rho
= \frac{\operatorname{Cov}\left( X, Y \right)}{\sqrt{\operatorname{Var}\left( X \right)\operatorname{Var}\left( Y \right)}}
= \frac{\sigma_{X,Y}}{\sigma_X \sigma_Y}
= \frac{\mathrm{E}\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]}{\sigma_{X} \sigma_{Y}}
$$</p>
<p>If $X$ and $Y$ are more likely to have values larger or smallerthan their means $\mu_X, \mu_Y$ concurrently, then the product $\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)$ is more likely to be positive, which leads to a positive value of the correlation coefficient. On the other hand, the correlation coefficient is more likely to be negative.</p>
<p>By the Cauchy-Schwarz inequality we have</p>
<p>$$
\left\vert \operatorname{Cov}\left( X,Y \right) \right\vert^2 \le \operatorname{Var}\left( X \right) \operatorname{Var}\left( Y \right)
$$</p>
<p>and hence</p>
<p>$$
-1 \le \rho \le 1
$$</p>
<p>The equality holds iff there is a deterministic linear relation between $X$ and $Y$, $Y = aX + b$.</p>
<p>Given a sample of $n$ observed pairs $(x_i, y_i)$, the sample correlation coefficient is defined as</p>
<p>$$
r_{x y}
= \frac{s_{x,y}}{s_x, s_y}
= \frac{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\sqrt{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2} \sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}}},
$$</p>
<p>or equivalently,</p>
<p>$$
\begin{aligned}
r_{x y} &amp;=\frac{\sum x_{i} y_{i}-n \bar{x} \bar{y}}{n s_{x}^{\prime} s_{y}^{\prime}} \
&amp;=\frac{n \sum x_{i} y_{i}-\sum x_{i} \sum y_{i}}{\sqrt{n \sum x_{i}^{2}-\left(\sum x_{i}\right)^{2}} \sqrt{n \sum y_{i}^{2}-\left(\sum y_{i}\right)^{2}}}
\end{aligned}
$$</p>
</div>
<div class="section" id="spearman-correlation-coefficient">
<h4>Spearman Correlation Coefficient<a class="headerlink" href="#spearman-correlation-coefficient" title="Permalink to this headline">¶</a></h4>
<p>Spearman’s rank correlation is more robust than Pearson’s to capture nonlinear relationships. In fact, it assesses monotonic relationships. For a sample of $n$ scores $X_i, Y_i$, they are first converted to ranks $\operatorname{rg}<em>{X_i}, \operatorname{rg}</em>{Y_i}$, and the Spearman correlation coefficient is defined as the Pearson correlation coefficient between the rank variables.µ</p>
<p>$$
r_{s}=\rho_{\mathrm{rg}<em>{X}, \mathrm{rg}</em>{Y}}=\frac{\operatorname{Cov}\left(\mathrm{rg}<em>{X}, \mathrm{rg}</em>{Y}\right)}{\sigma_{\mathrm{rg}<em>{X}} \sigma</em>{\mathrm{rg}_{Y}}}
$$</p>
<p>If there is <strong>no ties,</strong> then it can be computed by the formula</p>
<p>$$
r_{s}=1-\frac{6 \sum_i d_{i}^{2}}{n\left(n^{2}-1\right)}
$$</p>
<p>where $d_i = \operatorname{rg}<em>{X_i} - \operatorname{rg}</em>{Y_i}$ is the rank difference of each observation.</p>
<p>One can see that</p>
<ul class="simple">
<li><p>If two variables are monotonically related (even if their relationship is not linear), then $d_i = 0$ for all $i$, and therefore $r_s = 1$. For instance, $X\sim U(-1,1), Y=X^3$.</p></li>
<li><p>If two variables are inversely monotonically related, then $d_i = n-1, n-3, \ldots, 3-n, 1-n$ and $\sum_i d_i ^2 = \frac{1}{3} n (n^2-1)$, and therefore $r_s = 1-2 = -1$</p></li>
</ul>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Mutual information can also be applied to measure association between two variables, given their distribution functions.</p>
</div>
</div>
</div>
<div class="section" id="correlated">
<h3>Correlated<a class="headerlink" href="#correlated" title="Permalink to this headline">¶</a></h3>
<p>Two random variables $X,Y$ are said to be</p>
<ul class="simple">
<li><p>correlated if $\operatorname{Cov}\left( X,Y \right) \ne 0$</p></li>
<li><p>uncorrelated if $\operatorname{Cov}\left( X,Y \right) = 0$.</p></li>
</ul>
</div>
<div class="section" id="dependence">
<h3>Dependence<a class="headerlink" href="#dependence" title="Permalink to this headline">¶</a></h3>
<p>Two random variables $X,Y$ are independent iff the joints cumulative distribution function satisfies</p>
<p>$$
F_{X, Y}(x, y)=F_{X}(x) F_{Y}(y) \quad \text{for all}\ x, y
$$</p>
<p>or equivalently, the joint density satisfies</p>
<p>$$
f_{X, Y}(x, y)=f_{X}(x) f_{Y}(y) \quad \text{for all}\ x, y
$$</p>
<p>From this definition we have</p>
<p>$$
f_{X\mid Y}(x\mid y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}  = f_X(x)
$$</p>
<p>which can be interpreted as “knowing any information about $Y=y$ does not change our knowledge of $X$”. If this is false then the two random variables are not independent.</p>
</div>
</div>
<div class="section" id="comparison">
<h2>Comparison<a class="headerlink" href="#comparison" title="Permalink to this headline">¶</a></h2>
<div class="section" id="independent-rightarrow-uncorrelated">
<h3>Independent $\Rightarrow$ Uncorrelated<a class="headerlink" href="#independent-rightarrow-uncorrelated" title="Permalink to this headline">¶</a></h3>
<p>If two random variables are independent, then $\operatorname{E}\left( XY \right) = \operatorname{E}\left( X \right) \operatorname{E}\left( Y \right)$, $\operatorname{Cov}\left( X,Y \right) = 0$, i.e., they are uncorrelated.</p>
</div>
<div class="section" id="uncorrelated-not-rightarrow-independent">
<h3>Uncorrelated $\not \Rightarrow$ Independent<a class="headerlink" href="#uncorrelated-not-rightarrow-independent" title="Permalink to this headline">¶</a></h3>
<p>If $\operatorname{Cov}\left( X,Y \right) = 0$ or $\rho(X,Y) = 0$, then we CAN NOT say they are independent.</p>
<p>For instance, let $X\sim U(-1,1)$ and $Y = \left\vert X \right\vert$. Then $Y$ is completely dependent on $X$, but</p>
<p>$$\begin{align}
\operatorname{Cov}\left( X, Y \right)<br />
&amp;= \operatorname{E}\left( XY \right) - \operatorname{E}\left( X \right) \operatorname{E}\left( Y \right)   \
&amp;= \operatorname{E}\left( X \left\vert X \right\vert \right) - \operatorname{E}\left( X \right) \operatorname{E}\left( \left\vert X \right\vert \right)\
&amp;= \operatorname{E}\left( X^2 \right)\cdot \frac{1}{2} + \operatorname{E}\left( -X^2 \right)\cdot \frac{1}{2} - 0 \cdot \frac{1}{2} \
&amp; = 0
\end{align}$$</p>
<p>so that $\rho(X,Y) = 0$</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p>One special case is bivariate normal distribution. If two variables $X,Y$ follows a bivariate normal distribution, then $\operatorname{Cov}\left( X,Y \right) = 0$ implies their independence. However, this does not hold for two arbitrary normal variables. See __.</p></li>
<li><p>For two random variables, if their mutual information is 0, then they are independent. See __.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="simpson-s-paradox">
<h2>Simpson’s Paradox<a class="headerlink" href="#simpson-s-paradox" title="Permalink to this headline">¶</a></h2>
<p>We have talked about the dependence between two random variables, which says that the information of a random variable $X$ depends on the information of another variable $Y$. In fact, here “the information of $X$” can be generalized to any probablistic objects, such as</p>
<ul class="simple">
<li><p>the distribution of a random vector $\boldsymbol{X}=\left[ X_1, \ldots, X_2 \right]$</p></li>
<li><p>the correlation of two random variables $\mathrm{Corr}\left( X_1, X_2 \right)$</p></li>
<li><p>some statistical conclusions.</p></li>
</ul>
<p>Simpson’s Paradox refers to this case. It is a phenomenon in probability and statistics, in which a trend appears in several different groups of data but disappears or reverses when these groups are combined.</p>
<p>The cause of Simpson’s paradox is the existence of a confounding variable, which has dependence with the observed variables.</p>
<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/f/fb/Simpsons_paradox_-_animation.gif" width="50%" align="center"/>
</p>
<p>Mathematically, if the trends are correlations, it can be formulated as</p>
<p>$$\mathrm{Corr}(X,Y,\vert, Z) &gt; 0 \not \Rightarrow \mathrm{Corr}(X,Y) &gt; 0$$</p>
<p>where $Z$ is a confounding variable.</p>
<p>If the trends are proportions, we can illustrate them with vectors. In the below case, for a vector $v$, suppose the angle between it and the $x$-axis is $\theta$. The horizontal projection $\vert \overrightarrow{v}\cos\theta\vert$ is the number of applicants and the vertical projection $\vert \overrightarrow{v}\sin\theta\vert$ is the number of accepted candidates. A steeper vector then represents a larger acceptance rate.</p>
<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/c/cd/Simpsons_paradox.jpg" width="50%" />
</p>
<p>The Simpson’s paradox says that, even if $\overrightarrow{L_{1}}$ has a smaller slope than $\overrightarrow{B_{1}}$ and $\overrightarrow{L_{2}}$ has a smaller slope than $\overrightarrow{B_{2}}$, the overall slop $\overrightarrow{L_{1}} + \overrightarrow{L_{2}}$ can be greater than $\overrightarrow{B_{1}}+\overrightarrow{B_{2}}$. For this to occur, one of the orange vectos must have a greater slope than one of the blue vectors (e.g. $\overrightarrow{L_{2}}$ vs. $\overrightarrow{B_{1}}$), and these will generally be <strong>longer</strong> than the alternatively subscripted vectors (i.e. imbalanced data) – thereby dominating the overall comparison.</p>
<p align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Simpson_paradox_vectors.svg/1200px-Simpson_paradox_vectors.svg.png" width="50%">
</p>
</div>
<div class="section" id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>(Raining, Tags: Jane Street, Quant, 20Q4)</p>
<p><em>Suppose the probabilities of raining on Saturday and Sunday are $p$ and $q$ respectively. What is the probability of raining on weekend? What is the probability that it rains on either Saturday or Sunday?</em></p>
<p>:::{admonition,dropdown,seealso} <em>Proof</em></p>
<p>Note that the question does not specify the dependence of raining on Saturday and Sunday. To be rigorous, we introduce two indicator variables</p>
<p>$$\begin{align}
X &amp;= \mathbb{I}[\text{raining on Saturday}] \
Y &amp;= \mathbb{I}[\text{raining on Sunday}] \
\end{align}$$</p>
<p>Hence</p>
<p>$$\begin{align}
\mathrm{P}(X=1) &amp;= p\
\mathrm{P}(Y=1) &amp;= q\
\end{align}$$</p>
<p>Suppose $\mathrm{P}(X=1, Y=1)=a$, then the contingency table is</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>$X \ \backslash \ Y$</p></th>
<th class="text-align:center head"><p>$0$</p></th>
<th class="text-align:center head"><p>$1$</p></th>
<th class="text-align:center head"><p>total</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>$0$</p></td>
<td class="text-align:center"><p>$1-p-q+a$</p></td>
<td class="text-align:center"><p>$q-a$</p></td>
<td class="text-align:center"><p>$1-p$</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>$1$</p></td>
<td class="text-align:center"><p>$p-a$</p></td>
<td class="text-align:center"><p>$a$</p></td>
<td class="text-align:center"><p>$p$</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>total</p></td>
<td class="text-align:center"><p>$1-q$</p></td>
<td class="text-align:center"><p>$q$</p></td>
<td class="text-align:center"><p>$1$</p></td>
</tr>
</tbody>
</table>
<p>Note that there are constraints on $a$:</p>
<p>$$\begin{align}
1-p-q+a &amp;\ge 0 \
p-a &amp; \ge 0 \
q-a &amp; \ge 0
\end{align}$$</p>
<p>So we can obtain the valid range for $a$:</p>
<p>$$\max(p+q-1,0) \le a \le \min(p,q)$$</p>
<p>The required answer is</p>
<p>$$\begin{align}
p_1&amp;= \mathrm{P}(\text{raining on weekend})  \
&amp; = 1 - \mathrm{P}(X=0, Y=0)  \
&amp; = p+q-a \
&amp; \in [\max(p,q), \min(p+q,1)] \
p_2 &amp;= \mathrm{P}(\text{raining on either Saturday or Sunday})  \
&amp; = \mathrm{P}(X=1, Y=0) + \mathrm{P}(X=0, Y=1)  \
&amp; = p+q-2a \
&amp; \in [\vert p-q\vert, \min(p+q, 2-p-q)]
\end{align}$$</p>
<p>:::</p>
</li>
<li><p>(Expected Value of the Maximum of Two Uniform Random Variables)</p>
<p><em>Suppose $X$ and $Y$ are two uniformly distributed random variables over the interval $[0,1]$. What is the expected value $\mathrm{E}[\max(X,Y)]$?</em></p>
<p>:::{admonition,dropdown,seealso} <em>Proof</em></p>
<p>Let $Z=\max(X,Y)$. Since there is no dependence specified, we start from the special cases.</p>
<ul>
<li><p>If $X$ and $Y$ are independent, then</p>
<p>$$\begin{align}
\mathrm{P}(Z\le z) &amp;= \mathrm{P}(\max (X, Y) \le z) \
&amp;=\mathrm{P}(X \leqslant z) \mathrm{P}(Y \leqslant z) \
&amp;= z^2 \
\mathrm{E}(Z) &amp;= \int_{0}^{1}\mathrm{P}(Z\ge z)\mathrm{d}z \
&amp;= \int_{0}^{1}\left(1-z^{2}\right) \mathrm{d}z \
&amp;=\frac{2}{3}
\end{align}$$</p>
<p>Another way without finding the cumulative distribution function $\mathrm{P}\left( Z\le z \right)$:</p>
<p>$$
\begin{aligned}
\mathrm{E}(\max (x, y)) &amp;=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \max (x, y) p(x, y) ,\mathrm{d}x ,\mathrm{d}y \
&amp;=\int_{0}^{1} \int_{0}^{1} \max (x, y) ,\mathrm{d}x ,\mathrm{d}y \
&amp;=\int_{0}^{1} \int_{0}^{x} x ,\mathrm{d}y ,\mathrm{d}x+\int_{0}^{1} \int_{0}^{y} y ,\mathrm{d}x ,\mathrm{d}y \
&amp;=\int_{0}^{1} x^{2} ,\mathrm{d}x+\int_{0}^{1} y^{2} ,\mathrm{d}y \
&amp;=\left[\frac{x^{3}}{3}\right]<em>{0}^{1}+\left[\frac{y^{3}}{3}\right]</em>{0}^{1} \
&amp;=\frac{1}{3}+\frac{1}{3} \
&amp;=\frac{2}{3}
\end{aligned}
$$</p>
<p>In particular, for $n$ independent uniform random variables,</p>
<p>$$\begin{align}
\mathrm{E}(Z) &amp;= \int_{0}^{1}\mathrm{P}(Z\ge z)\mathrm{d}z\
&amp;= \int_{0}^{1}\left(1-z^{n}\right) \mathrm{d}z\
&amp;= \frac{n}{n+1}\
\end{align}$$</p>
</li>
<li><p>If $X$ and $Y$ has the relation $X=Y$, then</p>
<p>$$\mathrm{E}(Z)=\mathrm{E}(X)=\frac{1}{2}$$</p>
<p>In this case</p>
<p>$$\begin{align}
\mathrm{Corr}\left( X,Y \right) &amp;= \frac{\mathrm{Cov}\left( X,Y \right)}{\sqrt{\mathrm{Var}\left( X \right)\mathrm{Var}\left( Y \right)}} \
&amp;= \frac{\mathrm{Cov}\left( X,X \right)}{\sqrt{\mathrm{Var}\left( X \right)\mathrm{Var}\left( X \right)}} \
&amp;= \frac{\mathrm{Var}\left( X \right)}{\mathrm{Var}\left( X \right)}\
&amp;= 1
\end{align}$$</p>
</li>
<li><p>If $X$ and $Y$ has the relation $X+Y=1$, then by the law of total expectation</p>
<p>$$\begin{align}
\mathrm{E}(Z) &amp;=\mathrm{E}[\mathrm{E}(Z ,\vert, X)]\
&amp;=\mathrm{\mathrm{P}\left( X\le \frac{1}{2} \right)} \cdot \mathrm{E}\left( 1-X,\vert, X\le \frac{1}{2}  \right) + \mathrm{P}\left( X&gt; \frac{1}{2} \right) \cdot \mathrm{E}\left( X,\vert, X &gt; \frac{1}{2}\right)\
&amp;= \frac{1}{2} \times \frac{3}{4}  + \frac{1}{2} \times \frac{3}{4}  \
&amp;=\frac{3}{4}
\end{align}$$</p>
<p>In this case</p>
<p>$$\begin{align}
\mathrm{Corr}\left( X,Y \right) &amp;= \frac{\mathrm{Cov}\left( X,Y \right)}{\sqrt{\mathrm{Var}\left( X \right)\mathrm{Var}\left( Y \right)}} \
&amp;= \frac{\mathrm{Cov}\left( X,1-X \right)}{\sqrt{\mathrm{Var}\left( X \right)\mathrm{Var}\left( 1-X \right)}} \
&amp;= \frac{\mathrm{-Var}\left( X \right)}{\mathrm{Var}\left( X \right)}\
&amp;= - 1
\end{align}$$</p>
</li>
</ul>
<p>It seems that the range is $[\frac{1}{2}, \frac{3}{4}]$.</p>
<p>:::</p>
</li>
<li><p>(Lower Bound of Correlation for IID)</p>
<p><em>Suppose $X_1, X_2, \ldots, X_n$ where $n\ge 2$ are IID variables with common pairwise correlation $\rho = \operatorname{Corr}\left( X_i, X_j \right)$ for $i\ne j$. What is the lower bound of $r$ and when is it obtained?</em></p>
<p>:::{admonition,dropdown,seealso} <em>Proof</em></p>
<p>Since</p>
<p>$$\begin{align}
\operatorname{Var}\left( \sum_i X_i \right)
&amp;= \sum_i \operatorname{Var}\left( X_i \right) + \sum_{i=1}^n \sum_{j\ne i}^n \operatorname{Cov}\left( X_i, X_j \right) \
&amp;= n \sigma^2 + n(n-1)\rho\sigma^2 \
\ge 0 \
\end{align}$$</p>
<p>we have</p>
<p>$$
\rho \ge - \frac{1}{n-1}
$$</p>
<p>if $\sigma^2 &gt; 0$, otherwise $\rho$ is undefined.</p>
<p>The lower bound is obtained iff $\operatorname{Var}\left( \sum_i X_i \right) = 0$, i.e., $\sum_i X_i = \text{constant}$ almost surely.</p>
<p>:::</p>
</li>
<li><p><em>For three variables $X,Y,Z$, is it possible that $\operatorname{Cov}\left( X,Y \right) \ne 0, \operatorname{Cov}\left( Y, Z \right) \ne 0$ but $\operatorname{Cov}\left( X, Z \right) = 0$?</em></p>
<p>:::{admonition,dropdown,seealso} <em>Solution</em></p>
<p>Consider the correlation matrix</p>
<p>$$
\boldsymbol{C} = \left[\begin{array}{ccc}
1 &amp; a &amp; 0\
a &amp; 1 &amp; b\
0 &amp; b &amp; 1
\end{array}\right]
$$</p>
<p>Since it is positive semi definite, we must have</p>
<p>$$
\operatorname{det}(\boldsymbol{C}) = (1) - (a^2 + b^2) \ge 0
$$</p>
<p>which has infinite many solutions $(a,b)$.</p>
<p>:::</p>
</li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./12-probabilities"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="11-expectation-and-variance.html" title="previous page">Expectation and Variance</a>
    <a class='right-next' id="next-link" href="31-bayesian-theorem.html" title="next page">Bayesian’s Theorem</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dennis Zheng<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>