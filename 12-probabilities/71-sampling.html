
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Sampling &#8212; Data Science Handbook</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multivariate Notations" href="90-multivariate-notations.html" />
    <link rel="prev" title="Markov Chain" href="51-markov-chain.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Data Science Handbook</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Data Science Handbook
  </a>
 </li>
</ul>
<p>
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11-math/00-math.html">
   Math
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/11-combinatorics.html">
     Combinatorics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/20-vector-spaces.html">
     Vector Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/31-geometry.html">
     Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/21-linear-algebra.html">
     Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/51-linear-programming.html">
     Linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/52-non-linear-programming.html">
     Non-linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/90-puzzles.html">
     Puzzles
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="00-probabilities.html">
   Probabilities
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="11-expectation-and-variance.html">
     Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-correlation-and-dependence.html">
     Correlation and Dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="31-bayesian-theorem.html">
     Bayesian’s Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="51-markov-chain.html">
     Markov Chain
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="90-multivariate-notations.html">
     Multivariate Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="91-exponential-families.html">
     Exponential Families
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="91-large-sample-theory.html">
     Large Sample Theory
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../13-statistics/00-statistics.html">
   Statistics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/11-sample-survey.html">
     Sample Survey
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/13-randomized-trial.html">
     Randomized Controlled Trials
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/21-hypothesis-testing.html">
     Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/25-two-sample-tests.html">
     Two Sample Mean Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/33-confusion-matrix.html">
     Confusion Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/41-maximum-likelihood-estimation.html">
     Maximum Likelihood Estimator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/43-estimators-evaluation.html">
     Estimators Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../14-python/00-python.html">
   Python
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/11-programming-tools.html">
     Programmer tools
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/12-syntax.html">
     Syntax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/13-data-structure.html">
     Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../14-python/15-functional-programming.html">
     Functional Programming
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../17-sql/00-sql.html">
   SQL
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/11-database.html">
     Database
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/12-relational-structure.html">
     Relational Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/31-data-query.html">
     Data Query
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../17-sql/33-data-manipulation.html">
     Data Manipulation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../19-miscellaneous/00-miscellaneous.html">
   Miscellaneous
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../19-miscellaneous/11-latex.html">
     LaTeX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19-miscellaneous/13-myst.html">
     MyST Markdown
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p>
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../20-algorithms-concepts/00-algorithms-concepts.html">
   Algorithms Concepts
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/51-polynomial-reduction.html">
     Polynomial Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/53-P-and-NP.html">
     <span class="math notranslate nohighlight">
      \(P\)
     </span>
     and
     <span class="math notranslate nohighlight">
      \(NP\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/61-randomized-algo.html">
     Randomized Algorithms
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../21-greedy-algorithms/00-greedy-algorithms.html">
   Greedy Algorithms
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/11-interval-scheduling.html">
     Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/31-huffman-coding.html">
     Huffman Coding
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../23-dynamic-programming/00-dynamic-programming.html">
   Dynamic Programming
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/11-weighted-interval-scheduling.html">
     Weighted Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/13-longest-common-subsequence.html">
     Longest Common Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/15-longest-increasing-subsequence.html">
     Longest Increasing Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/17-largest-sum-subsequence.html">
     Largest Sum Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/31-knapsack.html">
     Minimum Knapsack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/51-chain-matrix-multiplication.html">
     Chain Matrix Multiplication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../25-graph-related/00-graph-related.html">
   Graph Related
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/13-shortest-path.html">
     Shortest Path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/21-minimum-spanning-tree.html">
     Minimum Spanning Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/31-maximum-flow.html">
     Maximum Flow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/32-matching.html">
     Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/42-maximum-independent-set.html">
     Maximum Independent Set in Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/91-LP-max-flow-min-cut.html">
     LP on Max-flow and Min-cut
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../26-algo-for-big-data/00-algo-for-big-data.html">
   For Big Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../26-algo-for-big-data/10-streaming.html">
     Streaming Model
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p>
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../30-ml-basics/00-ml-basics.html">
   Machine Learning Basics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/02-taxonomy.html">
     Taxonomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/03-information-theory.html">
     Information Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/05-kernels.html">
     Kernels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/11-data-issues.html">
     Data Issues
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/51-semi-supervised.html">
     Semi-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/53-self-supervised.html">
     Self-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/61-fourier-transform.html">
     Fourier Transform-based Representations
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../31-regression/00-regression.html">
   Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/11-lm-estimation.html">
     Linear Models - Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/12-lm-inference.html">
     Linear Models - Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/13-lm-diagnosis.html">
     Linear Models - Diagnosis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/14-lm-advanced.html">
     Linear Models - Advanced Topics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/21-generalized-linear-models.html">
     Generalized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/22-logistic-regression.html">
     Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/23-multinomial-logitsitc.html">
     Multinomial Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/24-ordinal-logistic.html">
     Ordinal Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/25-poisson-regression.html">
     Poisson Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../32-classification/00-classification.html">
   Classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/11-support-vector-machine.html">
     Support Vector Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/21-decision-tree.html">
     Decision Tree
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../33-dimensionality-reduction/00-dimensionality-reduction.html">
   Dimensionality Reduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/11-principal-component-analysis.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/13-canonical-correlation-analysis.html">
     Canonical Corerlation Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/21-multidimensional-scaling.html">
     Multidimensional Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/23-graph-based-spectral-methods.html">
     Graph-based Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/25-t-SNE.html">
     SNE and
     <span class="math notranslate nohighlight">
      \(t\)
     </span>
     -SNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/31-kernel-pca.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/32-kernel-cca.html">
     Kernel CCA
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../34-clustering/00-clustering.html">
   Clustering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/11-k-means.html">
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/13-agglomerative-methods.html">
     Agglomerative Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/31-spectral-clustering.html">
     Spectral Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/41-gaussian-mixtures.html">
     Gaussian Mixtures
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../35-graphical-models/00-graphical-models.html">
   Graphical Models
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/03-random-walks.html">
     Random Walks in Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/11-hidden-markov-models.html">
     Hidden Markov Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/31-topic-models.html">
     Topic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/33-language-models.html">
     Language Models
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../37-neural-networks/00-neural-networks.html">
   Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/01-stochastic-gradient-descent.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/03-trainability.html">
     Trainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/05-regularization.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/11-autoencoders.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/13-variational-autoencoders.html">
     Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/31-sequential-models.html">
     Sequential Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/41-GAN.html">
     Generative Adversarial Networks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../38-ml-for-graph-data/00-ml-for-graph-data.html">
   For Graph-structured Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/01-graph-basics.html">
     Graph Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/11-descriptive-analysis.html">
     Descriptive Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/13-sampling-and-estimation.html">
     Sampling and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/21-modeling.html">
     Modeling
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/12-probabilities/71-sampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/12-probabilities/71-sampling.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/dennissxz/data-science-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/dennissxz/data-science-handbook/issues/new?title=Issue%20on%20page%20%2F12-probabilities/71-sampling.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/dennissxz/data-science-handbook/master?urlpath=tree/12-probabilities/71-sampling.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimation-of-mean-and-total">
   Estimation of Mean and Total
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#equal-probability-sampling">
     Equal Probability Sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#with-replacement">
       With Replacement
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#without-replacement">
       Without Replacement
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unequal-probability-sampling">
     Unequal Probability Sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#horvitz-thompson-estimate">
       Horvitz-Thompson Estimate
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       With Replacement
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimation-of-group-size-and-species">
   Estimation of Group Size and Species
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#group-size">
     Group Size
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#group-species">
     Group Species
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#monte-carlo">
   Monte Carlo
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rejection-sampling">
   Rejection Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#markov-chain-monte-carlo">
   Markov Chain Monte Carlo
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#general-setting">
     General Setting
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metropolis-hastings">
     Metropolis Hastings
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gibbs-sampling">
   Gibbs Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#others">
   Others
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#poisson-sampling">
     Poisson Sampling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bernoulli-sampling">
     Bernoulli Sampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise">
   Exercise
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sampling-from-a-triangle">
     Sampling from a Triangle
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section id="sampling">
<h1>Sampling<a class="headerlink" href="#sampling" title="Permalink to this headline">¶</a></h1>
<p>In this section we introduce some some sampling methods for various problem settings. Suppose we generate a sample <span class="math notranslate nohighlight">\(\left\{ x_1, x_2, \ldots, x_n \right\}\)</span> from some distribution <span class="math notranslate nohighlight">\(p(x)\)</span>.</p>
<p>If the exact functional form of <span class="math notranslate nohighlight">\(p(x)\)</span> is unknown or hard to obtain, but we know some function <span class="math notranslate nohighlight">\(f(x)\)</span> that is proportional to <span class="math notranslate nohighlight">\(p(x)\)</span> up to some normalizing constant, then we can use <span class="math notranslate nohighlight">\(f(x)\)</span> to obtain the sample. Some methods include</p>
<ul class="simple">
<li><p>Rejection sampling</p></li>
<li><p>Markov Chain Monte Carlo</p>
<ul>
<li><p>Metropolis Hastings</p></li>
</ul>
</li>
</ul>
<p>For multivariate distributions, e.g. <span class="math notranslate nohighlight">\(d=2\)</span>, if we want to generate a sample <span class="math notranslate nohighlight">\(\left\{ (x_1, y_1), \ldots, (x_n, y_n) \right\}\)</span> from unknown <span class="math notranslate nohighlight">\(p(x,y)\)</span>, and <span class="math notranslate nohighlight">\(f(x \vert y )\propto p(x\vert y)\)</span> and <span class="math notranslate nohighlight">\(f(y \vert x )\propto p(x\vert y)\)</span> are known, then we can use <span class="math notranslate nohighlight">\(f(x \vert y)\)</span> and <span class="math notranslate nohighlight">\(f(y \vert x)\)</span> to obtain the sample. Gibbs sampling solve this problem setting.</p>
<section id="estimation-of-mean-and-total">
<span id="estimation-mean-total"></span><h2>Estimation of Mean and Total<a class="headerlink" href="#estimation-of-mean-and-total" title="Permalink to this headline">¶</a></h2>
<p>Setup</p>
<ul class="simple">
<li><p>a population <span class="math notranslate nohighlight">\(U = \left\{ 1, \ldots, N_u \right\}\)</span> of <span class="math notranslate nohighlight">\(N_u\)</span> units, e.g. people, animals</p></li>
<li><p>a value <span class="math notranslate nohighlight">\(y_i\)</span> for each <span class="math notranslate nohighlight">\(i \in U\)</span>, e.g. height, age</p></li>
<li><p><span class="math notranslate nohighlight">\(\tau = \sum_{i \in U} y_i\)</span> is the total, and <span class="math notranslate nohighlight">\(\mu = \frac{\tau}{N_u}\)</span> is the average, of <span class="math notranslate nohighlight">\(y\)</span>’s in the population</p></li>
<li><p><span class="math notranslate nohighlight">\(S = \left\{ i_1, \ldots, i_n \right\}\)</span> is a sample of <span class="math notranslate nohighlight">\(n\)</span> units from <span class="math notranslate nohighlight">\(U\)</span>, and we can observe <span class="math notranslate nohighlight">\(y_i\)</span> for each <span class="math notranslate nohighlight">\(i \in S\)</span>.</p></li>
</ul>
<p>Estimation of population total <span class="math notranslate nohighlight">\(\tau\)</span> or average <span class="math notranslate nohighlight">\(\mu\)</span> from a random sample is an ubiquitous task.</p>
<section id="equal-probability-sampling">
<h3>Equal Probability Sampling<a class="headerlink" href="#equal-probability-sampling" title="Permalink to this headline">¶</a></h3>
<section id="with-replacement">
<h4>With Replacement<a class="headerlink" href="#with-replacement" title="Permalink to this headline">¶</a></h4>
<p>Consider a sample <span class="math notranslate nohighlight">\(S\)</span> uniformly from <span class="math notranslate nohighlight">\(U\)</span> with replacement, then we have unbiased estimates</p>
<div class="math notranslate nohighlight">
\[
\hat{\mu} = \frac{1}{n} \sum_{i \in S}  y_i \quad \hat{\tau} = N_u \bar{y}
\]</div>
<p>with variance</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Var}\left( \hat{\mu} \right) = \frac{\sigma^2}{n}  \quad \operatorname{Var}\left( \hat{\tau} \right) =  \frac{N_u^2\sigma^2}{n}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the population variance, which can be estimates by <span class="math notranslate nohighlight">\(s^2 = \frac{1}{n-1} \sum_{i \in S} (y_i - \bar{y})^2\)</span>.</p>
</section>
<section id="without-replacement">
<h4>Without Replacement<a class="headerlink" href="#without-replacement" title="Permalink to this headline">¶</a></h4>
<p>Now consider sampling without replacement. The inclusion probability of unit <span class="math notranslate nohighlight">\(i\)</span> in a sample of size <span class="math notranslate nohighlight">\(n\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\pi_i = \frac{\binom{N_u - 1}{n-1} }{\binom{N_u}{n} } = \frac{n}{N_u}
\]</div>
<p>Similarly, let <span class="math notranslate nohighlight">\(\pi_{ij}\)</span> be the probability that units <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> are both in the sample <span class="math notranslate nohighlight">\(S\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
\pi_{ij} = \frac{n(n-1)}{N_u(N_u - 1) }
\]</div>
<p>The unbiased estimates of the mean and total have the same form</p>
<div class="math notranslate nohighlight">
\[
\hat{\tau}_\pi = N_u \bar{y} \quad \hat{\mu}_\pi =  \bar{y}
\]</div>
<p>but smaller variance</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Var}\left( \hat{\mu}_\pi \right) = \frac{N_u - n}{N_u } \frac{ \sigma^2 }{n} &lt; \frac{\sigma^2 }{n}   \quad \operatorname{Var}\left( \hat{\tau}_\pi \right) = \frac{N_u (N_u - n) \sigma^2 }{n} &lt; \frac{N_u ^2 \sigma^2 }{n}  
\]</div>
</section>
</section>
<section id="unequal-probability-sampling">
<h3>Unequal Probability Sampling<a class="headerlink" href="#unequal-probability-sampling" title="Permalink to this headline">¶</a></h3>
<p>In many situations, some units are more likely than others to be included in a sample, either by design or by accident, e.g. interviewing people on a street, locating homeless vs homeowners, etc. Sampling under designs of this sort is called <strong>unequal</strong> probability sampling.</p>
<p>In this setting, the sample mean is a biased estimator for <span class="math notranslate nohighlight">\(\mu\)</span>. The Horvitz-Thompson estimator remedies this problem. Note that the Horvitz-Thompson estimator does not depend on the number of times a unit may be selected. Each distinct unit of the sample is utilized only once. We first consider sampling without replacement such that all units in <span class="math notranslate nohighlight">\(S\)</span> is distinct.</p>
<section id="horvitz-thompson-estimate">
<h4>Horvitz-Thompson Estimate<a class="headerlink" href="#horvitz-thompson-estimate" title="Permalink to this headline">¶</a></h4>
<p>Suppose that each unit <span class="math notranslate nohighlight">\(i \in U\)</span> has probability <span class="math notranslate nohighlight">\(\pi_i\)</span> of being included in a sample <span class="math notranslate nohighlight">\(S\)</span> of size <span class="math notranslate nohighlight">\(n\)</span>. The Horvitz-Thompson estimate of <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\mu\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\hat{\tau}_\pi = \sum_{i \in S} \frac{y_i}{\pi_i} \quad \hat{\mu}_\pi = \frac{1}{N_u}  \hat{\tau}_\pi
\]</div>
<p>the estimator <span class="math notranslate nohighlight">\(\hat{\tau}_\pi\)</span> is unbiased since</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\left(\hat{\tau}_{\pi}\right)=\mathbb{E}\left(\sum_{i \in S} \frac{y_{i}}{\pi_{i}}  \right)=\mathbb{E}\left(\sum_{i \in {U}}\frac{y_{i}}{\pi_{i}} Z_i\right)=\sum_{i \in {U}} \frac{y_{i}}{\pi_{i}} \mathbb{E}\left(Z_{i}\right) = \tau
\]</div>
<p>where <span class="math notranslate nohighlight">\(Z_i = 1\)</span> if <span class="math notranslate nohighlight">\(i \in S\)</span> and zero otherwise, hence <span class="math notranslate nohighlight">\(\mathbb{E}\left( Z_i \right) = \mathbb{P}\left( Z_i = 1 \right) = \pi_i\)</span>.</p>
<p>To find the variance of this estimator, use the indicator variable approach, we obtain</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathbb{V}\left(\hat{\tau}_{\pi}\right)
&amp;= \operatorname{Cov} \left(\sum_{i \in {U}}\frac{y_{i}}{\pi_{i}} Z_i, \sum_{i \in {U}}\frac{y_{i}}{\pi_{i}} Z_i\right) \\
&amp;= \sum_{i\in U}\left(\frac{1-\pi_{i}}{\pi_{i}}\right) y_{i}^{2}+\sum_{i\in U}\sum_{j \neq i}\left(\frac{\pi_{i j}-\pi_{i} \pi_{j}}{\pi_{i} \pi_{j}}\right) y_{i} y_{j} \\
&amp;=\sum_{i \in U} \sum_{j \in U} y_{i} y_{j}\left(\frac{\pi_{i j}}{\pi_{i} \pi_{j}}-1\right) \quad \text{$\pi_{ij} = \pi_i$ when $i = j$.}
\end{aligned}\end{split}\]</div>
<p>An unbiased estimator for this is</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\widehat{\mathbb{V}}\left(\hat{\tau}_{\pi}\right)
&amp;= \sum_{i\in S}\left(\frac{1-\pi_{i}}{\pi_{i}^{2}}\right) y_{i}^{2}+\sum_{i\in S} \sum_{j \neq i}\left(\frac{\pi_{i j}-\pi_{i} \pi_{j}}{\pi_{i} \pi_{j}}\right) \frac{1}{\pi_{i j}} y_{i} y_{j} \\
&amp;=\sum_{i \in S} \sum_{j \in S} y_{i} y_{j}\left(\frac{1}{\pi_{i} \pi_{j}}-\frac{1}{\pi_{i j}}\right)
\end{aligned}\end{split}\]</div>
<p>assuming <span class="math notranslate nohighlight">\(\pi_{ij} &gt; 0\)</span> for all pairs <span class="math notranslate nohighlight">\((i, j)\)</span>. In particular, if the inclusion of units <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> are independent, then <span class="math notranslate nohighlight">\(\pi_{ij} = \pi_i \pi_j\)</span>, and only diagonal term <span class="math notranslate nohighlight">\((i=j)\)</span> remains in the above two quantities.</p>
<p>An approximate <span class="math notranslate nohighlight">\((1-\alpha)\)</span> 100% confidence interval for <span class="math notranslate nohighlight">\(\tau\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\hat{\tau}_{\pi} \pm t_{\alpha / 2} \sqrt{ \hat{\mathbb{V}}\left(\hat{\tau}_{\pi}\right)}
\]</div>
<p>The two analogous quantities for estimator <span class="math notranslate nohighlight">\(\hat{\mu}_\pi\)</span> are</p>
<div class="math notranslate nohighlight">
\[
\mathbb{V}\left(\hat{\mu}_{\pi}\right)=\frac{1}{N_u^2}  \mathbb{V}\left(\hat{\tau}_{\pi}\right) \quad  \mathbb{V}\left(\hat{\mu}_{\pi}\right)=\frac{1}{N_u^2}  \widehat{\mathbb{V}}\left(\hat{\tau}_{\pi}\right)
\]</div>
</section>
<section id="id1">
<h4>With Replacement<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Now we consider sampling with replacement. We first obtain a sample <span class="math notranslate nohighlight">\(S\)</span> of size <span class="math notranslate nohighlight">\(n\)</span>, then find a set <span class="math notranslate nohighlight">\(S^*\)</span> of distinct units from <span class="math notranslate nohighlight">\(S\)</span>, and use <span class="math notranslate nohighlight">\(S^*\)</span> to compute the Horvitz-Thompson estimates.</p>
<p>Let <span class="math notranslate nohighlight">\(p_i\)</span> be the probability of being selected in each of the <span class="math notranslate nohighlight">\(n\)</span> times for <span class="math notranslate nohighlight">\(i \in U\)</span>. It is easy to see that the inclusion probability in <span class="math notranslate nohighlight">\(S^*\)</span> (or equivalently, sample <span class="math notranslate nohighlight">\(S\)</span>) are</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\pi_i
&amp;= 1 - (1-p_i)^n\\
\pi_{ij}
&amp; = \mathbb{P}\left( i \in S \right) + \mathbb{P}\left( j \in S \right) - \mathbb{P}\left( i,j \in S \right) \\
&amp;= \pi_i + \pi_j - [1 - (1-p_i - p_j)^n]
\end{aligned}\end{split}\]</div>
<p>Horvitz-Thompson estimators can be computed with these values.</p>
<p>If <span class="math notranslate nohighlight">\(p_i\)</span> is directly proportional to the values <span class="math notranslate nohighlight">\(c_i\)</span> of some characteristic of <span class="math notranslate nohighlight">\(i\)</span>, i.e., <span class="math notranslate nohighlight">\(p_i = \frac{c_i}{\sum c_i}\)</span> we call this <strong>probability proportional to size</strong> (PPS) sampling. For instance, households might be selected for a marketing survey by drawing names from a database, in which case those households with more members in the database have a larger chance of being included.</p>
</section>
</section>
</section>
<section id="estimation-of-group-size-and-species">
<h2>Estimation of Group Size and Species<a class="headerlink" href="#estimation-of-group-size-and-species" title="Permalink to this headline">¶</a></h2>
<section id="group-size">
<h3>Group Size<a class="headerlink" href="#group-size" title="Permalink to this headline">¶</a></h3>
<p>The estimation of group total <span class="math notranslate nohighlight">\(\tau\)</span> above usually involve <span class="math notranslate nohighlight">\(N_u\)</span>, but often <span class="math notranslate nohighlight">\(N_u\)</span> is unknown, e.g. populations of endangered animal species. One method to estimate <span class="math notranslate nohighlight">\(N_u\)</span> is the class of <strong>capture-recapture</strong> estimators. The simplest version involves two stages</p>
<ol class="simple">
<li><p>Select a simple random sample <span class="math notranslate nohighlight">\(S_1\)</span> of size <span class="math notranslate nohighlight">\(n_1\)</span> without replacement, mark all units in <span class="math notranslate nohighlight">\(S_1\)</span>, and return then to the population</p></li>
<li><p>Select a simple random sample <span class="math notranslate nohighlight">\(S_2\)</span> of size <span class="math notranslate nohighlight">\(n_2\)</span> without replacement, the value</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
  \hat{N}_u^{(c/r)} = \frac{n_2}{m} n_1
  \]</div>
<p>is then used as an estimate of <span class="math notranslate nohighlight">\(N_u\)</span>, where <span class="math notranslate nohighlight">\(m = \left\vert S_1 \cap S_2 \right\vert\)</span> is the number of marked units in <span class="math notranslate nohighlight">\(S_2\)</span>. An estimator of the variance is</p>
<div class="math notranslate nohighlight">
\[
\widehat{V}\left(\hat{N}_{u}^{(c / r)}\right)=\frac{n_{1} n_{2}\left(n_{1}-m\right)\left(n_{2}-m\right)}{m^{3}}
\]</div>
<p>If <span class="math notranslate nohighlight">\(n_1\)</span> and <span class="math notranslate nohighlight">\(n_2\)</span> are fixed, then <span class="math notranslate nohighlight">\(m\)</span> follows a hypergeometric distribution, and the integer part of <span class="math notranslate nohighlight">\(\hat{N}_u^{(c/r)}\)</span> corresponds to MLE of <span class="math notranslate nohighlight">\(N_u\)</span>.</p>
</section>
<section id="group-species">
<h3>Group Species<a class="headerlink" href="#group-species" title="Permalink to this headline">¶</a></h3>
<p>Aka species problem. Suppose there <span class="math notranslate nohighlight">\(N_s\)</span> number of species in the forest, how to estimate <span class="math notranslate nohighlight">\(N_s\)</span>? Similar problems include how many words did Shakespeare know based on his published works, and how many kinds of ancient coins minted by a society based on archaeological finds.</p>
<p>It is possible that there are an arbitrary number of species in the population in arbitrarily small proportions. This fact allows for the species problem to potentially be quite ill-posed.</p>
<p>One nonparametric estimator called coverage estimator of <span class="math notranslate nohighlight">\(N_s\)</span> adjusts the number of observed species <span class="math notranslate nohighlight">\(n_{obs}\)</span> upward by a certain factor (??)</p>
<div class="math notranslate nohighlight">
\[
\hat{N}_s^{cov} = \frac{n_s ^{obs}}{\hat{c}} \quad \text{where} \quad \hat{c} = 1 - \frac{x_1}{n}
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_1\)</span> is the number of species observed <strong>only</strong> once in the sample of size <span class="math notranslate nohighlight">\(n\)</span>. The factor <span class="math notranslate nohighlight">\(\hat{c}\)</span> is an estimate of the coverage <span class="math notranslate nohighlight">\(c\)</span> of the sample: the fraction of population corresponding to species observed <strong>at least</strong> once.</p>
<p>Pros</p>
<ul class="simple">
<li><p>has asymptotic behavior quite close to that of MLE</p></li>
<li><p>easier to compute than MLE</p></li>
</ul>
<p>Cons</p>
<ul class="simple">
<li><p>suffer from significant bias and large variance in small samples</p></li>
</ul>
</section>
</section>
<section id="monte-carlo">
<h2>Monte Carlo<a class="headerlink" href="#monte-carlo" title="Permalink to this headline">¶</a></h2>
<p>Given a random variable <span class="math notranslate nohighlight">\(X\)</span> with PDF <span class="math notranslate nohighlight">\(f\)</span>, sometimes we need to compute the expectation of <span class="math notranslate nohighlight">\(g(X)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\left( g(X) \right) = \int g(x)f(x) \mathrm{~d}x
\]</div>
<p>When computationally tractable, closed form expressions are not available for this purpose, and numerical integration is infeasible. For instance, Monte Carlo method generate random draws <span class="math notranslate nohighlight">\(x_1, \ldots, x_n\)</span> of <span class="math notranslate nohighlight">\(X\)</span> from <span class="math notranslate nohighlight">\(f\)</span>, and compute the stochastic approximation</p>
<div class="math notranslate nohighlight">
\[
\widehat{\mathbb{E}}(g(X))=\frac{1}{n} \sum_{i=1}^{n} g\left(x_{i}\right)
\]</div>
<p>Sometimes it is hard to generate random draws from <span class="math notranslate nohighlight">\(f\)</span>. If we can sample from <span class="math notranslate nohighlight">\(h\)</span> where <span class="math notranslate nohighlight">\(w(x) = \frac{f(x)}{h(x)}\)</span>, then by re-arrangement we have</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}(g(X))= \frac{\int g(x) w(x) h(x) \mathrm{~d} x }{\int w(x) h(x) \mathrm{~d} x}
\]</div>
<p>Hence the approximation is</p>
<div class="math notranslate nohighlight">
\[
\widehat{\mathbb{E}}_{h}(g(X)) = \frac{(1 / n) \sum_{i=1}^{n} w\left(x_{i}\right) g\left(x_{i}\right)}{(1 / n) \sum_{i=1}^{n} w\left(x_{i}\right)}
\]</div>
</section>
<section id="rejection-sampling">
<h2>Rejection Sampling<a class="headerlink" href="#rejection-sampling" title="Permalink to this headline">¶</a></h2>
</section>
<section id="markov-chain-monte-carlo">
<h2>Markov Chain Monte Carlo<a class="headerlink" href="#markov-chain-monte-carlo" title="Permalink to this headline">¶</a></h2>
<section id="general-setting">
<h3>General Setting<a class="headerlink" href="#general-setting" title="Permalink to this headline">¶</a></h3>
</section>
<section id="metropolis-hastings">
<h3>Metropolis Hastings<a class="headerlink" href="#metropolis-hastings" title="Permalink to this headline">¶</a></h3>
<p>MH is a particular case of MCMC.</p>
</section>
</section>
<section id="gibbs-sampling">
<h2>Gibbs Sampling<a class="headerlink" href="#gibbs-sampling" title="Permalink to this headline">¶</a></h2>
</section>
<section id="others">
<h2>Others<a class="headerlink" href="#others" title="Permalink to this headline">¶</a></h2>
<p>Finite Population Sampling</p>
<section id="poisson-sampling">
<h3>Poisson Sampling<a class="headerlink" href="#poisson-sampling" title="Permalink to this headline">¶</a></h3>
</section>
<section id="bernoulli-sampling">
<h3>Bernoulli Sampling<a class="headerlink" href="#bernoulli-sampling" title="Permalink to this headline">¶</a></h3>
</section>
</section>
<section id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">¶</a></h2>
<section id="sampling-from-a-triangle">
<h3>Sampling from a Triangle<a class="headerlink" href="#sampling-from-a-triangle" title="Permalink to this headline">¶</a></h3>
<p>Tags: TwoSigma, Quant, 20Q4</p>
<p><em>How to generate uniformly distributed points in a triangle in a <span class="math notranslate nohighlight">\(xy\)</span>-plane, given the coordinates of the three vertices? Suppose that you have a generator that can generate uniformly distributed random values over the interval <span class="math notranslate nohighlight">\([0,1]\)</span> and you can use it twice.</em></p>
<p>We can first start from a special case and then generalize it: what if the three coordinates are <span class="math notranslate nohighlight">\((1,0), (0,1), (1,1)\)</span>? Call this triangle the basic triangle.</p>
<p>We can draw a random point <span class="math notranslate nohighlight">\((x,y)\)</span> from the square with vertices <span class="math notranslate nohighlight">\((0,0), (0,1), (1,1), (1,0)\)</span>, using twice the random generator. If the point is inside the basic triangle, which is identified by <span class="math notranslate nohighlight">\(x+y&gt;1\)</span>, then we keep it, otherwise we keep its symmetric point <span class="math notranslate nohighlight">\((1-x, 1-y)\)</span> which is inside the basic triangle. The sampling process is implemented in the below python script.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">sample_basic_triangle</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">inside</span> <span class="o">=</span> <span class="n">points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span>
    <span class="n">new_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">inside</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">points</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">points</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_points</span>

<span class="n">points</span> <span class="o">=</span> <span class="n">sample_basic_triangle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/71-sampling_2_0.png" src="../_images/71-sampling_2_0.png" />
</div>
</div>
<p>Then we can map these uniform random points in the basic triangle to the target triangle, by an affine transformation.</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{y}_i = A \boldsymbol{x}_i + \boldsymbol{b}
\]</div>
<p>where for <span class="math notranslate nohighlight">\(i=1,2,3\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{y}_i = (y_{i1}, y_{i2})\)</span> is vertex coordinate of the target triangle</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}_i = (x_{i1}, y_{i2})\)</span> is vertex coordinate of the basic triangle</p></li>
<li><p><span class="math notranslate nohighlight">\(A=\left[\begin{array}{cc}
a_{11} &amp; a_{12}\\
a_{21} &amp; a_{22}
\end{array}\right]\)</span> is a matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{b}=\left[\begin{array}{c}
b_{1}\\
b_{2}
\end{array}\right]\)</span> is a vector</p></li>
</ul>
<p>There are four unknown variables in <span class="math notranslate nohighlight">\(A\)</span> and 2 in <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>, and there are six equations, so we are able to solve them. Rearranging the equations gives the standard form of a linear system</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[\begin{array}{cccccc}
1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\
1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1\\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1
\end{array}\right]\left[\begin{array}{c}
a_{11}\\
a_{12}\\
a_{21}\\
a_{22}\\
b_{1}\\
b_{2}
\end{array}\right]=\left[\begin{array}{c}
y_{11}\\
y_{12}\\
y_{21}\\
y_{22}\\
y_{31}\\
y_{32}
\end{array}\right]
\end{split}\]</div>
<p>Below is a python script to solve for <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">solve</span>
<span class="k">def</span> <span class="nf">solve_affine</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    y: shape (3,2), the vertex coordinates of the target triangle</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
    <span class="n">Ab</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>               
    <span class="n">A</span> <span class="o">=</span> <span class="n">Ab</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Ab</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">solve_affine</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally we can write the function for the random generator.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample_triangle</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    sample from a triangle with vertex coordinates (0,1), (1,1), (1,0)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">sample_basic_triangle</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">A</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">solve_affine</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">new_points</span> <span class="o">=</span> <span class="n">A</span> <span class="o">@</span> <span class="n">points</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">b</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_points</span><span class="o">.</span><span class="n">T</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">sample_triangle</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/71-sampling_7_0.png" src="../_images/71-sampling_7_0.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./12-probabilities"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="51-markov-chain.html" title="previous page">Markov Chain</a>
    <a class='right-next' id="next-link" href="90-multivariate-notations.html" title="next page">Multivariate Notations</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dennis Zheng<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>