{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01158e3d",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Proposed by Pearson in 1901 and further developed by Hotelling in 1993.\n",
    "\n",
    "## Objective\n",
    "\n",
    "### Tasks\n",
    "\n",
    "Given $X_1, X_2, \\ldots, X_d$, we want to extract the most useful information of $p$ measurements such that\n",
    "\n",
    "1. **explore underlying dimension** behind the $p$ original measurements to explain the variation of $p$ original measurements, which may have interesting or revealing interpretations, such as size, shape and contrasts in natural science;\n",
    "\n",
    "2. **estimate latent variables** (i.e. variables that cannot be measured or observed.) which can explain the variation of the $p$ original measurements, especially in\n",
    "social behavioral sciences.\n",
    "\n",
    "3. **simplify the dimension** of the observed data set. Lower dimension can be chosen from the data set such that the variations of measurements can be captured with an acceptable level. For example, $k \\ll d$ latent variables are chosen to capture 90% of variation of $p$ original measurements. Indeed, this can be regarded as the data reduction or dimension reduction.\n",
    "\n",
    "### Formulation based on Distribution\n",
    "\n",
    "Consider a $d$-dimensional random vector $\\boldsymbol{x} = \\left( X_1, X_2, \\ldots, X_d \\right)^\\top$ with mean vector $\\boldsymbol{\\mu} = \\left( \\mu_1, \\ldots, \\mu_d \\right)^\\top$ and covariance matrix $\\boldsymbol{\\Sigma}$. PCA aims to obtain the variables $Z_1, Z_2, \\ldots, Z_k$ which are the **linear combinations** of $X_1, X_2, \\ldots, X_d$ and $k \\le d$, such that\n",
    "\n",
    "- The sum of the new individual variances\n",
    "\n",
    "  $$\n",
    "  \\operatorname{Var}\\left( Z_1 \\right) + \\operatorname{Var}\\left( Z_2 \\right) + \\ldots + \\operatorname{Var}\\left( Z_k \\right)\n",
    "  $$\n",
    "\n",
    "  is **close** to the sum of the original individual variances\n",
    "\n",
    "  $$\n",
    "  \\operatorname{Var}\\left( X_1 \\right) + \\operatorname{Var}\\left( X_2 \\right) + \\ldots + \\operatorname{Var}\\left( X_d \\right)\n",
    "  $$\n",
    "\n",
    "  and\n",
    "\n",
    "- The linear combinations $Z_i$ and $Z_j$ are **uncorrelated** for $i\\ne j$. This imply that each variable in $\\boldsymbol{z} = \\left( Z_1, Z_2, \\ldots, Z_k \\right)^\\top$ can be analyzed by using **univariate** techniques.\n",
    "\n",
    "The new variables $Z_j$ are called princial components.\n",
    "\n",
    "### Formulation based on Data\n",
    "\n",
    "Other formulations of PCA based on **centered** sample data matrix $\\boldsymbol{X}$ aim to find a linear mapping $\\mathbb{R} ^d \\rightarrow \\mathbb{R} ^k$ (assume $\\boldsymbol{X}$ is centered) to project the data matrix $\\boldsymbol{X}_{n \\times d}$ to a lower dimensional embedding matrix $\\boldsymbol{Z}_{n \\times k}$.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\boldsymbol{z}_i &= \\boldsymbol{W}_{d \\times k} ^\\top \\boldsymbol{x}_i \\\\\n",
    "\\boldsymbol{Z}_{n \\times k} &= \\boldsymbol{X}_{n \\times d}  \\boldsymbol{W} _{d \\times k} \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "The mapping $\\boldsymbol{W} _{d \\times k}$ are also called **loadings**, and the embeddings $\\boldsymbol{Z} _{n \\times k}$ are called **scores**. The loadings can be used to visualize how the original variables $X_j$ contributes to each principal component $Z_j$. The scores $\\boldsymbol{Z} _{n \\times k}$ can then be used for downstream tasks, e.g. visualization, classification.\n",
    "\n",
    "There are various equivalent formulations of optimization problems to find the loadings $\\boldsymbol{W}$:\n",
    "\n",
    "- Maximize the total variances $\\sum_i \\operatorname{Var}\\left( Z_i \\right)$ of the projected data $\\boldsymbol{Z} =  \\boldsymbol{X}  \\boldsymbol{W}$ (similar to the population formulation above)\n",
    "\n",
    "    $$\\begin{align}\n",
    "    \\max_{\\boldsymbol{W}}\\, & \\operatorname{tr}\\left( \\boldsymbol{Z} ^\\top \\boldsymbol{Z}  \\right)   \\\\\n",
    "     \\text{s.t.}  & \\ \\boldsymbol{W} ^\\top \\boldsymbol{W} = \\boldsymbol{I}  \\\\\n",
    "       &\\ \\boldsymbol{W} \\in \\mathbb{R} ^{d \\times k}\n",
    "    \\end{align}$$\n",
    "\n",
    "- Minimize total reconstruction loss, where $\\hat{\\boldsymbol{x} }_i = \\boldsymbol{W} \\boldsymbol{z} _i = \\boldsymbol{W} \\boldsymbol{W} ^{\\top} \\boldsymbol{x} _i$\n",
    "\n",
    "    $$\\begin{align}\n",
    "    \\min_{\\boldsymbol{W}}\\, & \\sum_i^n \\left\\Vert \\boldsymbol{x}_i - \\hat{\\boldsymbol{x} }_i \\right\\Vert ^2    \\\\\n",
    "    \\text{s.t.}  & \\boldsymbol{W} ^\\top \\boldsymbol{W} = \\boldsymbol{I}  \\\\\n",
    "       &\\ \\boldsymbol{W} \\in \\mathbb{R} ^{d \\times k}\n",
    "    \\end{align}$$\n",
    "\n",
    "- Low-dimensional Hyperplane fitting\n",
    "\n",
    "  Fit a low-dimensional hyperplane such that, when we project our data $\\boldsymbol{X}$ onto the hyperplane and obtain $\\boldsymbol{Z}$, the variance of our data is changed as little as possible. The low-dimensional hyperplane is defined by $\\boldsymbol{W}$, which is the matrix of basis vectors that span it. Minimizing the change in variance between the original data $\\boldsymbol{X}$ and its reconstruction $\\boldsymbol{Z} \\boldsymbol{W}^{\\top}$ is equivalent to minimizing the sum of squared error loss:\n",
    "\n",
    "  $$\\begin{align}\n",
    "  \\min_{\\boldsymbol{W}, \\left\\{ \\boldsymbol{z}_i \\right\\}}\\, & \\sum_i^n \\left\\Vert \\boldsymbol{x}_i - \\boldsymbol{W} \\boldsymbol{z} _i \\right\\Vert ^2    \\\\\n",
    "   \\text{s.t.}  & \\boldsymbol{W} ^\\top \\boldsymbol{W} = \\boldsymbol{I}  \\\\\n",
    "     &\\ \\boldsymbol{W} \\in \\mathbb{R} ^{d \\times k}, \\boldsymbol{z} _i \\in \\mathbb{R} ^{k}\n",
    "  \\end{align}$$\n",
    "\n",
    "  :::{admonition,dropdown,seealso} *Derivation of Equivalentce*\n",
    "\n",
    "  First, we write in matrix form\n",
    "\n",
    "  $$\n",
    "  \\min_{\\boldsymbol{W}, \\left\\{ \\boldsymbol{z}_i \\right\\}}\\, \\sum_i^n \\left\\Vert \\boldsymbol{x}_i - \\boldsymbol{W} \\boldsymbol{z} _i \\right\\Vert ^2\n",
    "  = \\min_{\\boldsymbol{W}, \\boldsymbol{Z}}\\, \\left\\| \\boldsymbol{X} - \\boldsymbol{Z} \\boldsymbol{W} ^{\\top} \\right\\|^2 \\\\\n",
    "  $$\n",
    "\n",
    "  Setting first order derivative w.r.t. $\\boldsymbol{Z}$ to 0 gives $\\boldsymbol{Z} = \\boldsymbol{X} \\boldsymbol{W}$. Hence the objective is\n",
    "\n",
    "\n",
    "  $$\\begin{aligned}\n",
    "  \\min_{\\boldsymbol{W}}\\, \\left\\| \\boldsymbol{X} - \\boldsymbol{X}\\boldsymbol{W} \\boldsymbol{W} ^{\\top} \\right\\|^2\n",
    "  &= \\min_{\\boldsymbol{W}}\\, \\operatorname{tr} \\left( (\\boldsymbol{X} - \\boldsymbol{X} \\boldsymbol{W} \\boldsymbol{W} ^{\\top} ) ^{\\top} (\\boldsymbol{X} - \\boldsymbol{X} \\boldsymbol{W} \\boldsymbol{W} ^{\\top} ) \\right) \\\\\n",
    "  &= \\min_{\\boldsymbol{W}}\\, \\operatorname{tr}(\\boldsymbol{X} ^{\\top} \\boldsymbol{X}  - \\boldsymbol{X} ^{\\top} \\boldsymbol{X} \\boldsymbol{W} \\boldsymbol{W} ^{\\top}  - \\boldsymbol{W} \\boldsymbol{W} ^{\\top} \\boldsymbol{X} ^{\\top} \\boldsymbol{X}  + \\boldsymbol{W} \\boldsymbol{W} ^{\\top} \\boldsymbol{X} ^{\\top} \\boldsymbol{X} \\boldsymbol{W} \\boldsymbol{W} ^{\\top} ) \\\\\n",
    "  &= \\min_{\\boldsymbol{W}}\\, \\operatorname{tr} \\left( \\boldsymbol{X} ^{\\top} \\boldsymbol{X}  - \\boldsymbol{W} ^{\\top} \\boldsymbol{X} ^{\\top} \\boldsymbol{X} \\boldsymbol{W}  \\right)  \\quad \\because \\text{by cyclic permutations in trace} \\\\\n",
    "  &\\Leftrightarrow   \\min_{\\boldsymbol{W}}\\, \\operatorname{tr} (\\boldsymbol{W} ^{\\top} \\boldsymbol{X} ^{\\top} \\boldsymbol{X} \\boldsymbol{W})\\\\\n",
    "  &= \\min_{\\boldsymbol{W}}\\, \\operatorname{tr} (\\boldsymbol{Z} ^{\\top} \\boldsymbol{Z})\\\\\n",
    "  \\end{aligned}$$\n",
    "\n",
    "  :::\n",
    "\n",
    "## Learning\n",
    "\n",
    "(pca-sequential)=\n",
    "### Sequential Maximization\n",
    "\n",
    "The first variable in $\\boldsymbol{z}$, i.e. $Z_1 = \\boldsymbol{u} \\boldsymbol{x}$ is obtained to maximize its variance, i.e.,\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}\\left(Z_{1}\\right)=\\max _{\\left\\Vert \\boldsymbol{u}  \\right\\Vert _2^2 = 1 } \\boldsymbol{u}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{u}\n",
    "$$\n",
    "\n",
    "where the constraint is to removes scaling or $\\boldsymbol{u}$. Suppose the maximum is achieved at $\\boldsymbol{u} = \\boldsymbol{u} _1$ and we call the variable $Z_1$ given below the **first population principal component**\n",
    "\n",
    "$$\n",
    "Z_1 = \\boldsymbol{u} _1^{\\top} \\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "Successively for $k=2, \\ldots, d$ the variance of $Z_i$ can be obtained by the following maximization\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\max _{\\boldsymbol{u} _k} && \\boldsymbol{u}_k^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{u}_k & \\\\\n",
    "\\mathrm{s.t.}\n",
    "&& \\quad \\boldsymbol{u}_k^{\\top} \\boldsymbol{u}_k&=1 \\\\\n",
    "&& \\boldsymbol{u}_k ^{\\top} \\boldsymbol{u} _j &= 0  \\text{  for }  j=1, \\ldots, k-1 \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "where the second constraint $\\boldsymbol{u}_k ^{\\top} \\boldsymbol{u} _j = 0$ comes from the identity\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Cov}\\left(Z_{k}, Z_{j}\\right)  &=\\operatorname{Cov}\\left(\\boldsymbol{u} _{k}^{\\top} \\boldsymbol{x}, \\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x}\\right) \\\\\n",
    "&=\\boldsymbol{u}_{k}^{\\top} \\operatorname{Cov}(\\boldsymbol{x}, \\boldsymbol{x}) \\boldsymbol{u}_{j} \\\\\n",
    "&=\\boldsymbol{u}_{k}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{u}_{j} \\\\\n",
    "&=\\boldsymbol{u}_{k}^{\\top} \\lambda_{j} \\boldsymbol{u}_{j} \\\\\n",
    "&=\\lambda_{j} \\boldsymbol{u}_{k}^{\\top} \\boldsymbol{u}_{j}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since $\\lambda_j > 0$ and we want uncorrelated principal components $\\operatorname{Cov}\\left(Z_k, Z_{j}\\right) = 0$, we obtain $\\boldsymbol{u} _k ^{\\top} \\boldsymbol{u} _j = 0$.\n",
    "\n",
    "After we solve $\\boldsymbol{u} _k$, the $k$-th population principal component is then\n",
    "\n",
    "$$\n",
    "Z_k = \\boldsymbol{u} _k^\\top \\boldsymbol{x}\n",
    "$$\n",
    "\n",
    ":::{admonition,dropdown,seealso} Derivation\n",
    "\n",
    "The problem to find $\\boldsymbol{u} _1$ is an [Rayleigh quotient](rayleigh-quotient) problem which has been solved there. We show how to solve the subsequent $\\boldsymbol{u} _k$ for $k \\ge 2$.\n",
    "\n",
    "When $k=2$, the problem is\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\max _{\\boldsymbol{u} _2} && \\boldsymbol{u}_2^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{u}_2 & \\\\\n",
    "\\mathrm{s.t.}\n",
    "&& \\quad \\boldsymbol{u}_2^{\\top} \\boldsymbol{u}_2&=1 \\\\\n",
    "&& \\boldsymbol{u}_2 ^{\\top} \\boldsymbol{u} _1 &= 0\\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "The Lagrangean is\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{2}=\\boldsymbol{u}_{2}^{\\top} \\Sigma \\boldsymbol{u}_{2}-\\lambda\\left(\\boldsymbol{u}_{2}^{\\top} \\boldsymbol{u}_{2}-1\\right)-\\delta\\left(\\boldsymbol{u}_{2}^{\\top} \\boldsymbol{u}_{1}-0\\right)\n",
    "$$\n",
    "\n",
    "Taking derivative w.r.t. $\\boldsymbol{u} _2$ gives\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}_{2}}{\\partial \\boldsymbol{u}_{2}}=2 \\boldsymbol{\\Sigma} \\boldsymbol{u}_{2}-2 \\lambda \\boldsymbol{u}_{2}-\\delta \\boldsymbol{u}_{1}=0\n",
    "$$\n",
    "\n",
    "Left-multiply $\\boldsymbol{u} _1 ^{\\top}$ we have\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "RHS &= \\boldsymbol{u}_{1}^{\\top} \\boldsymbol{0} =0 \\\\\n",
    "LHS &=2\\left(\\boldsymbol{u}_{1}^{\\top} \\Sigma \\boldsymbol{u}_{2}-\\boldsymbol{u}_{1}^{\\top} \\lambda \\boldsymbol{u}_{2}\\right)-\\boldsymbol{u}_{1}^{\\top} \\delta \\boldsymbol{u}_{1} \\\\\n",
    "&=2\\left(\\left(\\boldsymbol{\\Sigma} \\boldsymbol{u}_{1}\\right)^{\\top} \\boldsymbol{u}_{2}-\\lambda \\boldsymbol{u}_{1}^{\\top} \\boldsymbol{u}_{2}\\right)-\\delta \\boldsymbol{u}_{1}^{\\top} \\boldsymbol{u}_{1} \\\\\n",
    "&=2\\left(\\lambda \\boldsymbol{u}_{1}^{\\top} \\boldsymbol{u}_{2}-\\lambda \\boldsymbol{u}_{1}^{\\top} \\boldsymbol{u}_{2}\\right)-\\delta \\\\\n",
    "&=- \\delta\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence $\\delta = 0$. Substituting this back gives $\\Sigma \\boldsymbol{u} _2= \\lambda\\boldsymbol{u} _{2}$. Thus, $\\boldsymbol{u} _2$ is an eigenvector of $\\boldsymbol{\\Sigma}$ with eigenvalue $\\lambda$. The objective is then $\\boldsymbol{u} _2 \\boldsymbol{\\Sigma} \\boldsymbol{u} _2 = \\lambda$. Hence, we choose $\\lambda_2$, and choose $\\boldsymbol{u} _2$ to be the eigenvector of $\\boldsymbol{\\Sigma}$ associated with $\\lambda_2$.\n",
    "\n",
    "For $k=3, \\ldots, n$, the Lagrangean is\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{k}=\\boldsymbol{u}_{k}^{\\top} \\Sigma \\boldsymbol{u}_{k}-\\lambda\\left(\\boldsymbol{u}_{k}^{\\top} \\boldsymbol{u}_{k}-1\\right)-\\delta_{1}\\left(\\boldsymbol{u}_{k}^{\\top} \\boldsymbol{u}_{1}\\right)-\\cdots-\\delta_{k-1}\\left(\\boldsymbol{u}_{k}^{\\top} \\boldsymbol{u}_{k-1}\\right)\n",
    "$$\n",
    "\n",
    "Taking derivative gives\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L_{k}}{\\partial \\boldsymbol{u}_{k}} &=2(\\Sigma-\\lambda I) \\boldsymbol{u}_{k}-\\delta_{1} \\boldsymbol{u}_{1}-\\cdots-\\delta_{k-1} \\boldsymbol{u}_{k-1} \\\\\n",
    "&=2 \\boldsymbol{\\Sigma} \\boldsymbol{u}_{k}-2 \\lambda \\boldsymbol{u}_{k}-\\delta_{1} \\boldsymbol{u}_{1}-\\cdots-\\delta_{k-1} \\boldsymbol{u}_{k-1} \\\\\n",
    "&=0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Similarly, left multiplying $\\boldsymbol{u} _j ^{\\top}$ gives $\\delta_j=0$ for $j=1, \\ldots, k-1$. Substituting $\\delta_j=0$ back gives $\\boldsymbol{\\Sigma} \\boldsymbol{u} _k = \\lambda \\boldsymbol{u} _k$. We can then choose the $k$-th largest eigenvalue $\\lambda_k$ and the associated eigenvector to be $\\boldsymbol{u}_k$.\n",
    "\n",
    ":::\n",
    "\n",
    "### Spectral Decomposition\n",
    "\n",
    "Rather than obtaining the principal components sequentially, the principal components and their variances can be obtained simultaneously by solving for the eigenvectors and eigenvalues of $\\boldsymbol{\\Sigma}$. Its [spectral decomposition](eigen-decomposition) is,\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Sigma}  = \\boldsymbol{U} \\boldsymbol{\\Lambda} \\boldsymbol{U} ^\\top = \\sum_i^d \\lambda_i \\boldsymbol{u} _i \\boldsymbol{u} _i ^\\top\n",
    "$$\n",
    "\n",
    "where\n",
    "- $\\lambda_1 > \\lambda_2 > \\dots> \\lambda_d \\ge 0$ are ordered eigenvalues of $\\boldsymbol{\\Sigma}$: $\\boldsymbol{\\Lambda} =  \\operatorname{diag}(\\lambda_1, \\lambda_2, \\ldots, \\lambda_d)$\n",
    "- $\\boldsymbol{u} _1, \\ldots, \\boldsymbol{u} _d$ are their corresponding normalized eigenvectors forming the column vectors of the orthogonal matrix $\\boldsymbol{U} = \\left( \\boldsymbol{u} _1\\  \\boldsymbol{u} _2 \\ \\ldots \\  \\boldsymbol{u} _d \\right)$, where $\\boldsymbol{U}  ^\\top \\boldsymbol{U}   = \\boldsymbol{I}$ or $\\boldsymbol{u} _i ^\\top \\boldsymbol{u} _j = 1$ if $i=j$ and 0 otherwise.\n",
    "\n",
    "For derivation see [1](https://math.stackexchange.com/questions/3736092/how-to-solve-the-optimization-problem-of-pca?rq=1),[2](https://math.stackexchange.com/questions/1902421/prove-that-the-trace-of-the-matrix-product-uau-is-maximized-by-setting-us).\n",
    "\n",
    "The $k$-th population principal component is defined as\n",
    "\n",
    "$$\n",
    "Z_{k}=\\boldsymbol{u}_{k}^{\\top} \\boldsymbol{x}=u_{1 k} X_{1}+u_{2 k} X_{2}+\\cdots+u_{d k} X_{k}, \\quad k=1, \\ldots, d\n",
    "$$\n",
    "\n",
    "The principal component transform using the first $k$ principal directions is then\n",
    "\n",
    "$$\n",
    "\\boldsymbol{z} = \\boldsymbol{U}_{[:k]} ^\\top \\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "\\boldsymbol{Z} = \\boldsymbol{X} \\boldsymbol{U} _{[:k]}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{U} _{[:k]}$ means the matrix consisting of the first $k$ columns of $\\boldsymbol{U}$.\n",
    "\n",
    "### Properties\n",
    "\n",
    "1. All principal components are uncorrelated, i.e., $\\operatorname{Cov}\\left( Z_i, Z_j \\right) = 0$ for $i \\ne j$\n",
    "\n",
    "\n",
    "    :::{admonition,dropdown,seealso} *Proof*\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\operatorname{Cov}\\left(Z_{i}, Z_{j}\\right) &=\\operatorname{Cov}\\left(\\boldsymbol{u}_{i}^{\\top} \\boldsymbol{x}, \\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x}\\right) \\\\\n",
    "    &=\\mathrm{E}\\left(\\boldsymbol{u}_{i}^{\\top}(\\boldsymbol{x}-\\boldsymbol{\\mu})(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\top} \\boldsymbol{u}_{j}\\right) \\\\\n",
    "    &=\\boldsymbol{u}_{i}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\boldsymbol{u}_{i}^{\\top} \\boldsymbol{U} \\boldsymbol{\\Lambda} \\boldsymbol{U} ^{\\top} \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\left(\\boldsymbol{u}_{i}^{\\top}\\right)\\left(\\boldsymbol{u}_{1} \\boldsymbol{u}_{2} \\cdots \\boldsymbol{u}_{d}\\right) \\boldsymbol{\\Lambda}\\left(\\begin{array}{c}\n",
    "    \\boldsymbol{u}_{1}^{\\top} \\\\\n",
    "    \\boldsymbol{u}_{2}^{\\top} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\boldsymbol{u}_{d}^{\\top}\n",
    "    \\end{array}\\right) \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\boldsymbol{e}_{i}^{\\top} \\boldsymbol{\\Lambda} \\boldsymbol{e}_{j} \\\\\n",
    "    &=0\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "    :::\n",
    "\n",
    "\n",
    "1. The variance of the $i$-th principal component is $\\lambda_i$, i.e. $\\operatorname{Var}\\left( Z_i \\right) = \\lambda_i$.\n",
    "\n",
    "    :::{admonition,dropdown,seealso} *Proof*\n",
    "\n",
    "    $$\\begin{aligned}\n",
    "    \\operatorname{Var}\\left( Z_i \\right)\n",
    "    &= \\operatorname{Var}\\left( \\boldsymbol{u} _i ^\\top \\boldsymbol{x}  \\right) \\\\\n",
    "    &= \\boldsymbol{u} _i ^\\top \\boldsymbol{\\Sigma} \\boldsymbol{u} _i \\\\\n",
    "    &= \\boldsymbol{e}_i ^\\top \\boldsymbol{\\Lambda} \\boldsymbol{e}_i  \\\\\n",
    "    &= \\lambda_i\n",
    "    \\end{aligned}$$\n",
    "    :::\n",
    "\n",
    "1. The first principal component $Z_1 = \\boldsymbol{u} _1 ^\\top \\boldsymbol{x}$ has the largest variance among all linear combinations of $X_i$'s. Then for $i=2, \\ldots, p$, the $i$-th principal component has the largest variance among all linear combinations of $X_i$'s, which are uncorrelated with the first $(i-1)$ principal components.\n",
    "\n",
    "\n",
    "1. The principal component preserve the total variance\n",
    "\n",
    "    $$\n",
    "    \\sum_{i=1}^{d} \\operatorname{Var}\\left(Z_{i}\\right)=\\sum_{i=1}^{d} \\operatorname{Var}\\left(X_{i}\\right)\n",
    "    $$\n",
    "\n",
    "    or\n",
    "\n",
    "    $$\n",
    "    \\sum_{i=1}^{d} \\lambda_{i}=\\sum_{i=1}^{d} \\sigma_{i i}\n",
    "    $$\n",
    "\n",
    "    Hence, the PCA procedure, the total variance is preserved by re-allocated to $\\operatorname{Var}\\left( Z_1 \\right) \\ge \\operatorname{Var}\\left( Z_2 \\right) \\ge \\ldots \\operatorname{Var}\\left( Z_d \\right)$.\n",
    "\n",
    "    :::{admonition,dropdown,seealso} *Proof*\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\sum_{i=1}^{d} \\sigma_{i i} &=\\operatorname{tr}(\\boldsymbol{\\Sigma}) \\\\\n",
    "    &=\\operatorname{tr}\\left(\\sum_{i=1}^{d} \\lambda_{i} \\boldsymbol{u}_{i} \\boldsymbol{u}_{i}^{\\top}\\right) \\\\\n",
    "    &=\\sum_{i=1}^{d} \\lambda_{i} \\operatorname{tr}\\left(\\boldsymbol{u}_{i} \\boldsymbol{u}_{i}^{\\top}\\right) \\\\\n",
    "    &=\\sum_{i=1}^{d} \\lambda_{i} \\operatorname{tr}\\left(\\boldsymbol{u}_{i}^{\\top} \\boldsymbol{u}_{i}\\right) \\\\\n",
    "    &=\\sum_{i=1}^{d} \\lambda_{i}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "    :::\n",
    "\n",
    "\n",
    "1. If the correlation matrix $\\boldsymbol{\\rho} = \\boldsymbol{D}^{-1}\\boldsymbol{\\Sigma} \\boldsymbol{D}^{-1}$ instead of the covariance matrix $\\boldsymbol{\\Sigma}$ is used, i.e. variables $X_1, X_2, \\ldots, X_d$ are standardized, then\n",
    "\n",
    "\n",
    "   $$\n",
    "   \\sum_i^d \\lambda_i = \\sum_i^d \\sigma_{ii} = \\sum_i^d 1 =  d\n",
    "   $$\n",
    "\n",
    "1. The correlation between a principal component $Z_j$ and an original variable $X_i$ is given by\n",
    "\n",
    "    $$\n",
    "    \\operatorname{Corr}\\left( X_i, Z_j \\right) = \\frac{\\sqrt{\\lambda_j}a_{ij}}{\\sqrt{\\sigma_{ii}}}\n",
    "    $$\n",
    "\n",
    "    where $u_{ij}$ denotes the $i$-th element of $\\boldsymbol{u} _j$.\n",
    "\n",
    "    :::{admonition,dropdown,seealso} *Proof*\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\operatorname{Cov}\\left(X_{i}, Z_{j}\\right) &=\\operatorname{Cov}\\left(X_{i}, \\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x}\\right) \\\\\n",
    "    &=\\operatorname{Cov}\\left(\\boldsymbol{e}_{i}^{\\top} \\boldsymbol{x}, \\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x}\\right) \\\\\n",
    "    &=\\boldsymbol{e}_{i}^{\\top} \\boldsymbol{\\Sigma} \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\boldsymbol{e}_{i}^{\\top} \\sum_{k=1}^{d} \\lambda_{k} \\boldsymbol{u}_{k} \\boldsymbol{u}_{k}^{\\top} \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\lambda_{j} \\boldsymbol{e}_{i}^{\\top} \\boldsymbol{u}_{j} \\boldsymbol{u}_{j}^{\\top} \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\lambda_{j} \\boldsymbol{e}_{i}^{\\top} \\boldsymbol{u}_{j} \\\\\n",
    "    &=\\lambda_{j} u_{i j}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "    and then\n",
    "\n",
    "    $$\\begin{align}\n",
    "    \\operatorname{Corr}\\left(X_{i}, Z_{j}\\right)\n",
    "    &=\\frac{\\operatorname{Cov}\\left(X_{i}, Z_{j}\\right)}{\\sqrt{\\operatorname{Var}\\left(X_{i}\\right) \\operatorname{Var}\\left(Z_{j}\\right)}} \\\\\n",
    "    &=\\frac{\\lambda_{j} u_{i j}}{\\sqrt{\\sigma_{i i} \\lambda_{j}}} \\\\\n",
    "    &=\\frac{\\sqrt{\\lambda_{j}} u_{i j}}{\\sqrt{\\sigma_{i i}}}\n",
    "    \\end{align}$$\n",
    "    :::\n",
    "\n",
    "\n",
    "\n",
    "## Practical Issues\n",
    "\n",
    "### Tuning\n",
    "\n",
    "There are several ways to choose the number of principal components to retain.\n",
    "\n",
    "1. **Cumulative proportion cutoff**:\n",
    "\n",
    "    Include the components such that the cumulative proportion of the total variance explained is just more than a threshold value, say 80%, i.e., if\n",
    "\n",
    "    $$\n",
    "    \\begin{equation}\n",
    "    \\frac{\\sum_{i=1}^{k} \\operatorname{Var}\\left( Z_i \\right)}{\\sum_{i=1}^{d} \\operatorname{Var}\\left( X_i \\right)} >0.8\n",
    "    \\end{equation}\n",
    "    $$\n",
    "\n",
    "    This method keeps $m$ principal components.\n",
    "\n",
    "1. **Proportion cutoff**\n",
    "\n",
    "    Select the components whose eigenvalues are greater than a threshold value, say average of eigenvalues; for correlation matrix input, this average is $d^{-1} \\sum_{i=1}^{d} \\operatorname{Var}\\left( Z_i \\right)=d^{-1} d=1$ if we use the correlation matrix $\\boldsymbol{\\rho}$.\n",
    "\n",
    "1. **Scree plot**\n",
    "\n",
    "    Construct the so-called scree plot of the eigenvalue $\\ell_i$ on the vertical axis versus $i$ on horizontal axis with equal intervals for $i = 1, 2, \\ldots, d$, and join the points into a decreasing polygon. Try to find a “clean-cut” where the polygon “levels off” so that the first few eigenvalues seem to be far apart from the others.\n",
    "\n",
    "    :::{figure,myclass} pca-scree-plot\n",
    "    <img src=\"../imgs/pca-scree-plot.png\" width = \"50%\" alt=\"\"/>\n",
    "\n",
    "    Scree plot of $\\lambda$. [Fung 2021]\n",
    "    :::\n",
    "\n",
    "1. **Hypothesis testing**\n",
    "\n",
    "    Perform formal significance tests to determine the larger an unequal eigenvalues and retain the principal components to these eigenvalues.\n",
    "\n",
    "1. **Reconstruction loss**\n",
    "\n",
    "    Recall the principal component transform $\\boldsymbol{z} = \\boldsymbol{U}_{[:k]} ^\\top \\boldsymbol{x}$. Hence, to reconstruct $\\hat{\\boldsymbol{x} }$ by the first $k$ components $\\boldsymbol{u} _1, \\ldots, \\boldsymbol{u} _k$ in $\\boldsymbol{U}$ , we can use the expansion\n",
    "\n",
    "    $$\n",
    "    \\hat{\\boldsymbol{x} }= \\boldsymbol{U}_{[:k]} \\boldsymbol{z} =\\sum_{j=1}^{k}z_j \\boldsymbol{u} _{j} = \\sum_{j=1}^{k}\\left(\\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x} \\right) \\boldsymbol{u} _{j}\n",
    "    $$\n",
    "\n",
    "    If $\\boldsymbol{x}$ was centered before PCA, we add the mean back\n",
    "\n",
    "    $$\n",
    "    \\hat{\\boldsymbol{x} }=\\boldsymbol{\\mu} _{\\boldsymbol{x}} +\\sum_{j=1}^{k}\\left(\\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x} \\right) \\boldsymbol{u} _{j}\n",
    "    $$\n",
    "\n",
    "    To choose an optimal number of principal components $k$, we can examine the magnitude of the residual $\\left\\Vert \\boldsymbol{x} - \\hat{\\boldsymbol{x} } \\right\\Vert ^2$. The expected residual corresponds to variance in the **remaining** subspace.\n",
    "\n",
    "    :::{figure,myclass} pca-reconstruction\n",
    "    <img src=\"../imgs/pca-reconstruction.png\" width = \"80%\" alt=\"\"/>\n",
    "\n",
    "    Reconstruction of digits with mean and principal components [Livescu 2021]\n",
    "    :::\n",
    "\n",
    "\n",
    "1. **Downstream task performance**\n",
    "\n",
    "    Use the performance of the downstream task to choose an optimal number of principal components.\n",
    "\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "#### Geometric Meaning: Direction of Variation\n",
    "\n",
    "For the distribution of $\\boldsymbol{x}$, thelcenter location is determined by $\\boldsymbol{\\mu} _ X$ and the variation is captured by each principal direction $\\boldsymbol{u} _i$\n",
    "\n",
    "\n",
    "For the multinormal distribution, the family of **contours** of $\\boldsymbol{x}$ (on each of which the pdf is a constant) is a family of ellipsoids in the original coordinate system $\\boldsymbol{x}$ satisfying the following equation for a\n",
    "constant $c$,\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "(\\boldsymbol{x}-\\boldsymbol{\\mu})^{\\top} \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})=c^{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $c$ serves as an index of the family. This family of ellipsoids have orthogonal principal axes\n",
    "\n",
    "$$\n",
    "\\pm c\\lambda_i^{1/2}\\boldsymbol{u}_i, i= 1, 2, \\ldots, p\n",
    "$$\n",
    "\n",
    "with length\n",
    "- $2c\\lambda_i^{1/2}$\n",
    "- directional cosines as coefficients given in $\\boldsymbol{u} _i$ for the $i$-th axis.\n",
    "\n",
    ":::{figure} pca-gausian-ellipsoids\n",
    "<img src=\"../imgs/pca-pc-ellipsoids.png\" width = \"80%\" alt=\"\"/>\n",
    "\n",
    "PCA and Ellipsoids of Gaussian [Fung 2018]\n",
    ":::\n",
    "\n",
    "\n",
    "Another example is hand written digits. Suppose $\\boldsymbol{\\mu} _ \\boldsymbol{x}$ is the sample mean that determines the \"mean\" appearance of the digit $2$, then $\\boldsymbol{\\phi}_j$ is a principal direction which determines the location of variation of the black/white pixels.\n",
    "\n",
    "\n",
    ":::{figure,myclass} pca-reconstruction-scale\n",
    "<img src=\"../imgs/pca-pc-digits.png\" width = \"50%\" alt=\"\"/>\n",
    "\n",
    "Reconstruction of digits with mean and scaled principal components [Livescu 2021]\n",
    ":::\n",
    "\n",
    "#### Proportion Explained\n",
    "\n",
    "The proportion of total variance explained by $Z_i$, which is\n",
    "\n",
    "$$\\frac{\\lambda_i}{\\sum_{j=1}^d \\lambda_j}$$\n",
    "\n",
    "is considered as a measure of **importance** of $Z_i$ in a more parsimonious description of the system.\n",
    "\n",
    "#### Score of an Observation in Sample Data\n",
    "\n",
    "For a data set of $n$ observations, we decompose the sample covariance matrix $S$ as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\boldsymbol{S} =\\sum_{i=1}^{d} \\ell_{i} \\boldsymbol{u} _{i} \\boldsymbol{u} _{i}^{\\top}=\\boldsymbol{U} \\boldsymbol{L}  \\boldsymbol{U} ^\\top\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\ell_i$ are eigencalues of $\\boldsymbol{S}$ and $\\boldsymbol{u} _i$'s are their corresponding normalized eigenvectors.\n",
    "\n",
    "The $j$-th **sample** principal component is defined as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Z_{j}=\\boldsymbol{u}_{j}^{\\top} \\boldsymbol{x}=u_{1 j} X_{1}+u_{2 j} X_{2}+\\cdots+u_{d j} X_{d}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\begin{equation}\n",
    "\\boldsymbol{u}_{j}^{\\top}=\\left(\\begin{array}{llll}\n",
    "u_{1 j} & u_{2 j} & \\cdots & u_{d j}\n",
    "\\end{array}\\right)\n",
    "\\end{equation}$.\n",
    "\n",
    "The data layout is\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{array}{cccccccc}\n",
    "&& \\text{Data} \\ \\ \\boldsymbol{X}  &&&&\\text{PC} \\ \\ \\boldsymbol{Z} &\\\\\n",
    "\\hline X_{1} & X_{2} & \\cdots & X_{d} & \\quad \\quad Z_{1} & Z_{2} & \\cdots & Z_{k} \\\\\n",
    "x_{11} & x_{12} & \\cdots & x_{1 d} & \\quad \\quad z_{11} & z_{12} & \\cdots & z_{1 k} \\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2 d} & \\quad \\quad z_{21} & z_{22} & \\cdots & z_{2 k} \\\\\n",
    "& & \\vdots & & & & \\vdots & \\\\\n",
    "x_{n 1} & x_{n 2} & \\cdots & x_{n d} & \\quad \\quad z_{n 1} & z_{n 2} & \\cdots & z_{n k}\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the corresponding row vectors on the data matrices are related as\n",
    "\n",
    "$$\\boldsymbol{z} _i = \\boldsymbol{U}^\\top  \\boldsymbol{x} _i , i= 1, 2, \\ldots, n$$\n",
    "\n",
    "where $\\boldsymbol{z} _i$ can be interpreted as a vector of principal component scores for the $i$-th observation.\n",
    "\n",
    "\n",
    "```{margin}\n",
    "Properties of the population principal components are all valid in the sample context, by replacing\n",
    "\n",
    "$$\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} , \\boldsymbol{\\rho}, \\lambda_i, \\boldsymbol{u} _i$$\n",
    "\n",
    "by\n",
    "\n",
    "$$\\bar{\\boldsymbol{x}}, \\boldsymbol{S} , \\boldsymbol{R} , \\ell_i, \\boldsymbol{a} _i$$\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Special Cases\n",
    "\n",
    "#### Variables are Uncorrelated\n",
    "\n",
    "If $\\boldsymbol{X_i}$ are uncorrelated, then $\\boldsymbol{\\Sigma}$ is a diagonal matrix, i.e., $\\boldsymbol{\\Sigma} = \\operatorname{diag}\\left( \\sigma_{11}, \\sigma_{22}, \\ldots, \\sigma_{dd} \\right)$. Without loss of generality, assume $\\sigma_{11} > \\sigma_{22} > \\ldots > \\sigma_{dd}$, then from its spectral decomposition $\\boldsymbol{\\Sigma} = \\boldsymbol{U} ^\\top \\boldsymbol{\\Lambda} \\boldsymbol{U}$, we have\n",
    "- $\\boldsymbol{U} = \\boldsymbol{I}$\n",
    "- $\\boldsymbol{\\Lambda} = \\operatorname{diag}\\left( \\sigma_{ii} \\right)$, or $\\lambda_i = \\sigma_{ii}$.\n",
    "\n",
    "Hence, the principal component is\n",
    "\n",
    "$$\n",
    "Z_i = X_i\n",
    "$$\n",
    "\n",
    "Clearly, it is **not** necessary to perform PCA in this case.\n",
    "\n",
    "#### Variables are Perfectly Correlated\n",
    "\n",
    "In this case, the covariance matrix is not of full rank, i.e., $\\left\\vert \\boldsymbol{\\Sigma}  \\right\\vert = 0$. Then, some eiganvalues equal zero. In other words,\n",
    "\n",
    "$$\n",
    "\\lambda_1 > \\lambda_2 > \\ldots > \\lambda_m > \\lambda_{m+1} = \\ldots = \\lambda_d = 0\n",
    "$$\n",
    "\n",
    "Only $m$ eigenvectors $\\boldsymbol{u} _i$ can be obtained with $\\left\\Vert \\boldsymbol{u}_i  \\right\\Vert _2 ^2 =  1$ .\n",
    "\n",
    "#### Few Variables Have Extremely Large Variances\n",
    "\n",
    "If a few variables have extremely large variances in comparison with other variables, they will dominate the first few principal components and give the foregone conclusion that a few principal components is sufficient in summarizing information. That conclusion may even be spurious, as the measurement scales, which affect the variances, are quite arbitrary in a lot of applications.\n",
    "\n",
    "For example, $X_1$ is measured in meters while $X_2$ and $X_3$ are measured in kilometers. The first PC should have particularly large variance ($\\lambda_1$ is particularly large relative to $\\lambda_2$ and $\\lambda_3$). This property suggests that if $\\boldsymbol{x}$  are on different, or non-commensurable, measurement units, we should **standardize** them,\n",
    "\n",
    "$$\n",
    "Z_i = \\frac{X_i - \\mu_i}{\\sigma_i}\n",
    "$$\n",
    "\n",
    "before performing PCA.\n",
    "\n",
    "\n",
    "### Cons\n",
    "\n",
    "- Sensitive to variable transformation\n",
    "  - The results of PCA are not invariant under a linear transformation and, even worse, there is no easy correspondence between the two sets of results $\\boldsymbol{z}$ and $\\boldsymbol{z} ^\\top$, before and after the linear transformation. For example, the PCA using $\\boldsymbol{\\Sigma}$ is not the same as the PCA using $\\boldsymbol{\\rho}$ and we cannot use the PCA from $\\boldsymbol{\\rho}$ to get the PCA results from the original variables.\n",
    "  - If the two sets of results are consistent to each other, the PCA based on $\\boldsymbol{\\Sigma}$  may be preferred in some situation. If they are very different, or even contradictory, subject-matter knowledge and/or wisdom are needed to make a choice.\n",
    "  - The PCA based on covariance matrix is preferred when the original measurements units are very important, like in many applications in natural sciences. However, when the units of measurement are of artificial nature, like scores in some questions as frequently used in social sciences, the PCA based on correlation matrix is preferred.\n",
    "\n",
    "- Direction of variance may not be discriminative\n",
    "\n",
    "  But note that the direction of largest variance need not to be the most discriminative direction. See the example below.\n",
    "\n",
    "  :::{figure,myclass} pca-not-discriminative\n",
    "  <img src=\"../imgs/pca-classification.png\" width = \"80%\" alt=\"\"/>\n",
    "\n",
    "  PCA may not be discriminative [Livescu 2021]\n",
    "  :::\n",
    "\n",
    "  If we knew the labels, we could use a supervised dimensionality reduction, e.g. linear discriminant analysis.\n",
    "\n",
    "## Relation to\n",
    "\n",
    "### SVD\n",
    "\n",
    "Recall the SVD of the data matrix\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X}  = \\boldsymbol{U} \\boldsymbol{D} \\boldsymbol{V} ^\\top\n",
    "$$\n",
    "\n",
    "Suppose $X$ is centered, then $n$ times the sample covariance matrix $\\boldsymbol{S}$ is\n",
    "\n",
    "$$\n",
    "n\\boldsymbol{S} = \\boldsymbol{X} ^\\top \\boldsymbol{X} = \\boldsymbol{V} \\boldsymbol{D} ^\\top \\boldsymbol{D} \\boldsymbol{V} ^\\top\n",
    "$$\n",
    "\n",
    "Thus $\\boldsymbol{S} = \\boldsymbol{V} \\left( \\frac{1}{n} \\boldsymbol{D} ^{\\top} \\boldsymbol{D}  \\right) \\boldsymbol{V} ^{\\top}$,\n",
    "\n",
    "- the eigenvectors of $\\boldsymbol{S}$ are the right singular vectors $\\boldsymbol{V}$ of $\\boldsymbol{X}$,\n",
    "- the eigenvalues of $\\boldsymbol{S}$ are proportional to the squared singular values of $\\sigma_i$.\n",
    "\n",
    "So we can compute the PCA solutions via an SVD of data matrix $\\boldsymbol{X}$.\n",
    "- principal directions: $\\boldsymbol{V}$\n",
    "- scores: $\\boldsymbol{Z} =\\boldsymbol{X} \\boldsymbol{V} = \\boldsymbol{U} \\boldsymbol{D} \\boldsymbol{V} ^{\\top} \\boldsymbol{V} = \\boldsymbol{U} \\boldsymbol{D}$.\n",
    "\n",
    "### Compression\n",
    "\n",
    "Instead of storing the $n \\times d$ data matrix $\\boldsymbol{X}$, not we need to store the $d \\times 1$ mean vector $\\boldsymbol{\\mu} _ \\boldsymbol{x}$ and the $k\\times d$ projection matrix $\\boldsymbol{W}$, and the $n \\times k$ projected data matrix $\\boldsymbol{Z}$.\n",
    "\n",
    "To transmit $n$ examples, we need $d+dk+nk$ numbers instead of $nd$.\n",
    "\n",
    "### Gaussians\n",
    "\n",
    "PCA essentially models variance in the data. What distribution is characterized by variance? Gaussian. The covariance matrix parameter in $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} )$ has EVD\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\Sigma}=\\boldsymbol{R}\\left[\\begin{array}{lll}\n",
    "\\lambda_{1} & & \\\\\n",
    "& \\ddots & \\\\\n",
    "& & \\lambda_{d}\n",
    "\\end{array}\\right] \\boldsymbol{R}^{\\top}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{R}$ determines the orientation of the ellipsoid, and the eigenvalues specifies the scaling along the principal directions. The PCA solution $\\boldsymbol{U}$ from the sample covariance matrix $\\boldsymbol{S}$ should be close to $\\boldsymbol{R}$.\n",
    "\n",
    "\n",
    "### Classification\n",
    "\n",
    "For a classification task, we can perform PCA on the features before fitting the data to a classifier. The classifier might be more accurate since PCA reduces noise.\n",
    "\n",
    "(pca-autoencoder)=\n",
    "### Autoencoders\n",
    "\n",
    "PCA can be viewed as an [autoencoder](../37-neural-networks/11-autoencoders) of one single layer with certain constraints.\n",
    "\n",
    "Let\n",
    "- $k(\\boldsymbol{x}, \\boldsymbol{w} )$ be a kernel node parameterized by $\\boldsymbol{w}$ and output the kernel value.\n",
    "- $w_{ij}$ be the weight of the edge from the $i$-th input node to the $j$-th hidden node\n",
    "- $v_{ij}$ be the weight of the edge from the $i$-th hidden node to the $j$-th output node\n",
    "\n",
    "\n",
    "Recall that the projected vector in PCA is\n",
    "\n",
    "$$\n",
    "\\boldsymbol{z} = \\boldsymbol{W} ^\\top \\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "and the reconstruction is\n",
    "\n",
    "$$\n",
    "\\hat{\\boldsymbol{x}} = \\boldsymbol{W} \\boldsymbol{z}\n",
    "$$\n",
    "\n",
    "The objective is to minimize the total reconstruction loss\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{W}^{*}= \\underset{\\boldsymbol{W}}{\\operatorname{argmin}}  &\\ \\sum_{i}^{n}\\left\\|\\boldsymbol{x}_{i}-\\hat{\\boldsymbol{x}}_{i}\\right\\|^{2} \\\\\n",
    "=\\underset{\\boldsymbol{W}}{\\operatorname{argmin}} &\\ \\sum_{i}^{n}\\left\\|\\boldsymbol{x}_{i}-\\boldsymbol{W} \\boldsymbol{z}_{i}\\right\\|^{2} \\\\\n",
    "\\operatorname{s.t.} &\\boldsymbol{W}^{\\top} \\boldsymbol{W}=\\boldsymbol{I} \\\\\n",
    "&\\ \\boldsymbol{W} \\in \\mathbb{R}_{d \\times k}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Hence we can construct a neural network as follows\n",
    "\n",
    "- Input layer:\n",
    "  - $d$ nodes, which represent $\\boldsymbol{x} \\in \\mathbb{R} ^d$\n",
    "\n",
    "- Hidden layer:\n",
    "  - $k$ nodes, which represent $\\boldsymbol{z} \\in \\mathbb{R} ^k$\n",
    "  - The weights $w_{ij}$ are the entires in the matrix $\\boldsymbol{W} \\in \\mathbb{R}_{d \\times k}$, and $\\boldsymbol{W} ^\\top \\boldsymbol{W} = \\boldsymbol{I}$\n",
    "  - The activation function is simply the identity function\n",
    "\n",
    "- Output layer:\n",
    "  - $d$ nodes, which represent $\\hat{\\boldsymbol{x}} \\in \\mathbb{R} ^d$\n",
    "  - The weights $v_{ij} = w_{ji}$\n",
    "  - The activation function is simply the identity function\n",
    "\n",
    "\n",
    "## Identifiability\n",
    "\n",
    "PCA use EVD of sample covariance matrix $\\boldsymbol{S}$. As $n \\rightarrow \\infty$, by the Law of Large numbers, $\\boldsymbol{S} \\rightarrow \\boldsymbol{\\Sigma}$ hence its eigenvalues also converges to those of $\\boldsymbol{\\Sigma}$, i.e. we are able to recover the signal subspace. However, in high dimensional setting where $p$ is large, is this still true?\n",
    "\n",
    "Let $\\gamma = \\lim_{n ,p \\rightarrow \\infty} \\frac{p}{n}$. If $\\gamma > 0$, the top eigenvectors of sample covariance matrices might not reflect the subspace of signals. In fact, there is a threshold of signal-noise ratio.\n",
    "- below a threshold of SNR, PCA fails w.h.p.\n",
    "- above SNR, PCA approximate the signal subspace w.h.p.\n",
    "\n",
    "We illustrate this using a simplest rank-1 (spike) signal model. Suppose a $p$-variate random vector consists of signal and noise\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_i = g_{0, i} \\boldsymbol{u} + \\boldsymbol{g}_i\n",
    "$$\n",
    "\n",
    "where\n",
    "- $\\boldsymbol{u} \\in \\mathbb{R} ^p$ is some fixed signal **direction**, w.l.o.g. set $\\left\\| \\boldsymbol{u}  \\right\\| = 1$.\n",
    "- $g_{0,i} \\sim \\mathcal{N} (0, \\beta)$ and $\\beta$ control randomness and variation (**energy**) of signal\n",
    "- $\\boldsymbol{g}_i \\sim \\mathcal{N} (\\boldsymbol{0} , \\sigma^2 _{\\epsilon}\\boldsymbol{I} _p)$ is white noise, independent of $g_0$.\n",
    "\n",
    "Can we recover signal direction $\\boldsymbol{u}$ from principal component analysis on noisy measurements $\\boldsymbol{x}$? First note the distribution of $\\boldsymbol{x}$ is still Gaussian, with mean and variance\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbb{E} [\\boldsymbol{x}] &= \\boldsymbol{0} \\\\\n",
    "\\boldsymbol{\\Sigma}\n",
    "&= \\beta \\boldsymbol{u} \\boldsymbol{u} ^{\\top} + \\sigma^2 _{\\epsilon}\\boldsymbol{I} _p \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "It is easy to see that the first eigen pair of $\\boldsymbol{\\Sigma}$ is $(\\beta +\\sigma^2 _\\epsilon, \\boldsymbol{u})$ and the other eigenvalues are all 1.\n",
    "\n",
    "How the size of $\\beta$ and $\\sigma^2 _\\epsilon$ affect the identifiability of the signal direction $\\boldsymbol{u}$? Define the signal-noise ratio\n",
    "\n",
    "$$\n",
    "SNR = \\frac{\\beta}{\\sigma^2 _{\\epsilon}}\n",
    "$$\n",
    "\n",
    "For simplicity we assume that $\\sigma^2 _{\\epsilon}=1$ w.l.o.g. Then $SNR = \\beta$. Intuitively, if $\\beta$ is small, then the sample variance matrix is like meaningless $\\boldsymbol{I} _p$. PCA fail to distinguish $\\boldsymbol{u}$ from noise $\\boldsymbol{g}$. Pictorially, when $p=2$, the signal and data points are shown below. If $\\beta$ is too small, then it is hard to distinguish the signal direction from the data points. As $\\beta$ increases, the overall data points suggests a direction aligned with the signal direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abca017a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/runner/work/data-science-handbook/data-science-handbook/_build/jupyter_execute/33-dimensionality-reduction/11-principal-component-analysis_1_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n, p = 100, 2\n",
    "np.random.seed(1)\n",
    "b1, b2, b3 = 1/4, 1, 4\n",
    "u1 = u2 = u3 = np.array([1, 0.5]).reshape(1,2)\n",
    "g0 = np.random.normal(size=(100,1))\n",
    "g = np.random.normal(size=(100, 2))\n",
    "signal1 = np.sqrt(b1) * g0 * u1\n",
    "signal2 = np.sqrt(b2) * g0 * u2\n",
    "signal3 = np.sqrt(b3) * g0 * u3\n",
    "x1 = signal1 + g\n",
    "x2 = signal2 + g\n",
    "x3 = signal3 + g\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(9,3), dpi=200)\n",
    "s = 0.8\n",
    "\n",
    "ax[0].set_title(r'$\\beta=0.25$')\n",
    "ax[0].set(xlim=(-5, 5), ylim=(-5, 5))\n",
    "ax[0].set_aspect('equal', 'box')\n",
    "ax[0].scatter(signal1[:,0], signal1[:,1], s=s, c='C0', label='signal')\n",
    "ax[0].scatter(x1[:,0], x1[:,1], s=s, c='k', label='observed')\n",
    "ax[0].spines.left.set_position('center')\n",
    "ax[0].spines.bottom.set_position('center')\n",
    "ax[0].spines.right.set_color('none')\n",
    "ax[0].spines.top.set_color('none')\n",
    "\n",
    "ax[1].set_title(r'$\\beta=1$')\n",
    "ax[1].set(xlim=(-5, 5), ylim=(-5, 5))\n",
    "ax[1].set_aspect('equal', 'box')\n",
    "ax[1].scatter(signal2[:,0], signal2[:,1], s=s, c='C0')\n",
    "ax[1].scatter(x2[:,0], x2[:,1], s=s, c='k')\n",
    "ax[1].spines.left.set_position('center')\n",
    "ax[1].spines.bottom.set_position('center')\n",
    "ax[1].spines.right.set_color('none')\n",
    "ax[1].spines.top.set_color('none')\n",
    "\n",
    "ax[2].set_title(r'$\\beta=4$')\n",
    "ax[2].set(xlim=(-5, 5), ylim=(-5, 5))\n",
    "ax[2].set_aspect('equal', 'box')\n",
    "ax[2].scatter(signal3[:,0], signal3[:,1], s=s, c='C0')\n",
    "ax[2].scatter(x3[:,0], x3[:,1], s=s, c='k')\n",
    "ax[2].set_ylim\n",
    "ax[2].spines.left.set_position('center')\n",
    "ax[2].spines.bottom.set_position('center')\n",
    "ax[2].spines.right.set_color('none')\n",
    "ax[2].spines.top.set_color('none')\n",
    "\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a598a",
   "metadata": {},
   "source": [
    "We are interested in high-dimensional setting $n, p \\rightarrow \\infty$, under what conditions of $\\beta$ and $\\gamma$ can we detect $\\boldsymbol{u}$ via PCA from the observed data $\\boldsymbol{X}$. Let $\\widehat{\\boldsymbol{\\Sigma}}_{n} = \\frac{1}{n} \\boldsymbol{X} ^{\\top} \\boldsymbol{X}$ and $(\\hat{\\lambda}, \\hat{\\boldsymbol{u}})$ be its top eigen pair, here detection means\n",
    "- the top eigenvalue $\\hat{\\lambda}$ due to signal $\\boldsymbol{u}$ is distinguishable from those due to noise $\\boldsymbol{g}$\n",
    "- the estimated signal direction $\\hat{\\boldsymbol{u}}$ is close to the true signal direction $\\boldsymbol{u}$, measured by $\\langle \\hat{\\boldsymbol{u}} , \\boldsymbol{u} \\rangle \\ne 0$ w.h.p.\n",
    "\n",
    "### Phase Transition\n",
    "\n",
    "With random matrix theory, using the [Marchenko-pastur Distribution](marchenko-pastur-distribution), we have the following conclusions, as $n, p \\rightarrow \\infty$:\n",
    "\n",
    "- The largest eigenvalue $\\hat{\\lambda}$ satisfies\n",
    "\n",
    "  $$\n",
    "  \\lambda_{\\max }\\left(\\widehat{\\boldsymbol{\\Sigma}}_{n}\\right) \\rightarrow\\left\\{\\begin{array}{ll}\n",
    "  (1+\\sqrt{\\gamma})^{2}=\\gamma_{+}, & \\beta \\leq \\sqrt{\\gamma} \\\\\n",
    "  \\left(1+\\beta\\right)\\left(1+\\frac{\\gamma}{\\beta}\\right) > \\gamma_{+}, & \\beta>\\sqrt{\\gamma}\n",
    "  \\end{array}\\right.\n",
    "  $$\n",
    "\n",
    "  - if signal energy (or SNR) $\\beta$ is smaller than $\\sqrt{\\gamma}$, the top eigenvalue of sample covariance matrix never 'pops up' from those of noise random matrix $\\operatorname{Cov}\\left( \\boldsymbol{g}  \\right)$, which follows M-P distribution in range $[\\gamma_{-}, \\gamma_{+}]$. That is, we don't know whether it is due to signal $\\boldsymbol{u}$ or due to noise $\\boldsymbol{g}$.\n",
    "  - only if the signal energy $\\beta$ is beyond the phase transition threshold $\\sqrt{\\gamma}$, the top eigenvalue can be separated from noise random matrix eigenvalues. However, even in the latter case it is a **biased** estimation of the top eigenvalue $(1 + \\beta)$.\n",
    "\n",
    "- The estimated signal direction $\\hat{\\boldsymbol{u} }$ satisfies\n",
    "\n",
    "  $$\n",
    "  \\left|\\left\\langle \\boldsymbol{u} , \\hat{\\boldsymbol{u} }\\right\\rangle\\right|^{2} \\rightarrow\\left\\{\\begin{array}{ll}\n",
    "  0 & \\beta \\leq \\sqrt{\\gamma} \\\\\n",
    "  \\frac{1-\\gamma/\\beta^2}{1+\\gamma/\\beta^2}  & \\beta>\\sqrt{\\gamma}\n",
    "  \\end{array}\\right.\n",
    "  $$\n",
    "\n",
    "  - if signal is of low energy $(\\beta \\le \\sqrt{\\gamma})$, the estimated top eigenvector is **orthogonal** to the true direction $\\boldsymbol{u}$. PCA will tell us nothing about the true signal. In the extreme case $\\beta = 0$, the largest eigenvector returned by PCA is just that from $\\operatorname{Cov}\\left( \\boldsymbol{g}  \\right) = \\boldsymbol{I} _p$, which is purely a random direction.\n",
    "  - if the signal is of high energy $(\\beta \\ge \\sqrt{\\gamma})$, PCA will return a **biased** estimation which lies over a lateral surface of a **cone** whose angle with the true signal is $\\arccos \\left( \\sqrt{\\frac{1-\\gamma/\\beta^2}{1+\\gamma/\\beta^2} } \\right)$.\n",
    "\n",
    "\n",
    "For derivation when $\\beta > \\sqrt{\\gamma}$ case, see Yao's [notes](https://github.com/yao-lab/yao-lab.github.io/blob/master/book_datasci.pdf) (there are some typos). For the limiting distribution of $\\lambda_{max}$, see [Johnstone](https://arxiv.org/pdf/math/0611589.pdf) p.16-17.\n",
    "\n",
    "Key techniques in Yao's notes:\n",
    "- Use 'whitening' $\\boldsymbol{Z} = \\boldsymbol{\\Sigma} ^{-1/2} \\boldsymbol{X} \\sim \\mathcal{N} (\\boldsymbol{0} , \\boldsymbol{I} _p)$ and then $\\hat{\\boldsymbol{\\Sigma} }_{n}=\\frac{1}{n} \\boldsymbol{X} \\boldsymbol{X} ^{T}=\\boldsymbol{\\Sigma} ^{1 / 2}\\left(\\frac{1}{n} \\boldsymbol{Z} \\boldsymbol{Z} ^{T}\\right) \\boldsymbol{\\Sigma} ^{1 / 2}$ to relate the eigenvalue $\\hat{\\lambda}$ of $\\hat{\\boldsymbol{\\Sigma} }_n$ with M-P distribution for eigenvalues of $\\frac{1}{n} \\boldsymbol{Z} \\boldsymbol{Z} ^{T}$.\n",
    "- Use integration to approximate infinite summation, if\n",
    "  - The summation can be expressed as the expectation of some continuous random variable with known distribution function\n",
    "  - The number of terms in the summation, denoted $p$, is large enough, $p \\rightarrow \\infty$\n",
    "  - No term 'explode' to $\\infty$. For instance, for the summation $\\sum_{i=1}^p \\frac{c}{\\lambda - \\lambda_j}$ where $\\lambda_j \\sim f_{MP}$ over $[\\gamma_-, \\gamma_+]$, if $\\lambda \\in [\\gamma_-, \\gamma_+]$, then as $p \\rightarrow \\infty$, some denominator $\\lambda - \\lambda_j$ will be infinitely small, and that term explode.\n",
    "\n",
    "### Comparison to Davis-Kahan Theorem\n",
    "\n",
    "Recall: $\\boldsymbol{x}_i = g_{0,i} \\boldsymbol{u} + \\boldsymbol{g} _i$. If we use [Davis-Kahan theorem](davis-kahan), where\n",
    "- truth: $\\boldsymbol{M} = \\beta \\boldsymbol{u} \\boldsymbol{u} ^{\\top}$\n",
    "- noise: $\\boldsymbol{H} = \\frac{1}{n} \\sum_{i=1}^n  \\boldsymbol{g}_i \\boldsymbol{g}_i ^{\\top}$\n",
    "- observed:\n",
    "\n",
    "  $$\\begin{aligned}\n",
    "  \\widehat{\\boldsymbol{M}}\n",
    "  &=\\widehat{\\boldsymbol{\\Sigma}} _n \\\\\n",
    "  &= \\frac{1}{n} \\sum_{i=1}^n \\boldsymbol{x}_i \\boldsymbol{x}_i ^{\\top} \\\\\n",
    "  &= \\beta \\boldsymbol{u} \\boldsymbol{u} ^{\\top} + \\boldsymbol{u}  \\left(  \\frac{1}{n} \\sum g_{0, i} \\boldsymbol{g}_i ^{\\top}  \\right)+  \\left( \\frac{1}{n} \\sum g_{0, i}  \\boldsymbol{g}_i \\right) \\boldsymbol{u}  ^{\\top} + \\frac{1}{n} \\sum \\boldsymbol{g}_i \\boldsymbol{g}_i ^{\\top}   \\\\\n",
    "  &\\overset{n,p\\rightarrow \\infty}{=} \\beta \\boldsymbol{u} \\boldsymbol{u} ^{\\top} + \\frac{1}{n} \\sum \\boldsymbol{g}_i \\boldsymbol{g}_i ^{\\top}\\\\\n",
    "  &= \\boldsymbol{M} + \\boldsymbol{H}   \\\\\n",
    "  \\end{aligned}$$\n",
    "\n",
    "  Note that the cross-product term converges to $\\boldsymbol{0}$ since $g_{0,i} \\perp \\boldsymbol{g}_i$,  while the last term does not converge to $\\boldsymbol{I} _p$ since $p/n \\rightarrow \\gamma$, i.e. no enough samples for big (and growing) dimensions.\n",
    "\n",
    "The distance between the first eigenvector $\\hat{\\boldsymbol{u}}$ of $\\widehat{\\boldsymbol{M}}$ and $\\boldsymbol{u}$ of the truth $\\boldsymbol{M}$ is\n",
    "\n",
    "$$\n",
    "\\operatorname{dist}(\\hat{\\boldsymbol{u}}, \\boldsymbol{u})=\\left\\|\\hat{\\boldsymbol{u}} \\hat{\\boldsymbol{u}}^{\\top}-\\boldsymbol{u} \\boldsymbol{u}^{\\top}\\right\\|_{2} \\leq \\frac{\\|\\boldsymbol{H}\\|}{\\lambda_1(\\boldsymbol{M}) - \\lambda_2(\\boldsymbol{M} )-\\|\\boldsymbol{H} \\|} = \\frac{\\gamma_{+}}{\\lambda_1 - \\lambda_2 - \\gamma_{+}}\n",
    "$$\n",
    "\n",
    "where the spectral norm $\\|\\boldsymbol{H}\\| = \\gamma_{+}$ since the eigenvalues of $\\boldsymbol{H}$ follows [Marchenko-Pastur Distribution](marchenko-pastur-distribution) where the upper bound is $\\gamma_{+}$.\n",
    "\n",
    "If we want $|\\langle \\boldsymbol{u} ,  \\hat{\\boldsymbol{u}}\\rangle| ^2 > c$, then it is equivalent to $\\left\\|\\hat{\\boldsymbol{u}} \\hat{\\boldsymbol{u}}^{\\top}-\\boldsymbol{u} \\boldsymbol{u}^{\\top}\\right\\|_{2}^2 < 1-c$ since they [sum up to](norm) 1. That is, the denominator has some lower bound, i.e. $\\lambda_1 - \\lambda_2 - \\gamma_{+}>  b$. In the spike model, $\\lambda_1 - \\lambda_2 = \\beta - 0 = \\beta$. Hence, the condition for $\\beta$ is\n",
    "\n",
    "$$\n",
    "\\beta > (1 + \\sqrt{\\gamma})^2 + b\n",
    "$$\n",
    "\n",
    "This condition is stronger than the above result: $\\beta > \\sqrt{\\gamma}$ is ok."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.9.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "source_map": [
   14,
   734,
   790
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}