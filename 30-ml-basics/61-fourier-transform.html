
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Fourier Transform-based Representations &#8212; Data Science Handbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Regression" href="../31-regression/00-regression.html" />
    <link rel="prev" title="Self-supervised Learning" href="53-self-supervised.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      <h1 class="site-logo" id="site-title">Data Science Handbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Data Science Handbook
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-math/00-math.html">
   Math
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/11-combinatorics.html">
     Combinatorics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/20-vector-spaces.html">
     Vector Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/31-geometry.html">
     Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/21-linear-algebra.html">
     Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/51-linear-programming.html">
     Linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/52-non-linear-programming.html">
     Non-linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/90-puzzles.html">
     Puzzles
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12-probabilities/00-probabilities.html">
   Probabilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/11-expectation-and-variance.html">
     Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/13-correlation-and-dependence.html">
     Correlation and Dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/31-bayesian-theorem.html">
     Bayesian’s Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/51-markov-chain.html">
     Markov Chain
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/71-sampling.html">
     Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/90-multivariate-notations.html">
     Multivariate Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/91-exponential-families.html">
     Exponential Families
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/91-large-sample-theory.html">
     Large Sample Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../13-statistics/00-statistics.html">
   Statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/11-sample-survey.html">
     Sample Survey
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/13-randomized-trial.html">
     Randomized Controlled Trials
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/21-hypothesis-testing.html">
     Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/23-common-tests.html">
     Common Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/33-confusion-matrix.html">
     Confusion Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/41-maximum-likelihood-estimation.html">
     Maximum Likelihood Estimator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../13-statistics/43-estimators-evaluation.html">
     Estimators Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15-tools/00-tools.html">
   Tools
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/11-python.html">
     Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/21-r.html">
     R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/31-sql.html">
     SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/41-latex.html">
     LaTeX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/51-myst.html">
     MyST Markdown
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20-algorithms-concepts/00-algorithms-concepts.html">
   Algorithms Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/51-polynomial-reduction.html">
     Polynomial Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/53-P-and-NP.html">
     <span class="math notranslate nohighlight">
      \(P\)
     </span>
     and
     <span class="math notranslate nohighlight">
      \(NP\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/61-randomized-algo.html">
     Randomized Algorithms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../21-greedy-algorithms/00-greedy-algorithms.html">
   Greedy Algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/11-interval-scheduling.html">
     Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/31-huffman-coding.html">
     Huffman Coding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../23-dynamic-programming/00-dynamic-programming.html">
   Dynamic Programming
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/11-weighted-interval-scheduling.html">
     Weighted Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/13-longest-common-subsequence.html">
     Longest Common Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/15-longest-increasing-subsequence.html">
     Longest Increasing Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/17-largest-sum-subsequence.html">
     Largest Sum Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/31-knapsack.html">
     Minimum Knapsack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/51-chain-matrix-multiplication.html">
     Chain Matrix Multiplication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../25-graph-related/00-graph-related.html">
   Graph Related
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/13-shortest-path.html">
     Shortest Path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/21-minimum-spanning-tree.html">
     Minimum Spanning Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/31-maximum-flow.html">
     Maximum Flow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/32-matching.html">
     Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/42-maximum-independent-set.html">
     Maximum Independent Set in Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/91-LP-max-flow-min-cut.html">
     LP on Max-flow and Min-cut
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../26-algo-for-big-data/00-algo-for-big-data.html">
   For Big Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../26-algo-for-big-data/10-streaming.html">
     Streaming Model
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00-ml-basics.html">
   Machine Learning Basics
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="02-taxonomy.html">
     Taxonomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03-information-theory.html">
     Information Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05-kernels.html">
     Kernels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11-data-issues.html">
     Data Issues
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="51-semi-supervised.html">
     Semi-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="53-self-supervised.html">
     Self-supervised Learning
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Fourier Transform-based Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../31-regression/00-regression.html">
   Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/11-lm-estimation.html">
     Linear Models - Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/12-lm-inference.html">
     Linear Models - Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/13-lm-diagnosis.html">
     Linear Models - Diagnosis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/14-lm-advanced.html">
     Linear Models - Advanced Topics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/21-generalized-linear-models.html">
     Generalized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/22-logistic-regression.html">
     Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/23-multinomial-logitsitc.html">
     Multinomial Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/24-ordinal-logistic.html">
     Ordinal Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/25-poisson-regression.html">
     Poisson Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/31-multivariate-regression.html">
     Multivariate Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../32-classification/00-classification.html">
   Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/09-k-nearest-neighbors.html">
     K-nearest neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/11-support-vector-machine.html">
     Support Vector Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/11-normal.html">
     For Normal Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/21-decision-tree.html">
     Decision Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/31-linear-discriminant-analysis.html">
     Linear Discriminant Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../33-dimensionality-reduction/00-dimensionality-reduction.html">
   Dimensionality Reduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/11-principal-component-analysis.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/13-canonical-correlation-analysis.html">
     Canonical Correlation Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/21-multidimensional-scaling.html">
     Multidimensional Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/23-graph-based-spectral-methods.html">
     Graph-based Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/25-t-SNE.html">
     SNE and
     <span class="math notranslate nohighlight">
      \(t\)
     </span>
     -SNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/31-kernel-pca.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/32-kernel-cca.html">
     Kernel CCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/41-factor-analysis.html">
     Factor Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/51-correspondence-analysis.html">
     Correspondence Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../34-clustering/00-clustering.html">
   Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/11-k-means.html">
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/13-agglomerative-methods.html">
     Agglomerative Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/31-spectral-clustering.html">
     Spectral Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/41-gaussian-mixtures.html">
     Gaussian Mixtures
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../35-graphical-models/00-graphical-models.html">
   Graphical Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/03-random-walks.html">
     Random Walks in Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/11-hidden-markov-models.html">
     Hidden Markov Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/31-topic-models.html">
     Topic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/33-language-models.html">
     Language Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../37-neural-networks/00-neural-networks.html">
   Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/01-stochastic-gradient-descent.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/03-trainability.html">
     Trainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/05-regularization.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/11-autoencoders.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/13-variational-autoencoders.html">
     Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/31-sequential-models.html">
     Sequential Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/41-GAN.html">
     Generative Adversarial Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../38-ml-for-graph-data/00-ml-for-graph-data.html">
   For Graph-structured Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/01-graph-basics.html">
     Graph Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/11-descriptive-analysis.html">
     Descriptive Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/13-sampling-and-estimation.html">
     Sampling and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/21-modeling.html">
     Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/31-topology-inference.html">
     Topology Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/41-processes.html">
     Processes on Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/51-graph-rep-learning.html">
     Graph Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/30-ml-basics/61-fourier-transform.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/dennissxz/data-science-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/dennissxz/data-science-handbook/issues/new?title=Issue%20on%20page%20%2F30-ml-basics/61-fourier-transform.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basics">
   Basics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#main-idea">
     Main idea
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation">
     Motivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples-and-applications">
     Examples and Applications
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discrete-fourier-transform-dft">
   Discrete Fourier Transform (DFT)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformation">
     Transformation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relation-between-x-k-and-a-k">
     Relation between
     <span class="math notranslate nohighlight">
      \(X_k\)
     </span>
     and
     <span class="math notranslate nohighlight">
      \(a_k\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples">
     Examples
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continuous-time-fourier-transform">
   Continuous-time Fourier Transform
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-discrete-time-fourier-series-transforms">
   2-D Discrete-“time” Fourier series/transforms
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-discrete-time-convolution">
   2-D Discrete-“time” convolution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications-to-machine-learning">
   Applications to Machine Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-fourier-features">
     Random Fourier Features
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#faster-cnn-training">
     Faster CNN Training
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="fourier-transform-based-representations">
<h1>Fourier Transform-based Representations<a class="headerlink" href="#fourier-transform-based-representations" title="Permalink to this headline">¶</a></h1>
<p>Why study Fourier transform in ML?</p>
<ul class="simple">
<li><p>Staple of feature representation for many types of data (audio, images, others) for many decades, still useful in many settings</p></li>
<li><p>Also useful for deriving new algorithms in machine learning</p></li>
</ul>
<p>Before we do any learning, we start with some data representation. Typically, this involves converting raw data into feature vectors. These days, much of feature engineering is replaced by neural network-based feature learning. But not all…choice of initial representation can still be important for</p>
<ul class="simple">
<li><p>Visualization of raw data</p></li>
<li><p>Qualitative understanding of the data</p></li>
<li><p>Better input to a learning algorithm</p></li>
<li><p>When number of observations is small, handcraft features are also useful than complicated models, e.g. neural networks</p></li>
</ul>
<p>Fourier methods include</p>
<ul class="simple">
<li><p>Discrete-time and continuous-time Fourier series</p></li>
<li><p>Discrete-time and continuous-time Fourier transforms</p></li>
<li><p>Discrete Fourier transform (most common for digital signals)</p></li>
</ul>
<div class="section" id="basics">
<h2>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">¶</a></h2>
<div class="section" id="main-idea">
<h3>Main idea<a class="headerlink" href="#main-idea" title="Permalink to this headline">¶</a></h3>
<p>Decompose a signal <span class="math notranslate nohighlight">\(\left\{ \boldsymbol{x} _t \right\}=x_0, x_1, \ldots, x_{N-1}\)</span> as a sum of multiple sinusoids at different frequencies</p>
<div class="math notranslate nohighlight">
\[x_t=\sum_{k} a_{k} f_{k}(t)\]</div>
<p>where</p>
<ul class="simple">
<li><p>Signal = function of a discrete “time” variable <span class="math notranslate nohighlight">\(n\)</span></p></li>
<li><p>Subscript notation reminds us that the time variable is discrete</p></li>
<li><p><span class="math notranslate nohighlight">\(f_k(t)\)</span> sinusoid (sine/cosine function) at frequency indexed by <span class="math notranslate nohighlight">\(k\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(a_k =\)</span> “amount” of frequency <span class="math notranslate nohighlight">\(k\)</span> present in <span class="math notranslate nohighlight">\(\left\{ \boldsymbol{x} _t \right\}\)</span>, aka “<strong>spectrum</strong>” of the signal (but this word has other meanings).</p></li>
<li><p>Fourier transform algorithms: ways of finding <span class="math notranslate nohighlight">\(a_k\)</span> given <span class="math notranslate nohighlight">\(\left\{ \boldsymbol{x} _t \right\}\)</span></p></li>
</ul>
<p>Demo:</p>
<ul class="simple">
<li><p>http://www.falstad.com/dfilter/</p></li>
<li><p>https://www.youtube.com/watch?v=spUNpyF58BY&amp;ab_channel=3Blue1Brown</p></li>
</ul>
</div>
<div class="section" id="motivation">
<h3>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¶</a></h3>
<p>Physiology of hearing suggest that the structure of human ears are doing Fourier transform.</p>
<div class="figure align-default" id="fourier-ear">
<a class="reference internal image-reference" href="../_images/fourier-ear.png"><img alt="" src="../_images/fourier-ear.png" style="width: 30%;" /></a>
<p class="caption"><span class="caption-number">Fig. 49 </span><span class="caption-text">Hairs in the cochlea (3) have different frequency responses [<a class="reference external" href="http://texasearcenter.com">image link</a>]</span><a class="headerlink" href="#fourier-ear" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="examples-and-applications">
<h3>Examples and Applications<a class="headerlink" href="#examples-and-applications" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Speech</p>
<div class="figure align-default" id="fourier-speech">
<a class="reference internal image-reference" href="../_images/spectral-clustering-speech-sep.png"><img alt="" src="../_images/spectral-clustering-speech-sep.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-number">Fig. 50 </span><span class="caption-text">Separate components from a speech (apply FT to rolling windows)</span><a class="headerlink" href="#fourier-speech" title="Permalink to this image">¶</a></p>
</div>
</li>
<li><p>Financial market data</p></li>
<li><p>Weather data</p></li>
<li><p>Medical imaging, other scientific imaging</p></li>
<li><p>Image compression (e.g. JPEG)</p></li>
</ul>
<p>Applications to machine learning</p>
<ul class="simple">
<li><p>Feature extraction, compression and de-noising of speech/images: Can be an important precursor to unsupervised (or supervised) learning</p></li>
<li><p>Approximating kernels [Rahimi &amp; Recht 2007]</p></li>
<li><p>Speeding up convolutional neural networks [Mathieu et al. 2013]</p></li>
<li><p>Analyzing and regularizating neural networks [Aghazadeh et al. 2020]</p></li>
</ul>
</div>
</div>
<div class="section" id="discrete-fourier-transform-dft">
<h2>Discrete Fourier Transform (DFT)<a class="headerlink" href="#discrete-fourier-transform-dft" title="Permalink to this headline">¶</a></h2>
<p>We often start with a very long signal and compute its spectrum over sub-sequences (“windows”) of fixed length <span class="math notranslate nohighlight">\(N\)</span> starting at sample <span class="math notranslate nohighlight">\(t\)</span></p>
<div class="math notranslate nohighlight">
\[
\left\{ \boldsymbol{x}_t \right\} = x_t, x_{t+1}, \ldots x_{t+N-1}
\]</div>
<div class="section" id="transformation">
<h3>Transformation<a class="headerlink" href="#transformation" title="Permalink to this headline">¶</a></h3>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Euler’s relation <span class="math notranslate nohighlight">\(e^{j a}=\cos (a)+j \sin (a)\)</span> is used in derivation</p>
</div>
<p>The <em>discrete Fourier transform</em> (DFT) transforms <span class="math notranslate nohighlight">\(\left\{ \boldsymbol{x}_t \right\}\)</span> into another sequence <span class="math notranslate nohighlight">\(\left\{ \boldsymbol{X} _k \right\} = X_0, X_1, \ldots, X_{N-1}\)</span> where</p>
<div class="math notranslate nohighlight">
\[
X_k=\sum_{n=t}^{t+N-1} x_n e^{-j 2 \pi k n / N}, \quad k=0, \ldots, N-1
\]</div>
<ul class="simple">
<li><p>The DFT <span class="math notranslate nohighlight">\(\left\{ \boldsymbol{X} _k \right\}\)</span> is also called the <strong>spectrum</strong>. <span class="math notranslate nohighlight">\(X_k\)</span> is the value of the spectrum at the <span class="math notranslate nohighlight">\(k\)</span>-th frequency</p></li>
<li><p>Equivalently, we can consider <span class="math notranslate nohighlight">\(k = −N/2,...,0,...,N/2\)</span>, i.e. the sequence is <span class="math notranslate nohighlight">\(N\)</span>-periodic. Sometimes people write <span class="math notranslate nohighlight">\(\sum_{n=&lt;N&gt;}\)</span> for simplicity</p></li>
<li><p>The fast Fourier transform (FFT) is an algorithm used to compute DFT for window length <span class="math notranslate nohighlight">\(M = 2m\)</span> for some <span class="math notranslate nohighlight">\(m\)</span>.</p></li>
<li><p>After doing this for all frames (windows) of a signal, the result is a
<strong>spectrogram</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(X_k\)</span> is in general complex-valued</p>
<ul>
<li><p>often only the real part of it is used. (Why complex numbers? Real-world signals are real… but complex signals are often much easier to analyze)</p></li>
<li><p>we often use only its magnitude or phase</p></li>
</ul>
</li>
<li><p>units:</p>
<ul>
<li><p>Each time sample n corresponds to a time in seconds</p></li>
<li><p>Each frequency sample k corresponds to a frequency <span class="math notranslate nohighlight">\(f(k) = \frac{k}{N} R\)</span> in Hz, where R is the sampling rate.</p></li>
</ul>
</li>
</ul>
<p>Important property: Spectra of real signals are conjugate-symmetric</p>
<ul class="simple">
<li><p>Magnitude is symmetric about <span class="math notranslate nohighlight">\(k = 0\)</span> (equivalently about <span class="math notranslate nohighlight">\(N/2\)</span>)</p></li>
<li><p>Phase is anti-symmetric about <span class="math notranslate nohighlight">\(k = 0\)</span> (equivalently about <span class="math notranslate nohighlight">\(N/2\)</span>)</p></li>
<li><p>So we need only think about positive frequencies</p></li>
</ul>
</div>
<div class="section" id="relation-between-x-k-and-a-k">
<h3>Relation between <span class="math notranslate nohighlight">\(X_k\)</span> and <span class="math notranslate nohighlight">\(a_k\)</span><a class="headerlink" href="#relation-between-x-k-and-a-k" title="Permalink to this headline">¶</a></h3>
<p>For historical reasons we will define <span class="math notranslate nohighlight">\(X_k=N a_k\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[
a_{k}=\frac{1}{N} \sum_{n=&lt;N&gt;} x_n e^{-j k \omega_{0} n}
\]</div>
<p>which is called the <strong>analysis equation</strong>.</p>
<p>The decomposition is called the <strong>synthesis equation</strong></p>
<div class="math notranslate nohighlight">
\[
x_n=\sum_{k=&lt;N&gt;} a_{k} e^{j k \omega_{0} n}
\]</div>
<p>Note that</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(ω0 = 2π/N\)</span></p></li>
<li><p>Notation: Sometimes written <span class="math notranslate nohighlight">\(x_n \leftrightarrow a_k\)</span></p></li>
<li><p>Convenient to think of <span class="math notranslate nohighlight">\(a_k\)</span> as being defined for all <span class="math notranslate nohighlight">\(k\)</span>, although we only need a subset of <span class="math notranslate nohighlight">\(N\)</span> of them: <span class="math notranslate nohighlight">\(a_{k+N} = a_k\)</span></p></li>
<li><p>Since <span class="math notranslate nohighlight">\(x_n\)</span> is periodic, it is specified uniquely by only <span class="math notranslate nohighlight">\(N\)</span> numbers, either in time or in frequency domain</p></li>
</ul>
</div>
<div class="section" id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<p>Cosine function</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
x_n &amp;=\cos \left(\frac{\pi}{4} n\right) \\
&amp;=\frac{1}{2}\left(e^{j \pi n / 4}+e^{-j \pi n / 4}\right) \\
\Longrightarrow \omega_{0} &amp;=\pi / 4, N=8, a_{1}=a_{-1}=1 / 2, X[1]=X[-1]=8 \frac{1}{2}=4
\end{aligned}
\end{split}\]</div>
<p>Sine function</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
x_n &amp;=\sin \left(\frac{\pi}{4} n\right) \\
&amp;=\frac{1}{2 j}\left(e^{j \pi n / 4}-e^{-j \pi n / 4}\right) \\
\Longrightarrow \omega_{0} &amp;=\pi / 4, N=8, a_{1}=\frac{1}{2 j}, a_{-1}=-\frac{1}{2 j}
\end{aligned}
\end{split}\]</div>
</div>
</div>
<div class="section" id="continuous-time-fourier-transform">
<h2>Continuous-time Fourier Transform<a class="headerlink" href="#continuous-time-fourier-transform" title="Permalink to this headline">¶</a></h2>
<p>Even though we mainly deal with digitized data, we sometimes wish to reason about continuous-time functions. Continuous-time Fourier transform describes signals as continuous “sums” (integrals) of sinusoids at arbitrary frequency <span class="math notranslate nohighlight">\(\omega\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
x(t) &amp;=\frac{1}{2 \pi} \int_{-\infty}^{\infty} X(j \omega) e^{j \omega t} \mathrm{~d} \omega &amp;\text { Synthesis equation } \\
X(j \omega) &amp;=\int_{-\infty}^{\infty} x(t) e^{-j \omega t}  \mathrm{~d} t &amp; \text { Analysis equation }
\end{aligned}\end{split}\]</div>
</div>
<div class="section" id="d-discrete-time-fourier-series-transforms">
<h2>2-D Discrete-“time” Fourier series/transforms<a class="headerlink" href="#d-discrete-time-fourier-series-transforms" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
X_{k l}=&amp; \frac{1}{M N} \sum_{&lt;N&gt;} \sum_{&lt;M&gt;} x[m, n] e^{-j 2 \pi(n k / N+m l / M)} \\
&amp; \text{where }  0 \leq k \leq N-1,0 \leq l \leq M-1 \\
x[m, n]=&amp; \sum_{k=0}^{N-1} \sum_{l=0}^{M-1} X_{k l} e^{j 2 \pi(n k / N+m l / M)}
\end{aligned}
\end{split}\]</div>
<ul class="simple">
<li><p>Equivalent to 1-D transforms when one frequency dim is <strong>fixed</strong>.</p></li>
<li><p>2-D fast Fourier transform requires <span class="math notranslate nohighlight">\(M N (\log _{2} M) (\log _{2} N)\)</span> operations.</p></li>
</ul>
</div>
<div class="section" id="d-discrete-time-convolution">
<h2>2-D Discrete-“time” convolution<a class="headerlink" href="#d-discrete-time-convolution" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[
y\left[n_{1}, n_{2}\right]=x\left[n_{1}, n_{2}\right] * h\left[n_{1}, n_{2}\right]=\sum_{k_{1}=-\infty}^{\infty} \sum_{k_{2}=-\infty}^{\infty} x\left[k_{1}, k_{2}\right] h\left[n_{1}-k_{1}, n_{2}-k_{2}\right]
\]</div>
<ul class="simple">
<li><p>This is the operation being done in convolutional neural networks, on the image <span class="math notranslate nohighlight">\(x\)</span> and the filter <span class="math notranslate nohighlight">\(h\)</span>.</p></li>
<li><p>But we typically don’t bother with flipping the filter and state it as a dot product</p></li>
<li><p>The properties of convolution tell us <span class="math notranslate nohighlight">\(Y_{k l}=X_{k l} H_{k l}\)</span></p></li>
</ul>
</div>
<div class="section" id="applications-to-machine-learning">
<h2>Applications to Machine Learning<a class="headerlink" href="#applications-to-machine-learning" title="Permalink to this headline">¶</a></h2>
<div class="section" id="random-fourier-features">
<h3>Random Fourier Features<a class="headerlink" href="#random-fourier-features" title="Permalink to this headline">¶</a></h3>
<p>We introduced that computing kernel matrix is computationally expensive. We can approximate <span class="math notranslate nohighlight">\(\phi(\boldsymbol{x})\)</span> corresponding to a given kernel.</p>
<dl class="simple myst">
<dt>Theorem (Bochner’s)</dt><dd><p>Shift-invariant kernels (only depends on the difference <span class="math notranslate nohighlight">\(\boldsymbol{x} -\boldsymbol{y} \)</span>) are <span class="math notranslate nohighlight">\(n\)</span>-dimensional continuous Fourier transforms of some probability distribution <span class="math notranslate nohighlight">\(p(\boldsymbol{\omega} )\)</span>,</p>
</dd>
</dl>
<div class="math notranslate nohighlight">
\[
k(\boldsymbol{x} , \boldsymbol{y} )=k(\boldsymbol{x} -\boldsymbol{y} )=\int p(\boldsymbol{\omega} ) e^{j \boldsymbol{\omega}  ^{\top} (\boldsymbol{x} -\boldsymbol{y} )} \mathrm{~d} w=\mathbb{E}_{\omega}\left[\xi_{\omega}(\boldsymbol{x} ) \xi_{\omega}(\boldsymbol{y} )^{*}\right]
\]</div>
<p>where <span class="math notranslate nohighlight">\(\xi_{\omega}(\boldsymbol{x} )=e^{j \boldsymbol{\omega}  ^{\top}  \boldsymbol{y} }\)</span>.</p>
<p>So, we can estimate the kernel by <strong>averaging</strong> a bunch of such products for various random drawn values of <span class="math notranslate nohighlight">\(\boldsymbol{\omega}\)</span>.</p>
<p>Idea: Use a feature map <span class="math notranslate nohighlight">\(\phi(\boldsymbol{x})\)</span> that is a concatenation of a bunch of <span class="math notranslate nohighlight">\(\xi\)</span>’s. Then we have an explicit nonlinear map, and no need to do large kernel computations!</p>
<p>For Gaussian, Laplacian and Cauchy kernel, <span class="math notranslate nohighlight">\(p(\boldsymbol{\omega})\)</span> is easy to find.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{lll}
\text { Kernel Name } &amp; k(\Delta) &amp; p(\boldsymbol{\omega}) \\
\hline \text { Gaussian } &amp; e^{-\frac{\|\Delta\|_{2}^{2}}{2}} &amp; (2 \pi)^{-\frac{D}{2}} e^{-\frac{\|\omega\|_{2}^{2}}{2}} \\
\text { Laplacian } &amp; e^{-\|\Delta\|_{1}} &amp; \prod_{d} \frac{1}{\pi\left(1+\boldsymbol{\omega}_{d}^{2}\right)} \\
\text { Cauchy } &amp; \prod_{d} \frac{2}{1+\Delta_{d}^{2}} &amp; e^{-\|\Delta\|_{1}}
\end{array}
\end{split}\]</div>
<hr class="docutils" />
<p><strong>Algorithm</strong>: Random Fourier Features.</p>
<hr class="docutils" />
<ul class="simple">
<li><p>Require: A positive definite shift-invariant kernel <span class="math notranslate nohighlight">\(k(\boldsymbol{x}, \boldsymbol{y})=k(\boldsymbol{x}-\boldsymbol{y})\)</span></p></li>
<li><p>Ensure: A randomized feature map <span class="math notranslate nohighlight">\(\boldsymbol{z}(\boldsymbol{x}): \mathcal{R}^{d} \rightarrow \mathcal{R}^{2 D}\)</span> so that <span class="math notranslate nohighlight">\(\boldsymbol{z}(\boldsymbol{x})^{\prime} \boldsymbol{z}(\boldsymbol{y}) \approx k(\boldsymbol{x}-\boldsymbol{y})\)</span></p></li>
<li><p>Compute the Fourier transform  <span class="math notranslate nohighlight">\(p\)</span> of the kernel <span class="math notranslate nohighlight">\(k: p(\boldsymbol{\omega} )=\frac{1}{2 \pi} \int e^{-j \boldsymbol{\omega} ^{\top}  \Delta} k(\Delta) \mathrm{~d} \Delta\)</span></p></li>
<li><p>Draw <span class="math notranslate nohighlight">\(D \text { iid samples } \boldsymbol{\omega}_{1}, \cdots, \boldsymbol{\omega}_{D} \in \mathcal{R}^{d} \text { from } p\)</span></p></li>
<li><p>Let <span class="math notranslate nohighlight">\(\boldsymbol{z}(\boldsymbol{x}) \equiv \sqrt{\frac{1}{D}}\left[\cos \left( \boldsymbol{\omega} _{1}^{\prime} \boldsymbol{x}\right) \cdots \cos \left(\boldsymbol{\omega}_{D}^{\prime} \boldsymbol{x}\right) \sin \left(\boldsymbol{\omega}_{1}^{\prime} \boldsymbol{x}\right) \cdots \sin \left(\boldsymbol{\omega}_{D}^{\prime} \boldsymbol{x}\right)\right]^{\prime}\)</span></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="faster-cnn-training">
<h3>Faster CNN Training<a class="headerlink" href="#faster-cnn-training" title="Permalink to this headline">¶</a></h3>
<p>In-between two convolutional layers of depth <span class="math notranslate nohighlight">\(d_1\)</span> and <span class="math notranslate nohighlight">\(d_2\)</span>, the number of convolution computation is <span class="math notranslate nohighlight">\(d_1 \times d_2\)</span> in forward propagation. Fourier transform based convolution can speed up this process. [Mathieu, Henaff, LeCun, “Fast Training of Convolutional Networks through FFTs”, arXiv. 2013]</p>
<p>Today there are other methods that speed up CNN training.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./30-ml-basics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="53-self-supervised.html" title="previous page">Self-supervised Learning</a>
    <a class='right-next' id="next-link" href="../31-regression/00-regression.html" title="next page">Regression</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dennis Zheng<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-150740237-2', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>