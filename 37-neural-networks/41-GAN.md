# Generative Adversarial Networks



## Objective

Main idea: Generator and discriminator functions are playing an adversarial gam

- Draw a latent “noise” vector $\boldsymbol{z}$ from some simple distribution $p(\boldsymbol{z})$

- Generator $G(\boldsymbol{z};\boldsymbol{\theta} _g)$ generates examples of target objects $\boldsymbol{x} \in \mathbb{R} ^d$ from a distribution $p_g(\boldsymbol{x} |\boldsymbol{z} )$

- Discriminator outputs a probability $D(\boldsymbol{x} ) ∈ [0, 1]$ that the example $\boldsymbol{x}$ is “real” (as opposed to “fake” = generated by the model)

- Generator’s goal is to fool the discriminator



Loss for a given true training example $\boldsymbol{x}$

- $D$’s loss: $log D(x)$
- $G$’s loss: $log(1 − D(G(z)))$ where $\boldsymbol{z}$ is generated from $p(\boldsymbol{z})$

Objective:

$$
\min _{G} \max _{D} \left\{ E_{\boldsymbol{x}  \sim p_{\text {d }}(\boldsymbol{x} )}[\log D(\boldsymbol{x} )]+E_{\boldsymbol{\boldsymbol{z} }  \sim p_{\text{g} }(\boldsymbol{z} )}[\log (1-D(G(\boldsymbol{z} )))] \right\}
$$

Cannot be optimized just by backpropagation. Instead, alternate between updating $G$ and updating $D$

:::{figure} GAN-algo
<img src="../imgs/gan-algo.png" width = "80%" alt=""/>

GAN optimization algorithm [Goodfellow+ 2014]
:::

Note

- The minimax optimization problem has a global optimum when $p_g = p_d$.

- Algorithm 1 optimizes the objective given sufficient capacity in $G$ and $D$ and that the optimization is “successful” at each update.

- In practice, $G$ and $D$ are limited to some (large) function class defined by neural networks.

- In practice, we do not get to see the true data distribution but only an empirical distribution from the training set, so can’t guarantee that we improve the true objective.

There are some practical challenges to getting GANs to work

- Consider the very beginning of training: $G$ is very poor, $D$ does very well, no gradient is generated through the $D$ network, so we get stuck

- Consider what happens if $G$ only generates examples that look like the **mode** of $p_d(x)$: These are the most “natural” examples $\Rightarrow$ D has trouble discriminating these $\Rightarrow$ $G$ is happy $\Rightarrow$ $G$ learns a distribution that is too peaked around a mode


:::{figure} gan-example
<img src="../imgs/gan-example.png" width = "80%" alt=""/>

Generation of examples from GAN [Goodfellow+ 2014]
:::

## Improvements

- Combine the GAN loss with a more traditional reconstruction loss, to avoid getting stuck due to lack of discriminator gradient

### InfoGAN (Chen et al. 2016):

- Add to the model a vector of additional latent variables $\boldsymbol{c}$ that are meant to be “interpretable”

- Learn an inference model $q(\boldsymbol{x} |\boldsymbol{x} )$ as in variational autoencoders

- $q(\boldsymbol{x} |\boldsymbol{x} )$ shares most of its structure with $D$, resulting in very few additional parameters

- Important byproduct: Produces a learned representation $\boldsymbol{c}$!

We can check the learned representation of each dimension.

:::{figure} gan-infogan-examples
<img src="../imgs/gan-infogan-examples.png" width = "80%" alt=""/>

InfoGAN examples on digits [Chen+ 2016]
:::

:::{figure} gan-infogan-examples-2
<img src="../imgs/gan-infogan-examples-2.png" width = "80%" alt=""/>

InfoGAN examples on faces [Chen+ 2016]
:::

## Compared to VAE

- “Vanilla” GANs tend to produce sharper outputs than “vanilla” VAEs

- “Vanilla” GANs are much harder to train

- GANs do not produce an explicit model of the data distribution

More recent work

- Dramatically improved generation via either GAN-based or VAE-based models

- Newer models combine ideas from GANs and VAEs,
  - use different ways of measuring distance between distributions (e.g., Wasserstein GANs),
  - combine discrete and continuous representations (e.g., vector quantized VAEs)
