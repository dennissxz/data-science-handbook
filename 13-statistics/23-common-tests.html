
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Common Tests &#8212; Data Science Handbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Confusion Matrix" href="33-confusion-matrix.html" />
    <link rel="prev" title="Hypothesis Testing" href="21-hypothesis-testing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      <h1 class="site-logo" id="site-title">Data Science Handbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Data Science Handbook
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11-math/00-math.html">
   Math
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/11-combinatorics.html">
     Combinatorics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/20-vector-spaces.html">
     Vector Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/31-geometry.html">
     Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/21-linear-algebra.html">
     Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/51-linear-programming.html">
     Linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/52-non-linear-programming.html">
     Non-linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/90-puzzles.html">
     Puzzles
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12-probabilities/00-probabilities.html">
   Probabilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/11-expectation-and-variance.html">
     Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/13-correlation-and-dependence.html">
     Correlation and Dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/31-bayesian-theorem.html">
     Bayesian’s Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/51-markov-chain.html">
     Markov Chain
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/71-sampling.html">
     Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/90-multivariate-notations.html">
     Multivariate Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/91-exponential-families.html">
     Exponential Families
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/91-large-sample-theory.html">
     Large Sample Theory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00-statistics.html">
   Statistics
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="11-sample-survey.html">
     Sample Survey
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-randomized-trial.html">
     Randomized Controlled Trials
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="21-hypothesis-testing.html">
     Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Common Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="33-confusion-matrix.html">
     Confusion Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="41-maximum-likelihood-estimation.html">
     Maximum Likelihood Estimator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="43-estimators-evaluation.html">
     Estimators Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../15-tools/00-tools.html">
   Tools
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/11-python.html">
     Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/21-r.html">
     R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/31-sql.html">
     SQL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/41-latex.html">
     LaTeX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-tools/51-myst.html">
     MyST Markdown
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../20-algorithms-concepts/00-algorithms-concepts.html">
   Algorithms Concepts
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/51-polynomial-reduction.html">
     Polynomial Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/53-P-and-NP.html">
     <span class="math notranslate nohighlight">
      \(P\)
     </span>
     and
     <span class="math notranslate nohighlight">
      \(NP\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/61-randomized-algo.html">
     Randomized Algorithms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../21-greedy-algorithms/00-greedy-algorithms.html">
   Greedy Algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/11-interval-scheduling.html">
     Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/31-huffman-coding.html">
     Huffman Coding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../23-dynamic-programming/00-dynamic-programming.html">
   Dynamic Programming
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/11-weighted-interval-scheduling.html">
     Weighted Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/13-longest-common-subsequence.html">
     Longest Common Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/15-longest-increasing-subsequence.html">
     Longest Increasing Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/17-largest-sum-subsequence.html">
     Largest Sum Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/31-knapsack.html">
     Minimum Knapsack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/51-chain-matrix-multiplication.html">
     Chain Matrix Multiplication
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../25-graph-related/00-graph-related.html">
   Graph Related
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/13-shortest-path.html">
     Shortest Path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/21-minimum-spanning-tree.html">
     Minimum Spanning Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/31-maximum-flow.html">
     Maximum Flow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/32-matching.html">
     Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/42-maximum-independent-set.html">
     Maximum Independent Set in Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/91-LP-max-flow-min-cut.html">
     LP on Max-flow and Min-cut
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../26-algo-for-big-data/00-algo-for-big-data.html">
   For Big Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../26-algo-for-big-data/10-streaming.html">
     Streaming Model
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../30-ml-basics/00-ml-basics.html">
   Machine Learning Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/02-taxonomy.html">
     Taxonomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/03-information-theory.html">
     Information Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/05-kernels.html">
     Kernels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/11-data-issues.html">
     Data Issues
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/51-semi-supervised.html">
     Semi-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/53-self-supervised.html">
     Self-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/61-fourier-transform.html">
     Fourier Transform-based Representations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../31-regression/00-regression.html">
   Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/11-lm-estimation.html">
     Linear Models - Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/12-lm-inference.html">
     Linear Models - Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/13-lm-diagnosis.html">
     Linear Models - Diagnosis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/14-lm-advanced.html">
     Linear Models - Advanced Topics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/21-generalized-linear-models.html">
     Generalized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/22-logistic-regression.html">
     Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/23-multinomial-logitsitc.html">
     Multinomial Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/24-ordinal-logistic.html">
     Ordinal Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/25-poisson-regression.html">
     Poisson Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/31-multivariate-regression.html">
     Multivariate Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../32-classification/00-classification.html">
   Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/09-k-nearest-neighbors.html">
     K-nearest neighbors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/11-support-vector-machine.html">
     Support Vector Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/21-decision-tree.html">
     Decision Tree
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../33-dimensionality-reduction/00-dimensionality-reduction.html">
   Dimensionality Reduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/11-principal-component-analysis.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/13-canonical-correlation-analysis.html">
     Canonical Correlation Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/21-multidimensional-scaling.html">
     Multidimensional Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/23-graph-based-spectral-methods.html">
     Graph-based Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/25-t-SNE.html">
     SNE and
     <span class="math notranslate nohighlight">
      \(t\)
     </span>
     -SNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/31-kernel-pca.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/32-kernel-cca.html">
     Kernel CCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/41-factor-analysis.html">
     Factor Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/51-correspondence-analysis.html">
     Correspondence Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../34-clustering/00-clustering.html">
   Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/11-k-means.html">
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/13-agglomerative-methods.html">
     Agglomerative Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/31-spectral-clustering.html">
     Spectral Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/41-gaussian-mixtures.html">
     Gaussian Mixtures
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../35-graphical-models/00-graphical-models.html">
   Graphical Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/03-random-walks.html">
     Random Walks in Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/11-hidden-markov-models.html">
     Hidden Markov Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/31-topic-models.html">
     Topic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/33-language-models.html">
     Language Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../37-neural-networks/00-neural-networks.html">
   Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/01-stochastic-gradient-descent.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/03-trainability.html">
     Trainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/05-regularization.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/11-autoencoders.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/13-variational-autoencoders.html">
     Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/31-sequential-models.html">
     Sequential Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/41-GAN.html">
     Generative Adversarial Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../38-ml-for-graph-data/00-ml-for-graph-data.html">
   For Graph-structured Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/01-graph-basics.html">
     Graph Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/11-descriptive-analysis.html">
     Descriptive Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/13-sampling-and-estimation.html">
     Sampling and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/21-modeling.html">
     Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/31-topology-inference.html">
     Topology Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/41-processes.html">
     Processes on Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/51-graph-rep-learning.html">
     Graph Representation Learning
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/13-statistics/23-common-tests.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/dennissxz/data-science-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/dennissxz/data-science-handbook/issues/new?title=Issue%20on%20page%20%2F13-statistics/23-common-tests.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-sample-mean-tests">
   Two-sample Mean Tests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paired">
     Paired
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#normal">
       Normal
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#non-normal">
       Non-normal
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#independent">
     Independent
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#equal-variance">
       Equal Variance
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id1">
         Normal
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id2">
         Non-normal
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#unequal-variance">
       Unequal Variance
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#anova">
   ANOVA
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model">
     Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#test-statistic">
     Test Statistic
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multivariate-settings">
   Multivariate Settings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hotelling-s-t-2-distribution">
     Hotelling’s
     <span class="math notranslate nohighlight">
      \(T^2\)
     </span>
     Distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-sample-mean">
     One-sample Mean
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-sample-means">
     Two-sample Means
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Paired
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#two-independent-samples">
       Two Independent Samples
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#manova">
     MANOVA
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       Model
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       Test Statistic
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c-i-for-difference-in-two-means">
       C.I. for Difference in Two Means
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#test-for-equal-covariance">
       Test for Equal Covariance
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="common-tests">
<h1>Common Tests<a class="headerlink" href="#common-tests" title="Permalink to this headline">¶</a></h1>
<!-- ## Median test

Mood's median test is a special case of Pearson's chi-squared test. It is a nonparametric test that tests the null hypothesis that the medians of the populations from which two or more samples are drawn are identical.

## $z$-test

## $t$-test

## $F$-test

$F$ -distribution with degrees of freedom $\left(d_{1}, d_{2}\right)$, denoted as $F_{d_{1}, d_{2}}$, has the form
$$
\frac{Y_{1} / d_{1}}{Y_{2} / d_{2}}
$$
with $Y_{1} \sim \chi_{d_{1}}^{2}, \quad Y_{1} \sim \chi_{d_{2}}^{2}$ and $Y_{1} \Perp Y_{2}$.

## $\chi^2$-test -->
<div class="section" id="two-sample-mean-tests">
<h2>Two-sample Mean Tests<a class="headerlink" href="#two-sample-mean-tests" title="Permalink to this headline">¶</a></h2>
<p>Suppose we have two samples of data <span class="math notranslate nohighlight">\(\left\{x_{1}, \cdots, x_{n}\right\}\)</span> and <span class="math notranslate nohighlight">\(\left\{y_{1}, \cdots, y_{m}\right\}\)</span>.</p>
<p>A question of interest: Did the two samples come from the same distribution, as opposed to, one sample having larger values than the other on average?</p>
<p>To model them, we assume</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_{i}, \cdots, X_{n}\)</span> i.i.d. sampled from a distribution with mean with mean <span class="math notranslate nohighlight">\(\mu_X\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 _X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y_{i}, \cdots, Y_{m}\)</span> i.i.d. sampled from a distribution with mean with mean <span class="math notranslate nohighlight">\(\mu_Y\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 _Y\)</span></p></li>
</ul>
<p>We are interested in comparing the two samples, often by comparing the two means <span class="math notranslate nohighlight">\(\mu_X\)</span> and <span class="math notranslate nohighlight">\(\mu_Y\)</span>.</p>
<p>An unbiased estimator for the difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span>. To provide standard error to this estimator, <span class="math notranslate nohighlight">\(\operatorname{Var}\left( \bar{X} - \bar{Y} \right)\)</span> need to be estimated, contingent on sample properties.</p>
<div class="section" id="paired">
<h3>Paired<a class="headerlink" href="#paired" title="Permalink to this headline">¶</a></h3>
<p>In many studies, the <span class="math notranslate nohighlight">\(i\)</span>-th measurements in the two samples <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> actually are related, such as measurements before and after a treatment from the same subject.</p>
<p>When <span class="math notranslate nohighlight">\(m = n\)</span> and <span class="math notranslate nohighlight">\(\operatorname{Corr}\left( X_i,Y_i \right) = \rho \ne 0\)</span>, very often <span class="math notranslate nohighlight">\(\rho &gt;0\)</span>. Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\operatorname{Var}(\bar{X}-\bar{Y}) &amp;=\operatorname{Var}(\bar{X})+\operatorname{Var}(\bar{Y})-2 \times \operatorname{Cov}(\bar{X}, \bar{Y}) \\
&amp; \leq \operatorname{Var}(\bar{X})+\operatorname{Var}(\bar{Y}) \quad \text{when }\rho &gt;0
\end{aligned}
\end{split}\]</div>
<p>To have a more precise variance estimate, it is appropriate to consider pairing <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(Y_i\)</span> by investigating their difference:</p>
<div class="math notranslate nohighlight">
\[
D_{i}=X_{i}-Y_{i}, \quad i=1, \cdots, n
\]</div>
<p>Note that <span class="math notranslate nohighlight">\(D_i\)</span>’s are i.i.d. under the i.i.d. assumption of each of the two samples, with</p>
<div class="math notranslate nohighlight">
\[
\mu_{D}=\mu_{X}-\mu_{Y}, \quad \sigma_{D}^{2}=\sigma_{X}^{2}+\sigma_{Y}^{2}-2 \rho \sigma_{X} \sigma_{Y}
\]</div>
<p>Then essentially, we changed the inference problem into that of a <strong>one-sample case</strong>.</p>
<p>An unbiased estimator for the variance of difference <span class="math notranslate nohighlight">\(\sigma^2_D\)</span> is the sample variance.</p>
<div class="math notranslate nohighlight">
\[
S_{D}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(D_{i}-\bar{D}\right)^{2}=\widehat{\operatorname{Var}}\left(D_{i}\right)=\hat{\sigma}_{D}^{2}
\]</div>
<div class="section" id="normal">
<h4>Normal<a class="headerlink" href="#normal" title="Permalink to this headline">¶</a></h4>
<p>If <span class="math notranslate nohighlight">\(X \sim \mathcal{N} \left(\mu_{X}, \sigma_{X}^{2}\right), Y \sim \mathcal{N} \left(\mu_{Y}, \sigma_{Y}^{2}\right)\)</span>, then we have the distributions for the sample estimators</p>
<div class="math notranslate nohighlight">
\[
\frac{\bar{D}-\mu_{D}}{\sigma_{D} / \sqrt{n}} \sim \mathcal{N}(0,1), \quad \frac{(n-1) S_{D}^{2}}{\sigma_{D}^{2}} \sim \chi_{n-1}^{2}
\]</div>
<p>In addition, they are independent. By the definition of <span class="math notranslate nohighlight">\(t\)</span>-distribution, the test statistic</p>
<div class="math notranslate nohighlight">
\[
\frac{\bar{D}-\mu_{D}}{S_{D} / \sqrt{n}} \sim t_{n-1}
\]</div>
<p>is a pivot quantity not depending on the parameters if we are testing a hypothesis on <span class="math notranslate nohighlight">\(\mu_D\)</span>. For instance,</p>
<div class="math notranslate nohighlight">
\[
H_{0}: \mu_{D}=0
\]</div>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{X}-\bar{Y} \pm t_{n-1}^{(1-\alpha / 2)} \frac{S_{D}}{\sqrt{n}}
\]</div>
</div>
<div class="section" id="non-normal">
<h4>Non-normal<a class="headerlink" href="#non-normal" title="Permalink to this headline">¶</a></h4>
<p>When the samples are not normally distributed, <span class="math notranslate nohighlight">\(t_{n-1}\)</span> can be used as an approximate distribution.</p>
<p>When n is large, we may use the Central Limit Theorem,</p>
<div class="math notranslate nohighlight">
\[
\frac{\bar{D}-\mu_{D}}{S_{D} / \sqrt{n}} \overset{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)
\]</div>
<p>The asymptotic pivotal property can be used to conduct hypothesis tests.</p>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{X}-\bar{Y} \pm z^{(1-\alpha / 2)} \frac{S_{D}}{\sqrt{n}}
\]</div>
</div>
</div>
<div class="section" id="independent">
<h3>Independent<a class="headerlink" href="#independent" title="Permalink to this headline">¶</a></h3>
<p>Now we consider <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(Y_j\)</span> are independent.</p>
<div class="section" id="equal-variance">
<h4>Equal Variance<a class="headerlink" href="#equal-variance" title="Permalink to this headline">¶</a></h4>
<p>If <span class="math notranslate nohighlight">\(\sigma^2 _X = \sigma^2 _Y\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Var}(\bar{X}-\bar{Y})=\frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}=\sigma^{2}\left(\frac{1}{n}+\frac{1}{m}\right)
\]</div>
<p>and both sample variances <span class="math notranslate nohighlight">\(S_X^2\)</span> and <span class="math notranslate nohighlight">\(S_Y^2\)</span> are unbiased estimators of <span class="math notranslate nohighlight">\(\sigma^2\)</span></p>
<p>A better unbiased estimator is the <strong>pooled sample variance</strong></p>
<div class="math notranslate nohighlight">
\[
S_{p}^{2}=S_{\text {pooled }}^{2}=\frac{(n-1) S_{X}^{2}+(m-1) S_{Y}^{2}}{n+m-2}
\]</div>
<p>which has a <strong>larger testing power</strong> than the two sample variances.</p>
<div class="section" id="id1">
<h5>Normal<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h5>
<p>If both <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are of normal distributions, then the test statistic is</p>
<div class="math notranslate nohighlight">
\[
\frac{(\bar{X}-\bar{Y})-\left(\mu_{X}-\mu_{Y}\right)}{S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{n+m-2}
\]</div>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{X}-\bar{Y} \pm t_{n+m-2,1-\alpha / 2} S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}
\]</div>
</div>
<div class="section" id="id2">
<h5>Non-normal<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h5>
<p>When the samples are not normally distributed, <span class="math notranslate nohighlight">\(t_{n+m-2}\)</span> distribution can be used as an approximation.</p>
<p>When <strong>both</strong> <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> are large, we may apply the Central Limit Theorem,</p>
<div class="math notranslate nohighlight">
\[
\frac{(\bar{X}-\bar{Y})-\left(\mu_{X}-\mu_{Y}\right)}{S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}} \overset{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)
\]</div>
<div class="note admonition">
<p class="admonition-title"> Pooling vs paring</p>
<p>Consider the case n = m with equal variance.</p>
<ul>
<li><p>Under assumption that the two samples are independent, the variance is</p>
<div class="math notranslate nohighlight">
\[
    \operatorname{Var}(\bar{X}-\bar{Y})= \frac{2 \sigma^{2}}{n}
    \]</div>
<p>The pooled sample variance is the appropriate estimator to be used.</p>
</li>
<li><p>If the two samples were correlated with <span class="math notranslate nohighlight">\(Corr(X_i, X_j) = \rho &gt; 0\)</span>, the variance becomes smaller</p>
<div class="math notranslate nohighlight">
\[
    \operatorname{Var} (\bar{X}-\bar{Y})=(1-\rho) \frac{2 \sigma^{2}}{n}&lt; \frac{2 \sigma^{2}}{n}
    \]</div>
</li>
</ul>
<p>As a result, when correlation exists, the smaller paired sample variance is the appropriate one to use, since the test statistic using it has a <strong>larger power</strong>.</p>
<p>On the other hand, if the correlation is substantial and we fail to take it into consideration, the pooled sample variance estimator likely will overestimate the variance, and the estimate could be too large to be useful.</p>
</div>
</div>
</div>
<div class="section" id="unequal-variance">
<h4>Unequal Variance<a class="headerlink" href="#unequal-variance" title="Permalink to this headline">¶</a></h4>
<p>If <span class="math notranslate nohighlight">\(\sigma_{X}^{2} \neq \sigma_{Y}^{2}\)</span>, the variance we are interested to estimate has the form</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Var}(\bar{X}-\bar{Y})=\frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}
\]</div>
<p>which can be estimated by the unbiased estimator</p>
<div class="math notranslate nohighlight">
\[
\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}
\]</div>
<p>It is complicated to construct a pivot quantity like we did for the previous cases. Consider</p>
<div class="math notranslate nohighlight">
\[
T=\frac{\bar{X}-\bar{Y}-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}}
\]</div>
<p>When both <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are of normal distributions, we have</p>
<div class="math notranslate nohighlight">
\[
(n-1) S_{X}^{2} / \sigma_{X}^{2} \sim \chi_{n-1}^{2}, \quad(m-1) S_{Y}^{2} / \sigma_{Y}^{2} \sim \chi_{m-1}^{2}
\]</div>
<p>But since <span class="math notranslate nohighlight">\(\sigma_{X}^{2} \neq \sigma_{Y}^{2}\)</span>, the summation</p>
<div class="math notranslate nohighlight">
\[
\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m} \sim \frac{\sigma_{X}^{2}}{n(n-1)} x_{n-1}^{2}+\frac{\sigma_{Y}^{2}}{m(m-1)} X_{m-1}^{2}
\]</div>
<p>is not a multiple of a <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution.</p>
<p>Hence, <span class="math notranslate nohighlight">\(T\)</span> is not <span class="math notranslate nohighlight">\(t\)</span>-distributed.</p>
<p>If <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> are both large, we can resort to Central Limit Theorem as usual,</p>
<div class="math notranslate nohighlight">
\[
T=\frac{\left( \bar{X}-\bar{Y} \right)-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}} \stackrel{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)
\]</div>
<p>The asymptotic approximation lead to a <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span></p>
<div class="math notranslate nohighlight">
\[
\bar{X}_{i}-\bar{Y} \pm z_{1-\alpha / 2} \sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}
\]</div>
<p>However, there is a better approximation using <span class="math notranslate nohighlight">\(t_v\)</span> distribution than the normal approximation.</p>
<div class="math notranslate nohighlight">
\[
T=\frac{\bar{X}-\bar{Y}-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}} \stackrel{\mathcal{D}}{\longrightarrow} t_v
\]</div>
<p>But the degree of freedom <span class="math notranslate nohighlight">\(v\)</span> is involved. It is estimated by  Welch-Satterthwaite approximation,</p>
<div class="math notranslate nohighlight">
\[
\nu \approx \frac{\left(\frac{S_{X}^{2}}{n}+\frac{S_{T}^{2}}{m}\right)^{2}}{\left(\frac{S_{x}^{2}}{n}\right)^{2} /(n-1)+\left(\frac{S_{Y}^{2}}{m}\right)^{2} /(m-1)}
\]</div>
<p>The asymptotic approximation lead to a <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\bar{X}_{i}-\bar{Y} \pm t_{\nu}^{1-\alpha / 2} \sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}
\]</div>
</div>
</div>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<p>The analysis for the above cases are summarized into the table below. In general, if <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are of normal distributions, the pivot quantity follows a known distribution. If not, we use CLT to obtain an approximate distribution, which requires <strong>large</strong> <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span>.</p>
<div class="math notranslate nohighlight">
\[
H_0: \mu_X - \mu_Y = 0
\]</div>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Dependency</p></th>
<th class="head"><p>Test statistic</p></th>
<th class="head"><p>Normal</p></th>
<th class="head"><p>Non-normal, large <span class="math notranslate nohighlight">\(n, m\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Paired (reduced to a univariate test)</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\bar{D}-\mu_{D}}{S_{D} / \sqrt{n}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\sim t_{n-1}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\stackrel{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Independent with equal variance</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{(\bar{X}-\bar{Y})-\left(\mu_{X}-\mu_{Y}\right)}{S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\sim t_{n+m-2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\stackrel{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Independent with unequal variance</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\left( \bar{X}-\bar{Y} \right)-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}}\)</span></p></td>
<td><p>/</p></td>
<td><p><span class="math notranslate nohighlight">\(\stackrel{\mathcal{D}}{\longrightarrow} t_v\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="anova">
<h2>ANOVA<a class="headerlink" href="#anova" title="Permalink to this headline">¶</a></h2>
<p>Analysis of variance is used to compare several univariate sample means. For instance, in the plot below, we have five levels and observed the response <span class="math notranslate nohighlight">\(y\)</span>. We are interested in whether the five means are equal.</p>
<div class="figure align-default" id="test-one-way">
<a class="reference internal image-reference" href="../_images/test-one-way.png"><img alt="" src="../_images/test-one-way.png" style="width: 70%;" /></a>
<p class="caption"><span class="caption-number">Fig. 20 </span><span class="caption-text">One-way Layout</span><a class="headerlink" href="#test-one-way" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="model">
<h3>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h3>
<p>There are <span class="math notranslate nohighlight">\(n_\ell\)</span> observations from population or treatment group <span class="math notranslate nohighlight">\(\ell = 1, 2, \ldots, g\)</span></p>
<div class="math notranslate nohighlight">
\[
X_{\ell j}=\mu+\tau_{\ell}+e_{\ell j}, \quad \ell=1, \cdots, g, \quad j=1, \cdots, n_{\ell}
\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> is the <strong>overall mean</strong> parameter.</p></li>
<li><p><span class="math notranslate nohighlight">\(\tau_{\ell}\)</span> is the <strong>treatment effect</strong> parameter of the <span class="math notranslate nohighlight">\(\ell\)</span> th population or <span class="math notranslate nohighlight">\(\ell\)</span> th treatment group.</p></li>
<li><p><span class="math notranslate nohighlight">\(e_{\ell j} \sim N\left(0, \sigma^{2}\right)\)</span> is individual specific homogenous noise.</p></li>
<li><p>Parameter constraints: There should be constraints on the parameters such as <span class="math notranslate nohighlight">\(\sum_{\ell=1}^{g} n_{\ell} \tau_{\ell}=0\)</span>, to avoid redundancy or unidentifiability.</p></li>
</ul>
<p>To detect differences in treatment effects among the groups,
the first test of interest is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{\begin{array}{ll}
H_{0}: &amp; \tau_{1}=\cdots=\tau_{g}=0 \\
H_{1}: &amp; \tau_{\ell} \neq 0, \text { for some } \ell=1, \cdots, g
\end{array}\right.
\end{split}\]</div>
</div>
<div class="section" id="test-statistic">
<h3>Test Statistic<a class="headerlink" href="#test-statistic" title="Permalink to this headline">¶</a></h3>
<p>First, we decompose the observations as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
x_{\ell j} &amp;= \bar{x} + \left(\bar{x}_{\ell}-\bar{x}\right)+\left(x_{\ell j}-\bar{x}_{\ell}\right) \\
&amp;= \hat{\mu} + \hat{\tau}_\ell + \hat{e}_{\ell j}\\
\end{aligned}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{x}\)</span> is the overall mean, <span class="math notranslate nohighlight">\(\bar{x}_\ell\)</span> is the <span class="math notranslate nohighlight">\(\ell\)</span>-th group mean. Hence, the observation can be seen as estimated overall mean + estimated treatment effect + estimated noise. Equivalently,</p>
<div class="math notranslate nohighlight">
\[
\left(x_{\ell j}-\bar{x}\right)=\left(\bar{x}_{\ell}-\bar{x}\right)+\left(x_{\ell j}-\bar{x}_{\ell}\right)
\]</div>
<p>Summing up all <strong>squared</strong> terms, noticing that <span class="math notranslate nohighlight">\(\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\bar{x}_{\ell}-\bar{x}\right)\left(x_{\ell j}-\bar{x}_{\ell}\right)=0\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(x_{\ell j}-\bar{x}\right)^{2}=\sum_{\ell=1}^{g} n_{\ell}\left(\bar{x}_{\ell}-\bar{x}\right)^{2}+\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(x_{\ell j}-\bar{x}_{\ell}\right)^{2}
\]</div>
<p>The decomposition can be stated as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\sum(\text { total variation })^{2}=\sum\left(\begin{array}{c}
\text { between-group } \\
\text { treatment variation }
\end{array}\right)^{2}+\sum\left(\begin{array}{c}
\text { within-group } \\
\text { residual variation }
\end{array}\right)^{2}
\end{split}\]</div>
<p>The corresponding numbers of independent quantities of each term, i.e. the degrees of freedom, have the relation</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^{g} n_{\ell}-1=(g-1)+\sum_{\ell=1}^{g}\left(n_{\ell}-1\right)
\]</div>
<p>Therefore, we obtain the analysis of variance table</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|c|c|c}
\hline \begin{array}{c}
\text { Source } \\
\text { of variation }
\end{array} &amp; \text { SS (sum of squares) } &amp; \text { d.f. } &amp; \begin{array}{c}
F \text {-value } \\
\text { (variance ratio) }
\end{array} \\
\hline \text { Treatments } &amp; S S_{t r t}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\bar{x}_{\ell}-\bar{x}\right)^{2} &amp; g-1 &amp; S S_{t r t} /(g-1) \\
\text { Residuals } &amp; S S_{\text {res }}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(x_{\ell j}-\bar{x}_{\ell}\right)^{2} &amp; \sum_{\ell=1}^{g} n_{\ell}-g &amp; \\
\hline \text { Total } &amp; S S_{t o t}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(x_{\ell j}-\bar{x}\right)^{2} &amp; \sum_{\ell=1}^{g} n_{\ell}-1 &amp; \\
\hline
\end{array}
\end{split}\]</div>
<p>At test level <span class="math notranslate nohighlight">\(\alpha\)</span>, the null <span class="math notranslate nohighlight">\(H_0: \tau_{1}=\cdots=\tau_{g}=0\)</span> is rejected if</p>
<div class="math notranslate nohighlight">
\[
\frac{S S_{t r t} /(g-1)}{S S_{\text {res }} /\left(\sum_{\ell=1}^{g} n_{\ell}-g\right)}&gt;F_{g-1, \sum_{\ell=1}^{g} n_{\ell}-g}(\alpha)
\]</div>
<div class="warning admonition">
<p class="admonition-title"> Warning</p>
<p>In <code class="docutils literal notranslate"><span class="pre">manova()</span></code> function in R, if the group variable <span class="math notranslate nohighlight">\(\ell\)</span> is in numerical value, it is necessary to coerce it as data type <code class="docutils literal notranslate"><span class="pre">factor</span></code> by calling <code class="docutils literal notranslate"><span class="pre">as.factor()</span></code>.</p>
</div>
</div>
</div>
<div class="section" id="multivariate-settings">
<h2>Multivariate Settings<a class="headerlink" href="#multivariate-settings" title="Permalink to this headline">¶</a></h2>
<div class="section" id="hotelling-s-t-2-distribution">
<h3>Hotelling’s <span class="math notranslate nohighlight">\(T^2\)</span> Distribution<a class="headerlink" href="#hotelling-s-t-2-distribution" title="Permalink to this headline">¶</a></h3>
<dl class="simple myst">
<dt>Definition (Hotelling’s <span class="math notranslate nohighlight">\(T^2\)</span> Distribution )</dt><dd><p>Suppose random zero-mean Gaussian <span class="math notranslate nohighlight">\(\boldsymbol{x} \sim \mathcal{N} _p(\boldsymbol{0} , \boldsymbol{\Sigma} )\)</span> and Wishart random matrix <span class="math notranslate nohighlight">\(\boldsymbol{V} \sim W_p(k, \boldsymbol{\Sigma} )\)</span> are independent. Define</p>
<div class="math notranslate nohighlight">
\[
  T^2 = k \boldsymbol{x} ^{\top} \boldsymbol{V} ^{-1} \boldsymbol{x}
  \]</div>
<p>Then <span class="math notranslate nohighlight">\(T^2\)</span> is said to follow a Hotelling’s <span class="math notranslate nohighlight">\(T^2\)</span> distribution with parameter <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(k\)</span>, denoted as <span class="math notranslate nohighlight">\(T^2(p, k)\)</span>.</p>
<p>In univariate sense, the Hotelling’s <span class="math notranslate nohighlight">\(T^2\)</span> statistic can be reduced to the <strong>squared</strong> <span class="math notranslate nohighlight">\(t\)</span>-statistic. Hence it can be seen as multivariate generalization of (squared) <span class="math notranslate nohighlight">\(t\)</span>-distribution.</p>
</dd>
<dt>Properties</dt><dd><ul>
<li><p>If <span class="math notranslate nohighlight">\(\bar{\boldsymbol{x}}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{S}\)</span> are respectively the sample mean vector and sample covariance matrix of a random sample of size <span class="math notranslate nohighlight">\(n\)</span> taken from <span class="math notranslate nohighlight">\(\mathcal{N} _p(\boldsymbol{\mu} , \boldsymbol{\Sigma} )\)</span>, then</p>
<div class="math notranslate nohighlight">
\[n(\bar{\boldsymbol{x}}-\boldsymbol{\mu})^{\top} \boldsymbol{S}^{-1}(\bar{\boldsymbol{x}}-\boldsymbol{\mu}) \sim T^{2}(p, n-1)\]</div>
</li>
<li><p>The distribution of the quadratic form under non-normality is reasonably robust as long as the underlying multivariate distribution has pdf contours close to elliptical shape, but <span class="math notranslate nohighlight">\(T^2\)</span> is sensitive to the departure from such elliptical symmetry of the distribution.</p></li>
<li><p>Invariant under transformation of <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>:<span class="math notranslate nohighlight">\(\boldsymbol{C} \boldsymbol{x} + \boldsymbol{d}\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{C}\)</span> is non-singular.</p></li>
<li><p>Related to other distribution:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T^{2}(p, k)=\frac{k p}{k-p+1} F(p, k-p+1)\)</span>, usually used to find quantile <span class="math notranslate nohighlight">\(T^2(\alpha)\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(T^{2}(1, k)=t^{2}(k)=F(1, k)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T^{2}(p, \infty) \rightarrow \chi ^2 _p\)</span> by multivariate <a class="reference internal" href="../12-probabilities/91-large-sample-theory.html#clt"><span class="std std-ref">CLT</span></a>, <strong>without</strong> assuming normality of the distribution of <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span></p></li>
</ul>
</li>
<li><p>Related to Mahalanobis distance: <span class="math notranslate nohighlight">\(T^{2}=n D_{\boldsymbol{S}}^{2}(\bar{\boldsymbol{x}}, \boldsymbol{\mu})\)</span></p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="one-sample-mean">
<h3>One-sample Mean<a class="headerlink" href="#one-sample-mean" title="Permalink to this headline">¶</a></h3>
<p>Assume <span class="math notranslate nohighlight">\(\boldsymbol{x} \sim \mathcal{N} _p(\boldsymbol{0} , \boldsymbol{\Sigma} )\)</span>, want to test</p>
<div class="math notranslate nohighlight">
\[
H_{0}: \boldsymbol{\mu}=\boldsymbol{\mu}_{0} \operatorname{vs } H_{1}: \boldsymbol{\mu} \neq \boldsymbol{\mu}_{0}
\]</div>
<dl class="simple myst">
<dt>Test statistic under <span class="math notranslate nohighlight">\(H_0\)</span></dt><dd><ul>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is known:</p>
<div class="math notranslate nohighlight">
\[T^{2}=n\left(\bar{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right)^{\top} \boldsymbol{\Sigma}^{-1}\left(\bar{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right) \sim \chi^{2}(p)\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is unknown, estimated by <span class="math notranslate nohighlight">\(\boldsymbol{S}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    T^{2}=n\left(\bar{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right)^{\top} \boldsymbol{S}^{-1}\left(\bar{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right) &amp;\sim T^{2}(p, n-1) \\
    &amp;\sim \frac{(n-1) p}{n-p} F(p, n-p) \\
    &amp; \rightarrow \chi ^2 _p \quad \text{as } n \rightarrow \infty  
    \end{aligned}\end{split}\]</div>
</li>
<li><p>Analogously, in univariate case,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \left\{\begin{array}{l}
    \frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{\sigma} \sim N(0,1) \text { if } \sigma^{2} \text { is known } \\
    \frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{s} \sim t(n-1) \text { if } \sigma^{2} \text { is unknown. }
    \end{array}\right.
    \end{split}\]</div>
</li>
</ul>
</dd>
<dt>Confidence Region</dt><dd><ul>
<li><p>A <span class="math notranslate nohighlight">\((1-\alpha)100\%\)</span> confidence region for <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> is a <span class="math notranslate nohighlight">\(p\)</span>-dimensional ellipsoid centered at <span class="math notranslate nohighlight">\(\bar{\boldsymbol{x}}\)</span>, i.e. a collection of all those <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> which will not be rejected by the above <span class="math notranslate nohighlight">\(T^2\)</span> test at significance level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="math notranslate nohighlight">
\[
    \left\{\boldsymbol{\mu}: n(\bar{\boldsymbol{x}}-\boldsymbol{\mu})^{\top} \boldsymbol{S}^{-1}(\bar{\boldsymbol{x}}-\boldsymbol{\mu}) \leq T_{\alpha}^{2}(p, n-1)=c_{\alpha}\right\}
    \]</div>
<div class="figure align-default" id="test-ellipsoid">
<a class="reference internal image-reference" href="../_images/test-ellipsoid.png"><img alt="" src="../_images/test-ellipsoid.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-number">Fig. 21 </span><span class="caption-text">Confidence region</span><a class="headerlink" href="#test-ellipsoid" title="Permalink to this image">¶</a></p>
</div>
</li>
<li><p>This confidence ellipsoid above is the most precise confidence region of the vector <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>, in the sense that any other form of confidence region for <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> with the same confidence level <span class="math notranslate nohighlight">\((1-\alpha)\)</span> will have <strong>larger volume</strong> in the <span class="math notranslate nohighlight">\(p\)</span>-dimensional space of <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> and hence less precise.</p></li>
</ul>
</dd>
<dt>Simultaneous confidence intervals for each component</dt><dd><ul>
<li><p>Individual CIs: Sometimes people get used to confidence intervals for individual components, such as</p>
<div class="math notranslate nohighlight">
\[
    \bar{x}_{j}-t^{\alpha / 2}_{n-1} \frac{s_j}{\sqrt{n}} &lt;\mu_{j}&lt;\bar{x}_{j}+t^{\alpha / 2}_{n-1} \frac{s_j}{\sqrt{n}}
    \]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{x}_j\)</span> and <span class="math notranslate nohighlight">\(s_j\)</span> are respectively the sample mean and standard deviation of the <span class="math notranslate nohighlight">\(j\)</span>-th variate that has mean <span class="math notranslate nohighlight">\(\mu_j\)</span>. But there are <a class="reference internal" href="21-hypothesis-testing.html#multiple-testing"><span class="std std-ref">multiple testing</span></a> issues. We can then use Bonferroni or Scheffe simultaneous C.I.s to correct this.</p>
</li>
<li><p>The <span class="math notranslate nohighlight">\((1-\alpha)100\%\)</span> Bonferroni simultaneous C.I.s for <span class="math notranslate nohighlight">\(m\)</span> <strong>pre-determined</strong> linear components of means, <span class="math notranslate nohighlight">\(\boldsymbol{a}_{i}^{\top} \boldsymbol{\mu}(i=1, \ldots, m)\)</span>, are given by</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{a}_{i}^{\top} \bar{\boldsymbol{x}} \pm t ^{\alpha/(2m)}_{n-1} \sqrt{\frac{\boldsymbol{a}_{i}^{\top} \boldsymbol{S} \boldsymbol{a}_{i}}{n}}
    \]</div>
</li>
</ul>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Scheffe simultaneous C.I. works like a guarantee for any ‘data snooping’ linear combinations in exploratory data analysis. Besides, it is related to <a class="reference internal" href="21-hypothesis-testing.html#uit"><span class="std std-ref">union intersection test</span></a>.</p>
</div>
<ul>
<li><p>The <span class="math notranslate nohighlight">\((1-\alpha)100\%\)</span> Scheffe simultaneous C.I.s for <strong>all possible</strong> linear combinations of means <span class="math notranslate nohighlight">\(\boldsymbol{a} ^{\top} \boldsymbol{\mu}\)</span> are given by</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{a}^{\top} \bar{\boldsymbol{x}} \pm \sqrt{T_{\alpha}^{2}(p, n-1)} \sqrt{\frac{\boldsymbol{a}^{\top} \boldsymbol{S a}}{n}}
    \]</div>
</li>
<li><p>Pros: Compared with the advantages of ellipsoidal confidence regions, these hyper-rectangles (orthotopes) are easier to form and to compute.</p></li>
<li><p>Cons: Both Bonferroni and Scheffé intervals are <strong>wider</strong> (hence less accurate) than the ordinary confidence intervals which are constructed with separate confidence level of <span class="math notranslate nohighlight">\((1-\alpha)\)</span>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Are Scheffe interval boundaries tangent to the ellipsoid confidence region??</p>
</div>
<div class="figure align-default" id="test-multi-bon-sch">
<a class="reference internal image-reference" href="../_images/test-multi-Bon-Sch.png"><img alt="" src="../_images/test-multi-Bon-Sch.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 22 </span><span class="caption-text">Bonferroni (left) and Scheffe (right) simultaneous C.I.s.</span><a class="headerlink" href="#test-multi-bon-sch" title="Permalink to this image">¶</a></p>
</div>
</li>
<li><p>If we just want to conduct univariate tests of means <span class="math notranslate nohighlight">\(H_0: \mu_k = 0\)</span> for each <span class="math notranslate nohighlight">\(k = 1, 2, \ldots, p\)</span>, i.e. <span class="math notranslate nohighlight">\(\boldsymbol{a} _k = \boldsymbol{e} _k\)</span>, then the C.I. has the general form <span class="math notranslate nohighlight">\(\bar{x}_{k} \pm c_{n, p, \alpha} \sqrt{\frac{s_{k k}}{n}}\)</span> for some multiplier <span class="math notranslate nohighlight">\(c_{n, p, \alpha}\)</span> depending on <span class="math notranslate nohighlight">\(n,p,\alpha\)</span>. The above methods can be summarized as follows</p>
<ul class="simple">
<li><p>marginal C.I. using <span class="math notranslate nohighlight">\(t\)</span> statistics (ignoring dependence among components): <span class="math notranslate nohighlight">\(t_{n-1}^{\alpha/2}\)</span></p></li>
<li><p>Bonferroni simultaneous C.I. using <span class="math notranslate nohighlight">\(t\)</span> statistics: <span class="math notranslate nohighlight">\(t_{n-1}^{\alpha/(2p)}\)</span></p></li>
<li><p>Scheffe simultaneous C.I.: <span class="math notranslate nohighlight">\(\sqrt{T^2_\alpha (p, n-1)}\)</span></p></li>
<li><p>Asymptotic simultaneous C.I. using <span class="math notranslate nohighlight">\(\chi ^2\)</span> statistic as <span class="math notranslate nohighlight">\(n\)</span> is large: <span class="math notranslate nohighlight">\(\sqrt{\chi ^2 _p (\alpha)}\)</span></p></li>
</ul>
</li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="two-sample-means">
<h3>Two-sample Means<a class="headerlink" href="#two-sample-means" title="Permalink to this headline">¶</a></h3>
<p>Given two samples of <span class="math notranslate nohighlight">\(p\)</span>-variates, we are interest in whether their means are equal.</p>
<div class="math notranslate nohighlight">
\[
H_0: \boldsymbol{\mu} _1 = \boldsymbol{\mu} _2,\quad H_1: \text{otherwise}
\]</div>
<div class="section" id="id3">
<h4>Paired<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<p>First, we consider paired comparison for two dependent samples.</p>
<p>This is easy, we just define <span class="math notranslate nohighlight">\(\bar{\boldsymbol{d}} = \bar{\boldsymbol{x}}_1 - \bar{\boldsymbol{x}}_2\)</span>, and apply the above one-sample mean method to test <span class="math notranslate nohighlight">\(H_0: \boldsymbol{d} = \boldsymbol{0}\)</span>.</p>
<p>More precisely, if <span class="math notranslate nohighlight">\(\boldsymbol{d} \sim \mathcal{N} _p (\boldsymbol{\delta}, \boldsymbol{\Sigma} _d)\)</span></p>
<div class="math notranslate nohighlight">
\[
T^{2}=n(\bar{\boldsymbol{d} }-\boldsymbol{\delta} ) ^{\top}  \boldsymbol{S} _d^{-1}(\bar{\boldsymbol{d} }-\boldsymbol{\delta} ) \sim T^2(p, n-1) \sim \frac{(n-1) p}{n-p} F_{p, n-p}
\]</div>
</div>
<div class="section" id="two-independent-samples">
<h4>Two Independent Samples<a class="headerlink" href="#two-independent-samples" title="Permalink to this headline">¶</a></h4>
<p>We assume equal variance <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma} _1 = \boldsymbol{\Sigma} _2 = \boldsymbol{\Sigma}\)</span>. The pooled sample covariance matrix is an unbiased estimator of it</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{S}_{\text {pool }}=\frac{\left(n_{1}-1\right) \boldsymbol{S}_{1}+\left(n_{2}-1\right) \boldsymbol{S}_{2}}{n_{1}+n_{2}-2}, \quad \mathbb{E}\left(\boldsymbol{S}_{\text {pool }}\right)=\boldsymbol{\Sigma}
\]</div>
<p>By the independence between the two samples, the covariance of sample difference is</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Cov}\left(\bar{\boldsymbol{x}}_{1}-\bar{\boldsymbol{x}}_{2}\right)=\operatorname{Cov}\left(\bar{\boldsymbol{x}}_{1}\right)+\operatorname{Cov}\left(\bar{\boldsymbol{x}}_{2}\right)=\frac{1}{n_{1}} \boldsymbol{\Sigma} +\frac{1}{n_{2}} \boldsymbol{\Sigma}
\]</div>
<p>which can be estimated by <span class="math notranslate nohighlight">\(\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right) \boldsymbol{S}_{\text {pool }}\)</span> since</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\left[\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right) \boldsymbol{S}_{\text {pool }}\right]=\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right) \boldsymbol{\Sigma} =\operatorname{Cov}\left(\bar{\boldsymbol{x}}_{1}-\bar{\boldsymbol{x}}_{2}\right)
\]</div>
<p>Assume <span class="math notranslate nohighlight">\(\boldsymbol{x} _1 \sim \mathcal{N} _p (\boldsymbol{\mu} _1, \boldsymbol{\Sigma} ), \boldsymbol{x} _2 \sim \mathcal{N} _p (\boldsymbol{\mu} _2, \boldsymbol{\Sigma} )\)</span>, then under <span class="math notranslate nohighlight">\(H_0: \boldsymbol{\mu} _1 = \boldsymbol{\mu} _2\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
T^{2} &amp;\sim T^{2}\left(p, n_{1}+n_{2}-2\right) \\
&amp;\sim \frac{\left(n_{1}+n_{2}-2\right) p}{n_{1}+n_{2}-p-1} F_{p, n_{1}+n_{2}-p-1}
\end{aligned}\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
T^{2}=\left[\left(\bar{\boldsymbol{x}}_{1}-\bar{\boldsymbol{x}}_{2}\right)-\left(\boldsymbol{\mu} _{1}-\boldsymbol{\mu} _{2}\right)\right]^{\top}\left[\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right) \boldsymbol{S}_{\text {pool }}\right]^{-1}\left[\left(\bar{\boldsymbol{x}}_{1}-\bar{\boldsymbol{x}}_{2}\right)-\left(\boldsymbol{\mu} _{1}-\boldsymbol{\mu} _{2}\right)\right]
\]</div>
<p>The <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> Bonferroni simultaneous confidence interval for the difference of the <span class="math notranslate nohighlight">\(j\)</span>-th component means <span class="math notranslate nohighlight">\(\mu_{1j} - \mu_{2j}\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{x}_{1 j}-\bar{x}_{2 j} \pm t_{n_{1}+n_{2}-2}^{\alpha / (2 p)} \sqrt{\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right) s_{j j, \text{pool} }}, \quad j=1, \cdots, p
\]</div>
<p>More generally,</p>
<ul>
<li><p><span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> Bonferroni intervals for pre-determined <span class="math notranslate nohighlight">\(\boldsymbol{a}_{i}^{\top}\left(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2}\right), i=1, \ldots, k\)</span> is</p>
<div class="math notranslate nohighlight">
\[
  \boldsymbol{a}_{i}^{\top}\left(\bar{\boldsymbol{x}}_{1}- \bar{\boldsymbol{x}}_{2}\right) \pm t_{n_{1}+n_{2}-2}^{\alpha / (2 k)} \sqrt{\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)\boldsymbol{a}_{i}^{\top} \boldsymbol{S}_{\text{pool} } \boldsymbol{a}_{i}}
  \]</div>
</li>
<li><p><span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> Scheffe simultaneous intervals for  <span class="math notranslate nohighlight">\(\boldsymbol{a}^{\top}\left(\boldsymbol{\mu}_{1}-\boldsymbol{\mu}_{2}\right)\)</span> for all <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> is</p>
<div class="math notranslate nohighlight">
\[
  \boldsymbol{a}^{\top}\left(\bar{\boldsymbol{x}}_{1}- \bar{\boldsymbol{x}}_{2}\right) \pm \sqrt{T_{\alpha}^{2}\left(p, n_{1}+n_{2}-2\right)} \sqrt{\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)\boldsymbol{a}^{\top} \boldsymbol{S}_{\text{pool} } \boldsymbol{a}}
  \]</div>
</li>
</ul>
</div>
</div>
<div class="section" id="manova">
<span id="id4"></span><h3>MANOVA<a class="headerlink" href="#manova" title="Permalink to this headline">¶</a></h3>
<p>If there are multiple samples of multivariate observations, we use Multivariate Analysis of Variance (MANOVA). The data are treated as <span class="math notranslate nohighlight">\(g\)</span> sample groups of observed sample values, each sample group is from one of <span class="math notranslate nohighlight">\(g\)</span> populations.</p>
<div class="section" id="id5">
<h4>Model<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h4>
<p>The MANOVA model, generalized from ANOVA, becomes</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{X}_{\ell j}=\boldsymbol{\mu}+\boldsymbol{\tau}_{\ell}+\boldsymbol{e}_{\ell j}, \quad j=1, \cdots, n_{\ell}, \quad \ell=1, \cdots, g
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> is the <strong>overall mean</strong> vector,</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\tau} _{\ell}\)</span> is the <strong>treatment effect</strong> vector of the <span class="math notranslate nohighlight">\(\ell\)</span> th population or treatment group,</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{e}_{\ell j} \sim N_{p}(0, \Sigma)\)</span> is individual specific homogenous noise.</p></li>
<li><p>The parameter constraint here is <span class="math notranslate nohighlight">\(\sum_{\ell=1}^{g} n_{\ell} \boldsymbol{\tau}_{\ell}=0\)</span>.</p></li>
</ul>
</div>
<div class="section" id="id6">
<h4>Test Statistic<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p>Analogous to the univariate case, the test of interest is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{\begin{array}{ll}
H_{0}: &amp; \boldsymbol{\tau}_{1}=\cdots=\boldsymbol{\tau}_{g}=\boldsymbol{0}_{p} \\
H_{1}: &amp; \boldsymbol{\tau}_{\ell} \neq 0_{p}, \text { for some } \ell=1, \cdots, g .
\end{array}\right.
\end{split}\]</div>
<p>The data can be decomposed similarly,</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{x}_{\ell j}=\bar{\boldsymbol{x}}+\left(\bar{\boldsymbol{x}}_{\ell}-\bar{\boldsymbol{x}}\right)+\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}_{\ell}\right)
\]</div>
<p>or</p>
<div class="math notranslate nohighlight">
\[
(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}})=\left(\bar{\boldsymbol{x}}_{\ell}-\bar{\boldsymbol{x}}\right)+\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}_{\ell}\right)
\]</div>
<p>Then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}\right)\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}\right)^{\prime}=&amp;\left(\bar{\boldsymbol{x}}_{\ell}-\bar{\boldsymbol{x}}\right)\left(\bar{\boldsymbol{x}}_{\ell}-\bar{\boldsymbol{x}}\right)^{\prime}+\left(\bar{\boldsymbol{x}}_{\ell}-\bar{\boldsymbol{x}}\right)\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}_{\ell}\right)^{\prime} \\
&amp;+\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}_{\ell}\right)\left(\bar{\boldsymbol{x}}_{\ell}-\bar{\boldsymbol{x}}\right)^{\prime}+\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}_{\ell}\right)\left(\boldsymbol{x}_{\ell j}-\bar{\boldsymbol{x}}_{\ell}\right)^{\prime}
\end{aligned}
\end{split}\]</div>
<p>Summing up, we have</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}\right)\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}\right)^{\prime}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\overline{\boldsymbol{x}}_{\ell}-\overline{\boldsymbol{x}}\right)\left(\overline{\boldsymbol{x}}_{\ell}-\overline{\boldsymbol{x}}\right)^{\prime}+\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\mathbf{x}}_{\ell}\right)\left(\boldsymbol{x}_{\ell_{j}}-\overline{\boldsymbol{x}}_{\ell}\right)^{\prime}
\]</div>
<p>since</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\overline{\boldsymbol{x}}_{\ell}-\overline{\boldsymbol{x}}\right)\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}_{\ell}\right)^{\prime}=\boldsymbol{0}_{p \times p}, \quad \sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}_{\ell}\right)\left(\overline{\boldsymbol{x}}_{\ell}-\overline{\boldsymbol{x}}\right)^{\prime}=\boldsymbol{0}_{p \times p}
\]</div>
<p>The decomposition can be stated as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\sum(\text { total variation })^{2}=\sum\left(\begin{array}{c}
\text { &quot;between-group&quot; } \\
\text { treatment variation }
\end{array}\right)^{2}+\sum\left(\begin{array}{c}
\text { &quot;within-group&quot; } \\
\text { residual variation }
\end{array}\right)^{2}
\end{split}\]</div>
<p>with corresponding degrees of freedom</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^{g} n_{\ell}-1=(g-1)+\sum_{\ell=1}^{g}\left(n_{\ell}-1\right)
\]</div>
<p>Now we analyze the test statistic</p>
<p>Denote the between group (or between population) sum of squares and
cross products matrix as</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{B}=\sum_{\ell=1}^{g} n_{\ell}\left(\overline{\boldsymbol{x}}_{\ell}-\overline{\boldsymbol{x}}\right)\left(\overline{\boldsymbol{x}}_{\ell}-\overline{\boldsymbol{x}}\right)^{\prime}
\]</div>
<p>and the within group sum of squares and cross products matrix as</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{W}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}_{\ell}\right)\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}_{\ell}\right)^{\prime}=\left(n_{1}-1\right) \boldsymbol{S}_{1}+\cdots+\left(n_{g}-1\right) \boldsymbol{S}_{g}
\]</div>
<p>In fact <span class="math notranslate nohighlight">\(\boldsymbol{W}\)</span> is related to the pooled covariance matrix,</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{S}_{\text {pool }}=\frac{1}{\sum_{\ell=1}^{g}\left(n_{\ell}-1\right)}\left[\left(n_{1}-1\right) \boldsymbol{S}_{1}+\cdots+\left(n_{g}-1\right) \boldsymbol{S}_{g}\right]=\frac{1}{n-\mathrm{g}} \boldsymbol{W}
\]</div>
<p>The MANOVA table is then</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{c|c|c}
\hline \begin{array}{c}
\text { Source } \\
\text { of variation }
\end{array} &amp; \begin{array}{c}
\text { Matrix of sum of squares } \\
\text { and cross-products }
\end{array} &amp; \begin{array}{c}
\text { Degrees } \\
\text { of freedom }
\end{array} \\
\hline \text { Treatments } &amp; \boldsymbol{B}=\sum_{\ell=1}^{g} n_{\ell}\left(\overline{\boldsymbol{x}}_{\ell}-\bar{x}\right)\left(\overline{\boldsymbol{x}}_{\ell}-\bar{x}\right)^{\prime} &amp; g-1 \\
\text { Residuals } &amp; \boldsymbol{W}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}_{\ell}\right)\left(\boldsymbol{x}_{\ell j}-\overline{\mathbf{x}}_{\ell}\right)^{\prime} &amp; \sum_{\ell=1}^{g} n_{\ell}-\mathrm{g} \\
\hline \text { Total } &amp; \boldsymbol{B}+\boldsymbol{W}=\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}\right)\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}\right)^{\prime} &amp; \sum_{\ell=1}^{g} n_{\ell}-1 \\
\hline
\end{array}
\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\boldsymbol{B}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{W}\)</span> are <span class="math notranslate nohighlight">\(p \times p\)</span> covariance matrices, the test statistic uses their determinants, or the generalized variances.</p>
<p>We introduce Wilks’ Lambda</p>
<div class="math notranslate nohighlight">
\[
\Lambda^{*}=\frac{\operatorname{det}(\boldsymbol{W})}{\operatorname{det}(\boldsymbol{B}+\boldsymbol{W})}=\frac{\left|\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell j}-\overline{\boldsymbol{x}}_{\ell}\right)\left(\boldsymbol{x}_{\ell j}-\overline{\mathbf{x}}_{\ell}\right)^{\prime}\right|}{\left|\sum_{\ell=1}^{g} \sum_{j=1}^{n_{\ell}}\left(\boldsymbol{x}_{\ell_{j}}-\overline{\boldsymbol{x}}\right)\left(\boldsymbol{x}_{\ell_{j}}-\overline{\boldsymbol{x}}\right)^{\prime}\right|}
\]</div>
<p>which is the ratio of generalized variance of residual / generalized variance of total.</p>
<p>The distribution of <span class="math notranslate nohighlight">\(\Lambda^{*}\)</span> depends on <span class="math notranslate nohighlight">\(p, g, n_\ell\)</span> and is related to <span class="math notranslate nohighlight">\(F\)</span> distribution. When <span class="math notranslate nohighlight">\(n = \sum n_\ell\)</span> is large, Bartlett gives a simple chi-square approximation</p>
<div class="math notranslate nohighlight">
\[
-\left(n-1-\frac{p+g}{2}\right) \ln \Lambda^{*} \sim \chi_{p(g-1)}^{2}
\]</div>
<p>Even for moderate sample size, it is good practice to check and compare both tests.</p>
<p>Note</p>
<ul>
<li><p>We reject the null hypothesis that all group means are equal if the value of <span class="math notranslate nohighlight">\(\Lambda^{*}\)</span> is too “small”.</p></li>
<li><p>Wilks’ lambda is equivalent to the likelihood ratio test statistic.</p></li>
<li><p>Under the null Wilks’ lambda is of its own <span class="math notranslate nohighlight">\(\Lambda^{*}\)</span>-distribution, which is derived from the ratio of two random matrices <span class="math notranslate nohighlight">\(\boldsymbol{W}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{B} + \boldsymbol{W}\)</span>, each is of <a class="reference internal" href="../12-probabilities/91-exponential-families.html#wishart-distribution"><span class="std std-ref">Wishart distribution</span></a></p></li>
<li><p>We can express Wilks’ lambda by eigenvalues of <span class="math notranslate nohighlight">\(\boldsymbol{B} \boldsymbol{W} ^{-1}\)</span>, which can be seen as signal-noise ratio. If it is large, then <span class="math notranslate nohighlight">\(\lambda\)</span> is large, and <span class="math notranslate nohighlight">\(\Lambda^{*}\)</span> is small.</p>
<div class="math notranslate nohighlight">
\[
  \Lambda^{*}=\frac{|\boldsymbol{W}|}{|\boldsymbol{B}+\boldsymbol{W}|}=\frac{1}{\left|\boldsymbol{W}^{-1} \boldsymbol{B}+\boldsymbol{l}\right|}=\prod_{k=1}^{p} \frac{1}{1+\lambda_{k}}
  \]</div>
</li>
</ul>
<p>Other test statistics using the eigenvalues of <span class="math notranslate nohighlight">\(\boldsymbol{B} \boldsymbol{W} ^{-1}\)</span> include</p>
<ul class="simple">
<li><p>Hotelling-Lawley’s Trace: <span class="math notranslate nohighlight">\(\operatorname{trace}\left(\mathbf{B W}^{-1}\right)=\sum_{k=1}^{p} \lambda_{k}\)</span></p></li>
<li><p>Pillai’s Trace:  <span class="math notranslate nohighlight">\(\operatorname{trace}\left(\boldsymbol{B}(\boldsymbol{B}+\boldsymbol{W})^{-1}\right)=\operatorname{trace}\left(\boldsymbol{B} \boldsymbol{W}^{-1}\left(\boldsymbol{B} \boldsymbol{W}^{-1}+I\right)^{-1}\right)=\sum_{k=1}^{p} \frac{\lambda_{k}}{1+\lambda_{k}}\)</span></p></li>
<li><p>Roy’s Largest Root: <span class="math notranslate nohighlight">\(\max _{k}\left\{\lambda_{k}\right\}=\left\|\boldsymbol{B} \boldsymbol{W}^{-1}\right\|_{\infty}\)</span> which gives an upper bound</p></li>
</ul>
</div>
<div class="section" id="c-i-for-difference-in-two-means">
<h4>C.I. for Difference in Two Means<a class="headerlink" href="#c-i-for-difference-in-two-means" title="Permalink to this headline">¶</a></h4>
<p>If the null hypothesis of MANOVA is rejected, a natural question is, <strong>which</strong> treatments have significant effects?</p>
<p>To compare the effect of treatment <span class="math notranslate nohighlight">\(k\)</span> and treatment <span class="math notranslate nohighlight">\(\ell\)</span>, the quantity of interests is the difference of the vectors <span class="math notranslate nohighlight">\(\boldsymbol{\tau}_k - \boldsymbol{\tau}_\ell\)</span> which is the same as <span class="math notranslate nohighlight">\(\boldsymbol{\mu} _k - \boldsymbol{\mu} _\ell\)</span>. For two fixed <span class="math notranslate nohighlight">\(k, \ell\)</span>, there are <span class="math notranslate nohighlight">\(p\)</span> variables to compare. For each variable <span class="math notranslate nohighlight">\(i\)</span>, we want a confidence interval for <span class="math notranslate nohighlight">\(\tau_{ki} - \tau_{\ell i}\)</span>, which have the form</p>
<div class="math notranslate nohighlight">
\[
\hat{\tau}_{k i}-\hat{\tau}_{\ell i} \pm c \times \sqrt{\widehat{\operatorname{Var}}\left(\hat{\tau}_{k i}-\hat{\tau}_{\ell i}\right)}
\]</div>
<p>where the multiplier <span class="math notranslate nohighlight">\(c\)</span> depends on the level and the type of the confidence interval.</p>
<p>Assuming mutual independence and equal variance <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> among the <span class="math notranslate nohighlight">\(g\)</span> samples, using Bonferroni correction, we have</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(c = t_{n-g}^{\alpha/2m}\)</span>, where <span class="math notranslate nohighlight">\(m= p \binom{g}{2}\)</span> is the number of simultaneous confidence intervals.</p></li>
<li><p><span class="math notranslate nohighlight">\(\widehat{\operatorname{Var}}\left(\hat{\tau}_{k i}-\hat{\tau}_{\ell i}\right)=\frac{w_{i i}}{n-g}\left(\frac{1}{n_{k}}+\frac{1}{n_{\ell}}\right)\)</span> where <span class="math notranslate nohighlight">\(w_{ii}\)</span> is the diagonal entry of <span class="math notranslate nohighlight">\(\boldsymbol{W}\)</span>.</p></li>
</ul>
<p>Note that</p>
<ul class="simple">
<li><p>The Bonferroni method often gives confidence intervals too wide to be practical even for moderate <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(g\)</span>.</p></li>
<li><p>The equal variance can be tested.</p></li>
</ul>
</div>
<div class="section" id="test-for-equal-covariance">
<h4>Test for Equal Covariance<a class="headerlink" href="#test-for-equal-covariance" title="Permalink to this headline">¶</a></h4>
<p>Are the variables in the <span class="math notranslate nohighlight">\(g\)</span> population groups sharing the same
covariance structure?</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{\begin{array}{ll}
H_{0}: &amp; \boldsymbol{\Sigma}_{1}=\boldsymbol{\Sigma}_{2}=\cdots=\boldsymbol{\Sigma}_{g}=\boldsymbol{\Sigma} \\
H_{1}: &amp; \boldsymbol{\Sigma}_{i} \neq \boldsymbol{\Sigma}_{j} \quad \text { for some } i \neq j
\end{array}\right.
\end{split}\]</div>
<p>Box’s <span class="math notranslate nohighlight">\(M\)</span>-test for equal covariance structure is a likelihood-ratio type of test. Denote</p>
<div class="math notranslate nohighlight">
\[
\Lambda=\prod_{\ell=1}^{g}\left(\frac{\left|\boldsymbol{S}_{\ell}\right|}{\left|\boldsymbol{S}_{\text {pool }}\right|}\right)^{\left(n_{\ell}-1\right) / 2}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{S}_{\text {pool }}=\frac{1}{\sum_{\ell=1}^{g}\left(n_{\ell}-1\right)}\left[\left(n_{1}-1\right) \boldsymbol{S}_{1}+\cdots+\left(n_{g}-1\right) \boldsymbol{S}_{g}\right]=\frac{1}{n-\mathrm{g}} \boldsymbol{W}
\]</div>
<p>Box’s test is based on an approximation that the sampling distribution of <span class="math notranslate nohighlight">\(\ln \Lambda\)</span> is approximately of <span class="math notranslate nohighlight">\(\chi ^2\)</span> distribution under the equal covariance matrix hypothesis. Box’s <span class="math notranslate nohighlight">\(M\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
M &amp;=-2 \ln \Lambda \\
&amp;=(n-g) \ln \left|\boldsymbol{S}_{\text {pool }}\right|-\sum_{\ell=1}^{g}\left[\left(n_{\ell}-1\right) \ln \left|\boldsymbol{S}_{\ell}\right|\right]
\end{aligned}
\end{split}\]</div>
<p>Under the hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> of equal covariance, approximately</p>
<div class="math notranslate nohighlight">
\[
(1-u) M \sim \chi_{v}^{2}
\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(u = \left(\sum_{\ell=1}^{g} \frac{1}{n_{\ell}-1}-\frac{1}{n-g}\right) \frac{2 p^{2}+3 p-1}{6(p+1)(g-1)}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(v = p(p+1)(g-1)/2\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(H_0\)</span> is rejected if <span class="math notranslate nohighlight">\((1-u) M &gt; \chi_{v}^{2}(\alpha)\)</span>. Box’s M-test works well for small <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(g\)</span> <span class="math notranslate nohighlight">\((\le 5)\)</span> and moderate to large <span class="math notranslate nohighlight">\(n_\ell\)</span> <span class="math notranslate nohighlight">\((\ge 20)\)</span>.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./13-statistics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="21-hypothesis-testing.html" title="previous page">Hypothesis Testing</a>
    <a class='right-next' id="next-link" href="33-confusion-matrix.html" title="next page">Confusion Matrix</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dennis Zheng<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-150740237-2', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>