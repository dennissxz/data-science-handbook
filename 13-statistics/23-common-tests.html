
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Common Tests &#8212; Data Science Handbook</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Confusion Matrix" href="33-confusion-matrix.html" />
    <link rel="prev" title="Hypothesis Testing" href="21-hypothesis-testing.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Data Science Handbook</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Data Science Handbook
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Foundations
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11-math/00-math.html">
   Math
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/11-combinatorics.html">
     Combinatorics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/20-vector-spaces.html">
     Vector Spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/31-geometry.html">
     Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/21-linear-algebra.html">
     Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/51-linear-programming.html">
     Linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/52-non-linear-programming.html">
     Non-linear Programming
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11-math/90-puzzles.html">
     Puzzles
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12-probabilities/00-probabilities.html">
   Probabilities
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/11-expectation-and-variance.html">
     Expectation and Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/13-correlation-and-dependence.html">
     Correlation and Dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/31-bayesian-theorem.html">
     Bayesianâ€™s Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/51-markov-chain.html">
     Markov Chain
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/71-sampling.html">
     Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/90-multivariate-notations.html">
     Multivariate Notations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/91-exponential-families.html">
     Exponential Families
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12-probabilities/91-large-sample-theory.html">
     Large Sample Theory
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="00-statistics.html">
   Statistics
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="11-sample-survey.html">
     Sample Survey
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13-randomized-trial.html">
     Randomized Controlled Trials
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="21-hypothesis-testing.html">
     Hypothesis Testing
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Common Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="33-confusion-matrix.html">
     Confusion Matrix
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="41-maximum-likelihood-estimation.html">
     Maximum Likelihood Estimator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="43-estimators-evaluation.html">
     Estimators Evaluation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../15-programming/00-programming.html">
   Programming
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../15-programming/11-python.html">
     Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-programming/21-r.html">
     R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../15-programming/31-sql.html">
     SQL
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../19-miscellaneous/00-miscellaneous.html">
   Miscellaneous
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../19-miscellaneous/11-latex.html">
     LaTeX
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../19-miscellaneous/13-myst.html">
     MyST Markdown
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Algorithms
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../20-algorithms-concepts/00-algorithms-concepts.html">
   Algorithms Concepts
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/51-polynomial-reduction.html">
     Polynomial Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/53-P-and-NP.html">
     <span class="math notranslate nohighlight">
      \(P\)
     </span>
     and
     <span class="math notranslate nohighlight">
      \(NP\)
     </span>
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../20-algorithms-concepts/61-randomized-algo.html">
     Randomized Algorithms
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../21-greedy-algorithms/00-greedy-algorithms.html">
   Greedy Algorithms
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/11-interval-scheduling.html">
     Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../21-greedy-algorithms/31-huffman-coding.html">
     Huffman Coding
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../23-dynamic-programming/00-dynamic-programming.html">
   Dynamic Programming
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/11-weighted-interval-scheduling.html">
     Weighted Interval Scheduling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/13-longest-common-subsequence.html">
     Longest Common Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/15-longest-increasing-subsequence.html">
     Longest Increasing Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/17-largest-sum-subsequence.html">
     Largest Sum Subsequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/31-knapsack.html">
     Minimum Knapsack
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../23-dynamic-programming/51-chain-matrix-multiplication.html">
     Chain Matrix Multiplication
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../25-graph-related/00-graph-related.html">
   Graph Related
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/13-shortest-path.html">
     Shortest Path
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/21-minimum-spanning-tree.html">
     Minimum Spanning Tree
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/31-maximum-flow.html">
     Maximum Flow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/32-matching.html">
     Matching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/42-maximum-independent-set.html">
     Maximum Independent Set in Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../25-graph-related/91-LP-max-flow-min-cut.html">
     LP on Max-flow and Min-cut
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../26-algo-for-big-data/00-algo-for-big-data.html">
   For Big Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../26-algo-for-big-data/10-streaming.html">
     Streaming Model
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../30-ml-basics/00-ml-basics.html">
   Machine Learning Basics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/02-taxonomy.html">
     Taxonomy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/03-information-theory.html">
     Information Theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/05-kernels.html">
     Kernels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/11-data-issues.html">
     Data Issues
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/51-semi-supervised.html">
     Semi-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/53-self-supervised.html">
     Self-supervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../30-ml-basics/61-fourier-transform.html">
     Fourier Transform-based Representations
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../31-regression/00-regression.html">
   Regression
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/11-lm-estimation.html">
     Linear Models - Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/12-lm-inference.html">
     Linear Models - Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/13-lm-diagnosis.html">
     Linear Models - Diagnosis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/14-lm-advanced.html">
     Linear Models - Advanced Topics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/21-generalized-linear-models.html">
     Generalized Linear Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/22-logistic-regression.html">
     Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/23-multinomial-logitsitc.html">
     Multinomial Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/24-ordinal-logistic.html">
     Ordinal Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../31-regression/25-poisson-regression.html">
     Poisson Regression
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../32-classification/00-classification.html">
   Classification
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/11-support-vector-machine.html">
     Support Vector Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../32-classification/21-decision-tree.html">
     Decision Tree
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../33-dimensionality-reduction/00-dimensionality-reduction.html">
   Dimensionality Reduction
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/11-principal-component-analysis.html">
     Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/13-canonical-correlation-analysis.html">
     Canonical Correlation Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/21-multidimensional-scaling.html">
     Multidimensional Scaling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/23-graph-based-spectral-methods.html">
     Graph-based Spectral Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/25-t-SNE.html">
     SNE and
     <span class="math notranslate nohighlight">
      \(t\)
     </span>
     -SNE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/31-kernel-pca.html">
     Kernel PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/32-kernel-cca.html">
     Kernel CCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../33-dimensionality-reduction/41-factor-analysis.html">
     Factor Analysis
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../34-clustering/00-clustering.html">
   Clustering
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/11-k-means.html">
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -means clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/13-agglomerative-methods.html">
     Agglomerative Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/31-spectral-clustering.html">
     Spectral Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../34-clustering/41-gaussian-mixtures.html">
     Gaussian Mixtures
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../35-graphical-models/00-graphical-models.html">
   Graphical Models
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/03-random-walks.html">
     Random Walks in Graphs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/11-hidden-markov-models.html">
     Hidden Markov Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/31-topic-models.html">
     Topic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../35-graphical-models/33-language-models.html">
     Language Models
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../37-neural-networks/00-neural-networks.html">
   Neural Networks
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/01-stochastic-gradient-descent.html">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/03-trainability.html">
     Trainability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/05-regularization.html">
     Regularization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/11-autoencoders.html">
     Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/13-variational-autoencoders.html">
     Variational Autoencoders
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/31-sequential-models.html">
     Sequential Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../37-neural-networks/41-GAN.html">
     Generative Adversarial Networks
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../38-ml-for-graph-data/00-ml-for-graph-data.html">
   For Graph-structured Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/01-graph-basics.html">
     Graph Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/11-descriptive-analysis.html">
     Descriptive Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/13-sampling-and-estimation.html">
     Sampling and Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/21-modeling.html">
     Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../38-ml-for-graph-data/31-topology-inference.html">
     Topology Inference
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/13-statistics/23-common-tests.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/dennissxz/data-science-handbook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/dennissxz/data-science-handbook/issues/new?title=Issue%20on%20page%20%2F13-statistics/23-common-tests.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#two-sample-mean-tests">
   Two-sample Mean Tests
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#paired">
     Paired
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#normal">
       Normal
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#non-normal">
       Non-normal
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#independent">
     Independent
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#equal-variance">
       Equal Variance
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id1">
         Normal
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id2">
         Non-normal
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#unequal-variance">
       Unequal Variance
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multivariate-settings">
   Multivariate Settings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hotelling-s-t-2-distribution">
     Hotellingâ€™s
     <span class="math notranslate nohighlight">
      \(T^2\)
     </span>
     Distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-sample-mean">
     One-sample Mean
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="common-tests">
<h1>Common Tests<a class="headerlink" href="#common-tests" title="Permalink to this headline">Â¶</a></h1>
<!-- ## Median test

Mood's median test is a special case of Pearson's chi-squared test. It is a nonparametric test that tests the null hypothesis that the medians of the populations from which two or more samples are drawn are identical.

## $z$-test

## $t$-test

## $F$-test

$F$ -distribution with degrees of freedom $\left(d_{1}, d_{2}\right)$, denoted as $F_{d_{1}, d_{2}}$, has the form
$$
\frac{Y_{1} / d_{1}}{Y_{2} / d_{2}}
$$
with $Y_{1} \sim \chi_{d_{1}}^{2}, \quad Y_{1} \sim \chi_{d_{2}}^{2}$ and $Y_{1} \Perp Y_{2}$.

## $\chi^2$-test -->
<div class="section" id="two-sample-mean-tests">
<h2>Two-sample Mean Tests<a class="headerlink" href="#two-sample-mean-tests" title="Permalink to this headline">Â¶</a></h2>
<p>Suppose we have two samples of data <span class="math notranslate nohighlight">\(\left\{x_{1}, \cdots, x_{n}\right\}\)</span> and <span class="math notranslate nohighlight">\(\left\{y_{1}, \cdots, y_{m}\right\}\)</span>.</p>
<p>A question of interest: Did the two samples come from the same distribution, as opposed to, one sample having larger values than the other on average?</p>
<p>To model them, we assume</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_{i}, \cdots, X_{n}\)</span> i.i.d. sampled from a distribution with mean with mean <span class="math notranslate nohighlight">\(\mu_X\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 _X\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Y_{i}, \cdots, Y_{m}\)</span> i.i.d. sampled from a distribution with mean with mean <span class="math notranslate nohighlight">\(\mu_Y\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2 _Y\)</span></p></li>
</ul>
<p>We are interested in comparing the two samples, often by comparing the two means <span class="math notranslate nohighlight">\(\mu_X\)</span> and <span class="math notranslate nohighlight">\(\mu_Y\)</span>.</p>
<p>An unbiased estimator for the difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is <span class="math notranslate nohighlight">\(\bar{X} - \bar{Y}\)</span>. To provide standard error to this estimator, <span class="math notranslate nohighlight">\(\operatorname{Var}\left( \bar{X} - \bar{Y} \right)\)</span> need to be estimated, contingent on sample properties.</p>
<div class="section" id="paired">
<h3>Paired<a class="headerlink" href="#paired" title="Permalink to this headline">Â¶</a></h3>
<p>In many studies, the <span class="math notranslate nohighlight">\(i\)</span>-th measurements in the two samples <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> actually are related, such as measurements before and after a treatment from the same subject.</p>
<p>When <span class="math notranslate nohighlight">\(m = n\)</span> and <span class="math notranslate nohighlight">\(\operatorname{Corr}\left( X_i,Y_i \right) = \rho \ne 0\)</span>, very often <span class="math notranslate nohighlight">\(\rho &gt;0\)</span>. Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\operatorname{Var}(\bar{X}-\bar{Y}) &amp;=\operatorname{Var}(\bar{X})+\operatorname{Var}(\bar{Y})-2 \times \operatorname{Cov}(\bar{X}, \bar{Y}) \\
&amp; \leq \operatorname{Var}(\bar{X})+\operatorname{Var}(\bar{Y}) \quad \text{when }\rho &gt;0
\end{aligned}
\end{split}\]</div>
<p>To have a more precise variance estimate, it is appropriate to consider pairing <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(Y_i\)</span> by investigating their difference:</p>
<div class="math notranslate nohighlight">
\[
D_{i}=X_{i}-Y_{i}, \quad i=1, \cdots, n
\]</div>
<p>Note that <span class="math notranslate nohighlight">\(D_i\)</span>â€™s are i.i.d. under the i.i.d. assumption of each of the two samples, with</p>
<div class="math notranslate nohighlight">
\[
\mu_{D}=\mu_{X}-\mu_{Y}, \quad \sigma_{D}^{2}=\sigma_{X}^{2}+\sigma_{Y}^{2}-2 \rho \sigma_{X} \sigma_{Y}
\]</div>
<p>Then essentially, we changed the inference problem into that of a <strong>one-sample case</strong>.</p>
<p>An unbiased estimator for the variance of difference <span class="math notranslate nohighlight">\(\sigma^2_D\)</span> is the sample variance.</p>
<div class="math notranslate nohighlight">
\[
S_{D}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(D_{i}-\bar{D}\right)^{2}=\widehat{\operatorname{Var}}\left(D_{i}\right)=\hat{\sigma}_{D}^{2}
\]</div>
<div class="section" id="normal">
<h4>Normal<a class="headerlink" href="#normal" title="Permalink to this headline">Â¶</a></h4>
<p>If <span class="math notranslate nohighlight">\(X \sim \mathcal{N} \left(\mu_{X}, \sigma_{X}^{2}\right), Y \sim \mathcal{N} \left(\mu_{Y}, \sigma_{Y}^{2}\right)\)</span>, then we have the distributions for the sample estimators</p>
<div class="math notranslate nohighlight">
\[
\frac{\bar{D}-\mu_{D}}{\sigma_{D} / \sqrt{n}} \sim \mathcal{N}(0,1), \quad \frac{(n-1) S_{D}^{2}}{\sigma_{D}^{2}} \sim \chi_{n-1}^{2}
\]</div>
<p>In addition, they are independent. By the definition of <span class="math notranslate nohighlight">\(t\)</span>-distribution, the test statistic</p>
<div class="math notranslate nohighlight">
\[
\frac{\bar{D}-\mu_{D}}{S_{D} / \sqrt{n}} \sim t_{n-1}
\]</div>
<p>is a pivot quantity not depending on the parameters if we are testing a hypothesis on <span class="math notranslate nohighlight">\(\mu_D\)</span>. For instance,</p>
<div class="math notranslate nohighlight">
\[
H_{0}: \mu_{D}=0
\]</div>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{X}-\bar{Y} \pm t_{n-1}^{(1-\alpha / 2)} \frac{S_{D}}{\sqrt{n}}
\]</div>
</div>
<div class="section" id="non-normal">
<h4>Non-normal<a class="headerlink" href="#non-normal" title="Permalink to this headline">Â¶</a></h4>
<p>When the samples are not normally distributed, <span class="math notranslate nohighlight">\(t_{n-1}\)</span> can be used as an approximate distribution.</p>
<p>When n is large, we may use the Central Limit Theorem,</p>
<div class="math notranslate nohighlight">
\[
\frac{\bar{D}-\mu_{D}}{S_{D} / \sqrt{n}} \overset{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)
\]</div>
<p>The asymptotic pivotal property can be used to conduct hypothesis tests.</p>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{X}-\bar{Y} \pm z^{(1-\alpha / 2)} \frac{S_{D}}{\sqrt{n}}
\]</div>
</div>
</div>
<div class="section" id="independent">
<h3>Independent<a class="headerlink" href="#independent" title="Permalink to this headline">Â¶</a></h3>
<p>Now we consider <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(Y_j\)</span> are independent.</p>
<div class="section" id="equal-variance">
<h4>Equal Variance<a class="headerlink" href="#equal-variance" title="Permalink to this headline">Â¶</a></h4>
<p>If <span class="math notranslate nohighlight">\(\sigma^2 _X = \sigma^2 _Y\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Var}(\bar{X}-\bar{Y})=\frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}=\sigma^{2}\left(\frac{1}{n}+\frac{1}{m}\right)
\]</div>
<p>and both sample variances <span class="math notranslate nohighlight">\(S_X^2\)</span> and <span class="math notranslate nohighlight">\(S_Y^2\)</span> are unbiased estimators of <span class="math notranslate nohighlight">\(\sigma^2\)</span></p>
<p>A better unbiased estimator is the <strong>pooled sample variance</strong></p>
<div class="math notranslate nohighlight">
\[
S_{p}^{2}=S_{\text {pooled }}^{2}=\frac{(n-1) S_{X}^{2}+(m-1) S_{Y}^{2}}{n+m-2}
\]</div>
<p>which has a <strong>larger testing power</strong> than the two sample variances.</p>
<div class="section" id="id1">
<h5>Normal<a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h5>
<p>If both <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are of normal distributions, then the test statistic is</p>
<div class="math notranslate nohighlight">
\[
\frac{(\bar{X}-\bar{Y})-\left(\mu_{X}-\mu_{Y}\right)}{S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{n+m-2}
\]</div>
<p>A <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\bar{X}-\bar{Y} \pm t_{n+m-2,1-\alpha / 2} S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}
\]</div>
</div>
<div class="section" id="id2">
<h5>Non-normal<a class="headerlink" href="#id2" title="Permalink to this headline">Â¶</a></h5>
<p>When the samples are not normally distributed, <span class="math notranslate nohighlight">\(t_{n+m-2}\)</span> distribution can be used as an approximation.</p>
<p>When <strong>both</strong> <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> are large, we may apply the Central Limit Theorem,</p>
<div class="math notranslate nohighlight">
\[
\frac{(\bar{X}-\bar{Y})-\left(\mu_{X}-\mu_{Y}\right)}{S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}} \overset{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)
\]</div>
<div class="note admonition">
<p class="admonition-title"> Pooling vs paring</p>
<p>Consider the case n = m with equal variance.</p>
<ul>
<li><p>Under assumption that the two samples are independent, the variance is</p>
<div class="math notranslate nohighlight">
\[
    \operatorname{Var}(\bar{X}-\bar{Y})= \frac{2 \sigma^{2}}{n}
    \]</div>
<p>The pooled sample variance is the appropriate estimator to be used.</p>
</li>
<li><p>If the two samples were correlated with <span class="math notranslate nohighlight">\(Corr(X_i, X_j) = \rho &gt; 0\)</span>, the variance becomes smaller</p>
<div class="math notranslate nohighlight">
\[
    \operatorname{Var} (\bar{X}-\bar{Y})=(1-\rho) \frac{2 \sigma^{2}}{n}&lt; \frac{2 \sigma^{2}}{n}
    \]</div>
</li>
</ul>
<p>As a result, when correlation exists, the smaller paired sample variance is the appropriate one to use, since the test statistic using it has a <strong>larger power</strong>.</p>
<p>On the other hand, if the correlation is substantial and we fail to take it into consideration, the pooled sample variance estimator likely will overestimate the variance, and the estimate could be too large to be useful.</p>
</div>
</div>
</div>
<div class="section" id="unequal-variance">
<h4>Unequal Variance<a class="headerlink" href="#unequal-variance" title="Permalink to this headline">Â¶</a></h4>
<p>If <span class="math notranslate nohighlight">\(\sigma_{X}^{2} \neq \sigma_{Y}^{2}\)</span>, the variance we are interested to estimate has the form</p>
<div class="math notranslate nohighlight">
\[
\operatorname{Var}(\bar{X}-\bar{Y})=\frac{\sigma_{X}^{2}}{n}+\frac{\sigma_{Y}^{2}}{m}
\]</div>
<p>which can be estimated by the unbiased estimator</p>
<div class="math notranslate nohighlight">
\[
\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}
\]</div>
<p>It is complicated to construct a pivot quantity like we did for the previous cases. Consider</p>
<div class="math notranslate nohighlight">
\[
T=\frac{\bar{X}-\bar{Y}-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}}
\]</div>
<p>When both <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are of normal distributions, we have</p>
<div class="math notranslate nohighlight">
\[
(n-1) S_{X}^{2} / \sigma_{X}^{2} \sim \chi_{n-1}^{2}, \quad(m-1) S_{Y}^{2} / \sigma_{Y}^{2} \sim \chi_{m-1}^{2}
\]</div>
<p>But since <span class="math notranslate nohighlight">\(\sigma_{X}^{2} \neq \sigma_{Y}^{2}\)</span>, the summation</p>
<div class="math notranslate nohighlight">
\[
\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m} \sim \frac{\sigma_{X}^{2}}{n(n-1)} x_{n-1}^{2}+\frac{\sigma_{Y}^{2}}{m(m-1)} X_{m-1}^{2}
\]</div>
<p>is not a multiple of a <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution.</p>
<p>Hence, <span class="math notranslate nohighlight">\(T\)</span> is not <span class="math notranslate nohighlight">\(t\)</span>-distributed.</p>
<p>If <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span> are both large, we can resort to Central Limit Theorem as usual,</p>
<div class="math notranslate nohighlight">
\[
T=\frac{\left( \bar{X}-\bar{Y} \right)-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}} \stackrel{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)
\]</div>
<p>The asymptotic approximation lead to a <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span></p>
<div class="math notranslate nohighlight">
\[
\bar{X}_{i}-\bar{Y} \pm z_{1-\alpha / 2} \sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}
\]</div>
<p>However, there is a better approximation using <span class="math notranslate nohighlight">\(t_v\)</span> distribution than the normal approximation.</p>
<div class="math notranslate nohighlight">
\[
T=\frac{\bar{X}-\bar{Y}-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}} \stackrel{\mathcal{D}}{\longrightarrow} t_v
\]</div>
<p>But the degree of freedom <span class="math notranslate nohighlight">\(v\)</span> is involved. It is estimated by  Welch-Satterthwaite approximation,</p>
<div class="math notranslate nohighlight">
\[
\nu \approx \frac{\left(\frac{S_{X}^{2}}{n}+\frac{S_{T}^{2}}{m}\right)^{2}}{\left(\frac{S_{x}^{2}}{n}\right)^{2} /(n-1)+\left(\frac{S_{Y}^{2}}{m}\right)^{2} /(m-1)}
\]</div>
<p>The asymptotic approximation lead to a <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> confidence interval for the true difference in mean <span class="math notranslate nohighlight">\(\mu_X - \mu_Y\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\bar{X}_{i}-\bar{Y} \pm t_{\nu}^{1-\alpha / 2} \sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}
\]</div>
</div>
</div>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">Â¶</a></h3>
<p>The analysis for the above cases are summarized into the table below. In general, if <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are of normal distributions, the pivot quantity follows a known distribution. If not, we use CLT to obtain an approximate distribution, which requires <strong>large</strong> <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(m\)</span>.</p>
<div class="math notranslate nohighlight">
\[
H_0: \mu_X - \mu_Y = 0
\]</div>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Dependency</p></th>
<th class="head"><p>Test statistic</p></th>
<th class="head"><p>Normal</p></th>
<th class="head"><p>Non-normal, large <span class="math notranslate nohighlight">\(n, m\)</span></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Paired (reduced to a univariate test)</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\bar{D}-\mu_{D}}{S_{D} / \sqrt{n}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\sim t_{n-1}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\stackrel{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>Independent with equal variance</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{(\bar{X}-\bar{Y})-\left(\mu_{X}-\mu_{Y}\right)}{S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\sim t_{n+m-2}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\stackrel{\mathcal{D}}{\longrightarrow} \mathcal{N}(0,1)\)</span></p></td>
</tr>
<tr class="row-even"><td><p>Independent with unequal variance</p></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\left( \bar{X}-\bar{Y} \right)-\left(\mu_{X}-\mu_{Y}\right)}{\sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}}\)</span></p></td>
<td><p>/</p></td>
<td><p><span class="math notranslate nohighlight">\(\stackrel{\mathcal{D}}{\longrightarrow} t_v\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="multivariate-settings">
<h2>Multivariate Settings<a class="headerlink" href="#multivariate-settings" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="hotelling-s-t-2-distribution">
<h3>Hotellingâ€™s <span class="math notranslate nohighlight">\(T^2\)</span> Distribution<a class="headerlink" href="#hotelling-s-t-2-distribution" title="Permalink to this headline">Â¶</a></h3>
<dl class="simple myst">
<dt>Definition (Hotellingâ€™s <span class="math notranslate nohighlight">\(T^2\)</span> Distribution )</dt><dd><p>Suppose <span class="math notranslate nohighlight">\(\boldsymbol{x} \sim \mathcal{N} _p(\boldsymbol{0} , \boldsymbol{\Sigma} )\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{V} \sim W_p(k, \boldsymbol{\Sigma} )\)</span> are independent. Define</p>
<div class="math notranslate nohighlight">
\[
  T^2 = k \boldsymbol{x} ^{\top} \boldsymbol{V} ^{-1} \boldsymbol{x}
  \]</div>
<p>Then <span class="math notranslate nohighlight">\(T^2\)</span> is said to follow a Hotellingâ€™s <span class="math notranslate nohighlight">\(T^2\)</span> distribution with parameter <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(k\)</span>, denoted as <span class="math notranslate nohighlight">\(T^2(p, k)\)</span>.</p>
<p>In univariate sense, the Hotellingâ€™s <span class="math notranslate nohighlight">\(T^2\)</span> statistic can be reduced to the squared <span class="math notranslate nohighlight">\(t\)</span>-statistic.</p>
</dd>
<dt>Properties</dt><dd><ul>
<li><p>If <span class="math notranslate nohighlight">\(\bar{\boldsymbol{x}}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{S}\)</span> are respectively the sample mean vector and sample covariance matrix of a random sample of size <span class="math notranslate nohighlight">\(n\)</span> taken from <span class="math notranslate nohighlight">\(\mathcal{N} _p(\boldsymbol{\mu} , \boldsymbol{\Sigma} )\)</span>, then</p>
<div class="math notranslate nohighlight">
\[n(\overline{\boldsymbol{x}}-\boldsymbol{\mu})^{\top} \boldsymbol{S}^{-1}(\overline{\boldsymbol{x}}-\boldsymbol{\mu}) \sim T^{2}(p, n-1)\]</div>
</li>
<li><p>The distribution of the quadratic form under non-normality is reasonably robust as long as the underlying multivariate distribution has pdf contours close to elliptical shape, but <span class="math notranslate nohighlight">\(T^2\)</span> is sensitive to the departure from such elliptical symmetry of the distribution.</p></li>
<li><p>Invariant under transformation of <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>:<span class="math notranslate nohighlight">\(\boldsymbol{C} \boldsymbol{x} + \boldsymbol{d}\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{C}\)</span> is non-singular.</p></li>
<li><p>Related to other distribution:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T^{2}(p, k)=\frac{k p}{k-p+1} F(p, k-p+1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T^{2}(1, k)=t^{2}(k)=F(1, k)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(T^{2}(p, \infty) \rightarrow \chi ^2 _p\)</span> by CLT, without assuming normality of the distribution of <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span></p></li>
</ul>
</li>
<li><p>Related to Mahalanobis distance: <span class="math notranslate nohighlight">\(T^{2}=n D_{\boldsymbol{S}}^{2}(\overline{\boldsymbol{x}}, \boldsymbol{\mu})\)</span></p></li>
</ul>
</dd>
</dl>
</div>
<div class="section" id="one-sample-mean">
<h3>One-sample Mean<a class="headerlink" href="#one-sample-mean" title="Permalink to this headline">Â¶</a></h3>
<p>Assume <span class="math notranslate nohighlight">\(\boldsymbol{x} \sim \mathcal{N} _p(\boldsymbol{0} , \boldsymbol{\Sigma} )\)</span>, want to test</p>
<div class="math notranslate nohighlight">
\[
H_{0}: \boldsymbol{\mu}=\boldsymbol{\mu}_{0} \operatorname{vs } H_{1}: \boldsymbol{\mu} \neq \boldsymbol{\mu}_{0}
\]</div>
<dl class="simple myst">
<dt>Test statistic under <span class="math notranslate nohighlight">\(H_0\)</span></dt><dd><ul>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is known:</p>
<div class="math notranslate nohighlight">
\[T^{2}=n\left(\overline{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right)^{\top} \boldsymbol{\Sigma}^{-1}\left(\overline{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right) \sim \chi^{2}(p)\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is unknown, estimated by <span class="math notranslate nohighlight">\(\boldsymbol{S}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
    T^{2}=n\left(\overline{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right)^{\top} \boldsymbol{S}^{-1}\left(\overline{\boldsymbol{x}}-\boldsymbol{\mu}_{0}\right) &amp;\sim T^{2}(p, n-1) \\
    &amp;\sim \frac{(n-1) p}{n-p} F(p, n-p) \\
    &amp; \rightarrow \chi ^2 _p \quad \text{as } n \rightarrow \infty  
    \end{aligned}\end{split}\]</div>
</li>
<li><p>Analogously, in univariate case,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \left\{\begin{array}{l}
    \frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{\sigma} \sim N(0,1) \text { if } \sigma^{2} \text { is known } \\
    \frac{\sqrt{n}\left(\bar{x}-\mu_{0}\right)}{s} \sim t(n-1) \text { if } \sigma^{2} \text { is unknown. }
    \end{array}\right.
    \end{split}\]</div>
</li>
</ul>
</dd>
<dt>Confidence Region</dt><dd><ul>
<li><p>A <span class="math notranslate nohighlight">\((1-\alpha)100\%\)</span> confidence region for <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> is a <span class="math notranslate nohighlight">\(p\)</span>-dimensional ellipsoid centered at <span class="math notranslate nohighlight">\(\bar{\boldsymbol{x}}\)</span>, i.e. a collection of all those <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> which will not be rejected by the above <span class="math notranslate nohighlight">\(T^2\)</span> test at significance level <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="math notranslate nohighlight">
\[
    \left\{\boldsymbol{\mu}: n(\overline{\boldsymbol{x}}-\boldsymbol{\mu})^{\top} \boldsymbol{S}^{-1}(\overline{\boldsymbol{x}}-\boldsymbol{\mu}) \leq T_{\alpha}^{2}(p, n-1)=c_{\alpha}\right\}
    \]</div>
<div class="figure align-default" id="test-ellipsoid">
<a class="reference internal image-reference" href="../_images/test-ellipsoid.png"><img alt="" src="../_images/test-ellipsoid.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text">Confidence region</span><a class="headerlink" href="#test-ellipsoid" title="Permalink to this image">Â¶</a></p>
</div>
</li>
<li><p>This confidence ellipsoid above is the most precise confidence region of the vector <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span>, in the sense that any other form of confidence region for <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> with the same confidence level <span class="math notranslate nohighlight">\((1-\alpha)\)</span> will have <strong>larger volume</strong> in the <span class="math notranslate nohighlight">\(p\)</span>-dimensional space of <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> and hence less precise.</p></li>
</ul>
</dd>
<dt>Simultaneous confidence interval</dt><dd><ul>
<li><p>Individual CI: Sometimes people get used to confidence intervals for individual components, such as</p>
<div class="math notranslate nohighlight">
\[
    \bar{x}_{j}-t^{\alpha / 2}_{n-1} \frac{s_j}{\sqrt{n}} &lt;\mu_{j}&lt;\bar{x}_{j}+t^{\alpha / 2}_{n-1} \frac{s_j}{\sqrt{n}}
    \]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{x}_j\)</span> and <span class="math notranslate nohighlight">\(s_j\)</span> are respectively the sample mean and standard deviation of the <span class="math notranslate nohighlight">\(j\)</span>-th variate that has mean <span class="math notranslate nohighlight">\(\mu_j\)</span>.</p>
</li>
<li><p>Problem: while each of the <span class="math notranslate nohighlight">\(p\)</span> intervals has confidence level <span class="math notranslate nohighlight">\((1-\alpha)\)</span>, the joint probability (joint confidence level) that all the <span class="math notranslate nohighlight">\(p\)</span> statements are true simultaneously is less than <span class="math notranslate nohighlight">\((1-\alpha)\)</span>.</p>
<ul class="simple">
<li><p>for instance, if all the <span class="math notranslate nohighlight">\(p\)</span> variates are independent, then the joint confidence level is <span class="math notranslate nohighlight">\((1-\alpha)^p\)</span>.</p></li>
<li><p>to correct this, we can use Bonferroni or Scheffeâ€™s simultaneous C.I., which forms a hyper-rectangular region in <span class="math notranslate nohighlight">\(\mathbb{R} ^p\)</span>.</p></li>
</ul>
</li>
<li><p>The <span class="math notranslate nohighlight">\((1-\alpha)100\%\)</span> Bonferroni simultaneous C.I.s for <span class="math notranslate nohighlight">\(m\)</span> <strong>pre-determined</strong> linear components of means, <span class="math notranslate nohighlight">\(\boldsymbol{a}_{i}^{\top} \boldsymbol{\mu}(i=1, \ldots, m)\)</span>, are given by</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{a}_{i}^{\top} \overline{\boldsymbol{x}} \pm t ^{\alpha/(2m)}_{n-1} \sqrt{\frac{\boldsymbol{a}_{i}^{\top} \boldsymbol{S} \boldsymbol{a}_{i}}{n}}
    \]</div>
</li>
</ul>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Scheffe simultaneous C.I. works like a guarantee for any â€˜data snoopingâ€™ linear combinations in exploratory data analysis. Besides, it is related to <a class="reference internal" href="21-hypothesis-testing.html#uit"><span class="std std-ref">union intersection test</span></a>.</p>
</div>
<ul>
<li><p>The <span class="math notranslate nohighlight">\((1-\alpha)100\%\)</span> Scheffe simultaneous C.I.s for <strong>all possible</strong> linear combinations of means <span class="math notranslate nohighlight">\(\boldsymbol{a} ^{\top} \boldsymbol{\mu}\)</span> are given by</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{a}^{\top} \overline{\boldsymbol{x}} \pm \sqrt{T_{\alpha}^{2}(p, n-1)} \sqrt{\frac{\boldsymbol{a}^{\top} \boldsymbol{S a}}{n}}
    \]</div>
</li>
<li><p>Pros: Compared with the advantages of ellipsoidal confidence regions, these hyper-rectangles (orthotopes) are easier to form and to compute.</p></li>
<li><p>Cons: Both Bonferroni and ScheffÃ© intervals are <strong>wider</strong> (hence less accurate) than the ordinary confidence intervals which are constructed with separate confidence level of <span class="math notranslate nohighlight">\((1-\alpha)\)</span>.</p>
<div class="figure align-default" id="test-multi-bon-sch">
<a class="reference internal image-reference" href="../_images/test-multi-Bon-Sch.png"><img alt="" src="../_images/test-multi-Bon-Sch.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">Bonferroni (left) and Scheffe (left) simultaneous C.I.s.</span><a class="headerlink" href="#test-multi-bon-sch" title="Permalink to this image">Â¶</a></p>
</div>
</li>
<li><p>If we just want to conduct univariate tests of means <span class="math notranslate nohighlight">\(H_0: \mu_k = 0\)</span> for each <span class="math notranslate nohighlight">\(k = 1, 2, \ldots, p\)</span>, i.e. <span class="math notranslate nohighlight">\(\boldsymbol{a} _k = \boldsymbol{e} _k\)</span>, then the C.I. has the general form <span class="math notranslate nohighlight">\(\bar{x}_{k} \pm c_{n, p, \alpha} \sqrt{\frac{s_{k k}}{n}}\)</span> for some multiplier <span class="math notranslate nohighlight">\(c_{n, p, \alpha}\)</span> depending on <span class="math notranslate nohighlight">\(n,p,\alpha\)</span>. The above methods can be summarized as follows</p>
<ul class="simple">
<li><p>marginal C.I. using <span class="math notranslate nohighlight">\(t\)</span> statistics (ignoring dependence among components): <span class="math notranslate nohighlight">\(t_{n-1}^{\alpha/2}\)</span></p></li>
<li><p>Bonferroni simultaneous C.I. using <span class="math notranslate nohighlight">\(t\)</span> statistics: <span class="math notranslate nohighlight">\(t_{n-1}^{\alpha/(2p)}\)</span></p></li>
<li><p>Scheffe simultaneous C.I.: <span class="math notranslate nohighlight">\(\sqrt{T^2_\alpha (p, n-1)}\)</span></p></li>
<li><p>Asymptotic simultaneous C.I. using <span class="math notranslate nohighlight">\(\chi ^2\)</span> statistic as <span class="math notranslate nohighlight">\(n\)</span> is large: <span class="math notranslate nohighlight">\(\sqrt{\chi ^2 _p (\alpha)}\)</span></p></li>
</ul>
</li>
</ul>
</dd>
</dl>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./13-statistics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="21-hypothesis-testing.html" title="previous page">Hypothesis Testing</a>
    <a class='right-next' id="next-link" href="33-confusion-matrix.html" title="next page">Confusion Matrix</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dennis Zheng<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>